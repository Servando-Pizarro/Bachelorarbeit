{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981b8252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 16:58:48.751 INFO    numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-08-16 16:58:48.754 INFO    numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import logging\n",
    "import string \n",
    "import streamlit as st\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from haystack.utils import convert_files_to_docs, fetch_archive_from_http\n",
    "from haystack.nodes.file_converter import BaseConverter, DocxToTextConverter, PDFToTextConverter, TextConverter\n",
    "from haystack.schema import Document\n",
    "import pdfplumber\n",
    "\n",
    "import pandas as pd\n",
    "from haystack.nodes import PreProcessor\n",
    "import tempfile\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d793d355",
   "metadata": {},
   "source": [
    "# Text import and cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53349185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading txt,pdf and docx files \n",
    "\n",
    "def load_document(\n",
    "    file: str,\n",
    "    encoding: Optional[str] = None,\n",
    "    id_hash_keys: Optional[List[str]] = None,\n",
    ") -> List[Document]:\n",
    "    \n",
    "    \"\"\"\n",
    "    takes docx, txt and pdf files as input and extracts text as well as the filename as metadata. Since haystack\n",
    "    does not take care of all pdf files, pdfplumber is attached to the pipeline in case the pdf extraction fails\n",
    "    via Haystack.\n",
    "\n",
    "    Returns a list of type haystack.schema.Document\n",
    "    \"\"\"\n",
    "\n",
    "    if file.endswith('.pdf'):\n",
    "        converter = PDFToTextConverter(remove_numeric_tables=True)\n",
    "    if file.endswith('.txt'):\n",
    "        converter = TextConverter()\n",
    "    if file.endswith('.docx'):\n",
    "        converter = DocxToTextConverter()\n",
    "\n",
    "    print(converter)\n",
    "    documents = []\n",
    "\n",
    "    logger.info(\"Converting {}\".format(file))\n",
    "    # PDFToTextConverter, TextConverter, and DocxToTextConverter return a list containing a single Document\n",
    "    document = converter.convert(\n",
    "                file_path=file, meta=None, encoding=encoding, id_hash_keys=id_hash_keys\n",
    "            )[0]\n",
    "    text = document.content\n",
    "    documents.append(Document(content=text, meta={\"name\": file}, id_hash_keys=id_hash_keys))\n",
    "    \n",
    "    '''check if text is empty and apply different pdf processor. This can happen whith certain pdf types.'''\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a069b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''basic cleaning - suitable for transformer models'''\n",
    "def basic(s):\n",
    "    \"\"\"\n",
    "    :param s: string to be processed\n",
    "    :return: processed string: see comments in the source code for more info\n",
    "    \"\"\"\n",
    "    # Text Lowercase\n",
    "    s = s.lower() \n",
    "    # Remove punctuation\n",
    "    translator = str.maketrans(' ', ' ', string.punctuation) \n",
    "    s = s.translate(translator)\n",
    "    # Remove URLs\n",
    "    s = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', ' ', s, flags=re.MULTILINE)\n",
    "    s = re.sub(r\"http\\S+\", \" \", s)\n",
    "    # Remove new line characters\n",
    "    s = re.sub('\\n', ' ', s) \n",
    "  \n",
    "    # Remove distracting single quotes\n",
    "    s = re.sub(\"\\'\", \" \", s) \n",
    "    # Remove all remaining numbers and non alphanumeric characters\n",
    "    s = re.sub(r'\\d+', ' ', s) \n",
    "    s = re.sub(r'\\W+', ' ', s)\n",
    "\n",
    "    # define custom words to replace:\n",
    "    #s = re.sub(r'strengthenedstakeholder', 'strengthened stakeholder', s)\n",
    "    \n",
    "    return s.strip()\n",
    "\n",
    " \n",
    "\n",
    "def preprocessing(document):\n",
    "\n",
    "    \"\"\"\n",
    "    takes in haystack document object and splits it into paragraphs and applies simple cleaning.\n",
    "\n",
    "    Returns cleaned list of haystack document objects. One paragraph per object. Also returns pandas df and \n",
    "    list that contains all text joined together.\n",
    "    \"\"\"    \n",
    "\n",
    "    preprocessor = PreProcessor(\n",
    "        clean_empty_lines=True,\n",
    "        clean_whitespace=True,\n",
    "        clean_header_footer=True,\n",
    "        split_by=\"word\",\n",
    "        split_length=120,\n",
    "        split_respect_sentence_boundary=True,\n",
    "        #split_overlap=5\n",
    "    )\n",
    "    for i in document:\n",
    "        docs_processed = preprocessor.process([i])\n",
    "        for item in docs_processed:\n",
    "            item.content = basic(item.content)\n",
    "\n",
    "    print(\"your document has been splitted to\", len(docs_processed), \"paragraphs\")\n",
    "    \n",
    "    # create dataframe of text and list of all text\n",
    "    df = pd.DataFrame(docs_processed)\n",
    "    all_text = \" \".join(df.content.to_list())\n",
    "    par_list = df.content.to_list()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f1f03e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\serva\\Downloads\\NDCs\n",
      "Files in 'C:\\\\Users\\\\serva\\\\Downloads\\\\NDCs': ['Australias NDC June 2022 Update.docx', 'BOTSWANA.docx', 'EU_NDC_Submission_December 2020.docx', 'Updated - First NDC - FINAL - PDF.docx']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir('C:\\\\Users\\\\serva\\\\Downloads\\\\NDCs')\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "\n",
    "cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(\"Files in %r: %s\" % (cwd, files))\n",
    "\n",
    "\n",
    "# Safe directory in a var\n",
    "directory_in_str='C:\\\\Users\\\\serva\\\\Downloads\\\\NDCs'\n",
    "directory = os.fsencode(directory_in_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a3de94cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 17:31:04.319 INFO    __main__: Converting Australias NDC June 2022 Update.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<haystack.nodes.file_converter.docx.DocxToTextConverter object at 0x000001AC1FCA39D0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 140.53docs/s]\n",
      "2022-08-16 17:31:04.505 INFO    __main__: Converting BOTSWANA.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your document has been splitted to 14 paragraphs\n",
      "<haystack.nodes.file_converter.docx.DocxToTextConverter object at 0x000001AC1CE22BE0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 332.01docs/s]\n",
      "2022-08-16 17:31:04.556 INFO    __main__: Converting EU_NDC_Submission_December 2020.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your document has been splitted to 9 paragraphs\n",
      "<haystack.nodes.file_converter.docx.DocxToTextConverter object at 0x000001AC15125280>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/1 [00:00<?, ?docs/s]2022-08-16 17:31:04.592 WARNING haystack.nodes.preprocessor.preprocessor: One or more sentence found with word count higher than the split length.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 233.16docs/s]\n",
      "2022-08-16 17:31:04.632 INFO    __main__: Converting Updated - First NDC - FINAL - PDF.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your document has been splitted to 38 paragraphs\n",
      "<haystack.nodes.file_converter.docx.DocxToTextConverter object at 0x000001AC1B2740A0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/1 [00:00<?, ?docs/s]2022-08-16 17:31:04.646 WARNING haystack.nodes.preprocessor.preprocessor: One or more sentence found with word count higher than the split length.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 125.25docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your document has been splitted to 40 paragraphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "\"\"\"\"data=pd.DataFrame(columns=[\"content\",\"text\",\"id\",\"meta\",\"score\",\"embedding\"])\n",
    "df=preprocessing(docs)\n",
    "data1=data.append(df)\n",
    "\n",
    "print(data1)\"\"\"\n",
    "\n",
    "#Create an empty df to append the others to\n",
    "\n",
    "data=pd.DataFrame(columns=[\"content\",\"id\",\"meta\",\"score\",\"embedding\"])\n",
    "\n",
    "# Iterate through the files in that directory\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    docs=load_document(filename)\n",
    "    \n",
    "# Using the Preprocessor to create a df and append it to data \n",
    "    df = preprocessing(docs)\n",
    "    df[\"Country\"]=filename\n",
    "    data=data.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "979f884a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "      <th>meta</th>\n",
       "      <th>score</th>\n",
       "      <th>embedding</th>\n",
       "      <th>content_type</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonwealth of australia creative commons attribution international licence...</td>\n",
       "      <td>d2055926c3e3d72d804f0a85ff79b42</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 0}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the full licence terms are available from content contained herein should be...</td>\n",
       "      <td>cedb83948b28dc12f54f342b734deeeb</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 1}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no representation expressed or implied is made as to the currency accuracy r...</td>\n",
       "      <td>470a3cb556e9eb11cb75633cac46e8b2</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 2}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>both targets are economywide emissions reduction commitments covering all se...</td>\n",
       "      <td>677fca625f05d36da91dad3b9fc1de07</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 3}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it reflects the australian government s resolve to urgently step up action a...</td>\n",
       "      <td>4e12db243fde45e6e1b8b99fb865bdad</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 4}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           content  \\\n",
       "0  commonwealth of australia creative commons attribution international licence...   \n",
       "1  the full licence terms are available from content contained herein should be...   \n",
       "2  no representation expressed or implied is made as to the currency accuracy r...   \n",
       "3  both targets are economywide emissions reduction commitments covering all se...   \n",
       "4  it reflects the australian government s resolve to urgently step up action a...   \n",
       "\n",
       "                                 id  \\\n",
       "0   d2055926c3e3d72d804f0a85ff79b42   \n",
       "1  cedb83948b28dc12f54f342b734deeeb   \n",
       "2  470a3cb556e9eb11cb75633cac46e8b2   \n",
       "3  677fca625f05d36da91dad3b9fc1de07   \n",
       "4  4e12db243fde45e6e1b8b99fb865bdad   \n",
       "\n",
       "                                                               meta score  \\\n",
       "0  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 0}  None   \n",
       "1  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 1}  None   \n",
       "2  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 2}  None   \n",
       "3  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 3}  None   \n",
       "4  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 4}  None   \n",
       "\n",
       "  embedding content_type                               Country  \n",
       "0      None         text  Australias NDC June 2022 Update.docx  \n",
       "1      None         text  Australias NDC June 2022 Update.docx  \n",
       "2      None         text  Australias NDC June 2022 Update.docx  \n",
       "3      None         text  Australias NDC June 2022 Update.docx  \n",
       "4      None         text  Australias NDC June 2022 Update.docx  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0988822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>id</th>\n",
       "      <th>meta</th>\n",
       "      <th>score</th>\n",
       "      <th>embedding</th>\n",
       "      <th>content_type</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonwealth of australia creative commons attribution international licence...</td>\n",
       "      <td>d2055926c3e3d72d804f0a85ff79b42</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 0}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the full licence terms are available from content contained herein should be...</td>\n",
       "      <td>cedb83948b28dc12f54f342b734deeeb</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 1}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no representation expressed or implied is made as to the currency accuracy r...</td>\n",
       "      <td>470a3cb556e9eb11cb75633cac46e8b2</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 2}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>both targets are economywide emissions reduction commitments covering all se...</td>\n",
       "      <td>677fca625f05d36da91dad3b9fc1de07</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 3}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it reflects the australian government s resolve to urgently step up action a...</td>\n",
       "      <td>4e12db243fde45e6e1b8b99fb865bdad</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 4}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the australian government is working to urgently implement these policies to...</td>\n",
       "      <td>c2ee6398537ac65e7591b85b957bdd79</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 5}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a powering the regions fund to support the development of new clean energy i...</td>\n",
       "      <td>604457c5620e049fb968306436885fa3</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 6}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>australia s first national electric vehicle strategy to reduce emissions and...</td>\n",
       "      <td>6d20bd5f94f1c1306614dafac6eb4c4e</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 7}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>these new measures will build on existing emissions reduction and low emissi...</td>\n",
       "      <td>29888d9e51beeface2fe54477104ba68</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 8}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the annual statement and other climate policy will be informed by australia ...</td>\n",
       "      <td>177da64dfdc21898f9fdf2972508994c</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 9}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              Text  \\\n",
       "0  commonwealth of australia creative commons attribution international licence...   \n",
       "1  the full licence terms are available from content contained herein should be...   \n",
       "2  no representation expressed or implied is made as to the currency accuracy r...   \n",
       "3  both targets are economywide emissions reduction commitments covering all se...   \n",
       "4  it reflects the australian government s resolve to urgently step up action a...   \n",
       "5  the australian government is working to urgently implement these policies to...   \n",
       "6  a powering the regions fund to support the development of new clean energy i...   \n",
       "7  australia s first national electric vehicle strategy to reduce emissions and...   \n",
       "8  these new measures will build on existing emissions reduction and low emissi...   \n",
       "9  the annual statement and other climate policy will be informed by australia ...   \n",
       "\n",
       "                                 id  \\\n",
       "0   d2055926c3e3d72d804f0a85ff79b42   \n",
       "1  cedb83948b28dc12f54f342b734deeeb   \n",
       "2  470a3cb556e9eb11cb75633cac46e8b2   \n",
       "3  677fca625f05d36da91dad3b9fc1de07   \n",
       "4  4e12db243fde45e6e1b8b99fb865bdad   \n",
       "5  c2ee6398537ac65e7591b85b957bdd79   \n",
       "6  604457c5620e049fb968306436885fa3   \n",
       "7  6d20bd5f94f1c1306614dafac6eb4c4e   \n",
       "8  29888d9e51beeface2fe54477104ba68   \n",
       "9  177da64dfdc21898f9fdf2972508994c   \n",
       "\n",
       "                                                               meta score  \\\n",
       "0  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 0}  None   \n",
       "1  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 1}  None   \n",
       "2  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 2}  None   \n",
       "3  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 3}  None   \n",
       "4  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 4}  None   \n",
       "5  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 5}  None   \n",
       "6  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 6}  None   \n",
       "7  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 7}  None   \n",
       "8  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 8}  None   \n",
       "9  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 9}  None   \n",
       "\n",
       "  embedding content_type                               Country  \n",
       "0      None         text  Australias NDC June 2022 Update.docx  \n",
       "1      None         text  Australias NDC June 2022 Update.docx  \n",
       "2      None         text  Australias NDC June 2022 Update.docx  \n",
       "3      None         text  Australias NDC June 2022 Update.docx  \n",
       "4      None         text  Australias NDC June 2022 Update.docx  \n",
       "5      None         text  Australias NDC June 2022 Update.docx  \n",
       "6      None         text  Australias NDC June 2022 Update.docx  \n",
       "7      None         text  Australias NDC June 2022 Update.docx  \n",
       "8      None         text  Australias NDC June 2022 Update.docx  \n",
       "9      None         text  Australias NDC June 2022 Update.docx  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns \n",
    "\n",
    "data=data.rename(columns = {'content':'Text'})\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7371905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2e8ddd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    commonwealth of australia creative commons attribution international licence...\n",
       "1    the full licence terms are available from content contained herein should be...\n",
       "2    no representation expressed or implied is made as to the currency accuracy r...\n",
       "3    both targets are economywide emissions reduction commitments covering all se...\n",
       "4    it reflects the australian government s resolve to urgently step up action a...\n",
       "5    the australian government is working to urgently implement these policies to...\n",
       "6    a powering the regions fund to support the development of new clean energy i...\n",
       "7    australia s first national electric vehicle strategy to reduce emissions and...\n",
       "8    these new measures will build on existing emissions reduction and low emissi...\n",
       "9    the annual statement and other climate policy will be informed by australia ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "documents=data[\"Text\"]\n",
    "\n",
    "documents.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7e7421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "89db13ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d0662240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_docs = data['Text'].map(preprocess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2a64d368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [commonwealth, australia, creativ, common, attribut, intern, licenc, note, c...\n",
       "1    [licenc, term, avail, content, contain, attribut, australia, nation, determi...\n",
       "2    [represent, express, impli, currenc, accuraci, reliabl, complet, inform, con...\n",
       "3    [target, economywid, emiss, reduct, commit, cover, sector, gas, includ, aust...\n",
       "4    [reflect, australian, govern, resolv, urgent, step, action, work, alongsid, ...\n",
       "5    [australian, govern, work, urgent, implement, polici, maximis, emiss, reduct...\n",
       "6    [power, region, fund, support, develop, new, clean, energi, industri, decarb...\n",
       "7    [australia, nation, electr, vehicl, strategi, reduc, emiss, acceler, uptak, ...\n",
       "8    [new, measur, build, exist, emiss, reduct, low, emiss, technolog, acceler, p...\n",
       "9    [annual, statement, climat, polici, inform, australia, climat, chang, author...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5e2c5",
   "metadata": {},
   "source": [
    "# Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c254a047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 17:30:12.367 INFO    gensim.corpora.dictionary: adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-08-16 17:30:12.374 INFO    gensim.corpora.dictionary: built Dictionary(1152 unique tokens: ['adapt', 'agreement', 'allow', 'arm', 'attribut']...) from 101 documents (total 5635 corpus positions)\n",
      "2022-08-16 17:30:12.374 INFO    gensim.utils: Dictionary lifecycle event {'msg': \"built Dictionary(1152 unique tokens: ['adapt', 'agreement', 'allow', 'arm', 'attribut']...) from 101 documents (total 5635 corpus positions)\", 'datetime': '2022-08-16T17:30:12.374804', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d5e78aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 adapt\n",
      "1 agreement\n",
      "2 allow\n",
      "3 arm\n",
      "4 attribut\n",
      "5 australia\n",
      "6 avail\n",
      "7 coat\n",
      "8 common\n",
      "9 commonwealth\n",
      "10 content\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "700e4298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (5, 4),\n",
       " (27, 2),\n",
       " (40, 1),\n",
       " (58, 1),\n",
       " (63, 1),\n",
       " (69, 2),\n",
       " (85, 1),\n",
       " (88, 2),\n",
       " (95, 1),\n",
       " (107, 1),\n",
       " (108, 1),\n",
       " (117, 3),\n",
       " (119, 1),\n",
       " (125, 1),\n",
       " (127, 1),\n",
       " (135, 1),\n",
       " (137, 1),\n",
       " (151, 2),\n",
       " (159, 1),\n",
       " (184, 1),\n",
       " (205, 1),\n",
       " (257, 4),\n",
       " (268, 1),\n",
       " (283, 1),\n",
       " (285, 1),\n",
       " (295, 2),\n",
       " (313, 1),\n",
       " (314, 2),\n",
       " (315, 1),\n",
       " (316, 1),\n",
       " (317, 2),\n",
       " (318, 1),\n",
       " (319, 1),\n",
       " (320, 1),\n",
       " (321, 1),\n",
       " (322, 1),\n",
       " (323, 1),\n",
       " (324, 1),\n",
       " (325, 1),\n",
       " (326, 1),\n",
       " (327, 2)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cd60e11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 0 (\"adapt\") appears 1 time.\n",
      "Word 1 (\"agreement\") appears 1 time.\n",
      "Word 5 (\"australia\") appears 4 time.\n",
      "Word 27 (\"provid\") appears 2 time.\n",
      "Word 40 (\"australian\") appears 1 time.\n",
      "Word 58 (\"govern\") appears 1 time.\n",
      "Word 63 (\"inform\") appears 1 time.\n",
      "Word 69 (\"nation\") appears 2 time.\n",
      "Word 85 (\"action\") appears 1 time.\n",
      "Word 88 (\"climat\") appears 2 time.\n",
      "Word 95 (\"emiss\") appears 1 time.\n",
      "Word 107 (\"net\") appears 1 time.\n",
      "Word 108 (\"pari\") appears 1 time.\n",
      "Word 117 (\"target\") appears 3 time.\n",
      "Word 119 (\"zero\") appears 1 time.\n",
      "Word 125 (\"inventori\") appears 1 time.\n",
      "Word 127 (\"new\") appears 1 time.\n",
      "Word 135 (\"signific\") appears 1 time.\n",
      "Word 137 (\"track\") appears 1 time.\n",
      "Word 151 (\"impact\") appears 2 time.\n",
      "Word 159 (\"polici\") appears 1 time.\n",
      "Word 184 (\"communiti\") appears 1 time.\n",
      "Word 205 (\"region\") appears 1 time.\n",
      "Word 257 (\"report\") appears 4 time.\n",
      "Word 268 (\"annual\") appears 1 time.\n",
      "Word 283 (\"measur\") appears 1 time.\n",
      "Word 285 (\"progress\") appears 1 time.\n",
      "Word 295 (\"chang\") appears 2 time.\n",
      "Word 313 (\"basi\") appears 1 time.\n",
      "Word 314 (\"biennial\") appears 2 time.\n",
      "Word 315 (\"concert\") appears 1 time.\n",
      "Word 316 (\"context\") appears 1 time.\n",
      "Word 317 (\"detail\") appears 2 time.\n",
      "Word 318 (\"disast\") appears 1 time.\n",
      "Word 319 (\"ensur\") appears 1 time.\n",
      "Word 320 (\"environ\") appears 1 time.\n",
      "Word 321 (\"have\") appears 1 time.\n",
      "Word 322 (\"natur\") appears 1 time.\n",
      "Word 323 (\"readi\") appears 1 time.\n",
      "Word 324 (\"resili\") appears 1 time.\n",
      "Word 325 (\"tabl\") appears 1 time.\n",
      "Word 326 (\"take\") appears 1 time.\n",
      "Word 327 (\"transpar\") appears 2 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[10]\n",
    "\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                                     dictionary[bow_doc_4310[i][0]], \n",
    "                                                     bow_doc_4310[i][1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684c677",
   "metadata": {},
   "source": [
    "# TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb77891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 17:23:37.516 INFO    gensim.models.tfidfmodel: collecting document frequencies\n",
      "2022-08-16 17:23:37.518 INFO    gensim.models.tfidfmodel: PROGRESS: processing document #0\n",
      "2022-08-16 17:23:37.522 INFO    gensim.utils: TfidfModel lifecycle event {'msg': 'calculated IDF weights for 101 documents and 1121 features (4158 matrix non-zeros)', 'datetime': '2022-08-16T17:23:37.522003', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'initialize'}\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75ff88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "545d9de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.0386516605937095),\n",
      " (1, 0.027528524873248885),\n",
      " (2, 0.07945985312622485),\n",
      " (3, 0.11357588818407703),\n",
      " (4, 0.3178394125048994),\n",
      " (5, 0.10484707001246571),\n",
      " (6, 0.056910380511656374),\n",
      " (7, 0.11357588818407703),\n",
      " (8, 0.20844465760547684),\n",
      " (9, 0.2596187101922551),\n",
      " (10, 0.09651787065515095),\n",
      " (11, 0.11357588818407703),\n",
      " (12, 0.11357588818407703),\n",
      " (13, 0.3407276645522311),\n",
      " (14, 0.11357588818407703),\n",
      " (15, 0.11357588818407703),\n",
      " (16, 0.11357588818407703),\n",
      " (17, 0.16369452897972267),\n",
      " (18, 0.48258935327575475),\n",
      " (19, 0.11357588818407703),\n",
      " (20, 0.11357588818407703),\n",
      " (21, 0.22715177636815406),\n",
      " (22, 0.22715177636815406),\n",
      " (23, 0.11357588818407703),\n",
      " (24, 0.03436090789708789),\n",
      " (25, 0.11357588818407703),\n",
      " (26, 0.07396839804058246),\n",
      " (27, 0.05456484299324088),\n",
      " (28, 0.20181489042916792),\n",
      " (29, 0.09651787065515095),\n",
      " (30, 0.11357588818407703),\n",
      " (31, 0.08653957006408501),\n",
      " (32, 0.11357588818407703),\n",
      " (33, 0.11357588818407703),\n",
      " (34, 0.052423535006232855),\n",
      " (35, 0.11357588818407703),\n",
      " (36, 0.09651787065515095),\n",
      " (37, 0.0656879787137015)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1871436c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 17:24:24.456 INFO    gensim.models.ldamodel: using symmetric alpha at 0.2\n",
      "2022-08-16 17:24:24.457 INFO    gensim.models.ldamodel: using symmetric eta at 0.2\n",
      "2022-08-16 17:24:24.458 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "2022-08-16 17:24:24.460 INFO    gensim.models.ldamulticore: running online LDA training, 5 topics, 2 passes over the supplied corpus of 101 documents, updating every 8000 documents, evaluating every ~101 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-16 17:24:24.461 WARNING gensim.models.ldamulticore: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-16 17:24:24.463 INFO    gensim.models.ldamulticore: training LDA model using 4 processes\n",
      "2022-08-16 17:24:24.904 INFO    gensim.models.ldamulticore: PROGRESS: pass 0, dispatched chunk #0 = documents up to #101/101, outstanding queue size 1\n",
      "2022-08-16 17:24:26.975 INFO    gensim.models.ldamodel: topic #0 (0.200): 0.004*\"refer\" + 0.003*\"nation\" + 0.003*\"level\" + 0.003*\"plan\" + 0.003*\"australia\" + 0.003*\"averag\" + 0.003*\"emiss\" + 0.003*\"target\" + 0.003*\"determin\" + 0.003*\"transpar\"\n",
      "2022-08-16 17:24:26.975 INFO    gensim.models.ldamodel: topic #1 (0.200): 0.004*\"plan\" + 0.004*\"forest\" + 0.004*\"paragraph\" + 0.003*\"level\" + 0.003*\"brazil\" + 0.003*\"articl\" + 0.003*\"adapt\" + 0.003*\"account\" + 0.003*\"climat\" + 0.003*\"polici\"\n",
      "2022-08-16 17:24:26.976 INFO    gensim.models.ldamodel: topic #2 (0.200): 0.003*\"approach\" + 0.003*\"individu\" + 0.003*\"provid\" + 0.003*\"address\" + 0.003*\"polici\" + 0.003*\"ictu\" + 0.002*\"australia\" + 0.002*\"ipcc\" + 0.002*\"aviat\" + 0.002*\"transpar\"\n",
      "2022-08-16 17:24:26.977 INFO    gensim.models.ldamodel: topic #3 (0.200): 0.005*\"articl\" + 0.004*\"paragraph\" + 0.004*\"target\" + 0.004*\"energi\" + 0.004*\"agreement\" + 0.003*\"emiss\" + 0.003*\"sector\" + 0.003*\"pari\" + 0.003*\"european\" + 0.003*\"contribut\"\n",
      "2022-08-16 17:24:26.979 INFO    gensim.models.ldamodel: topic #4 (0.200): 0.004*\"australia\" + 0.003*\"protect\" + 0.003*\"account\" + 0.003*\"updat\" + 0.003*\"brazilian\" + 0.003*\"transit\" + 0.003*\"brazil\" + 0.003*\"methodolog\" + 0.003*\"australian\" + 0.003*\"climat\"\n",
      "2022-08-16 17:24:26.979 INFO    gensim.models.ldamodel: topic diff=2.515878, rho=1.000000\n",
      "2022-08-16 17:24:27.022 INFO    gensim.models.ldamodel: -9.265 per-word bound, 615.3 perplexity estimate based on a held-out corpus of 101 documents with 575 words\n",
      "2022-08-16 17:24:27.038 INFO    gensim.models.ldamulticore: PROGRESS: pass 1, dispatched chunk #0 = documents up to #101/101, outstanding queue size 1\n",
      "2022-08-16 17:24:27.064 INFO    gensim.models.ldamodel: topic #0 (0.200): 0.004*\"refer\" + 0.003*\"level\" + 0.003*\"nation\" + 0.003*\"australia\" + 0.003*\"averag\" + 0.003*\"emiss\" + 0.003*\"plan\" + 0.003*\"target\" + 0.003*\"transpar\" + 0.003*\"determin\"\n",
      "2022-08-16 17:24:27.066 INFO    gensim.models.ldamodel: topic #1 (0.200): 0.004*\"plan\" + 0.004*\"account\" + 0.004*\"paragraph\" + 0.004*\"articl\" + 0.004*\"level\" + 0.004*\"forest\" + 0.003*\"adapt\" + 0.003*\"assumpt\" + 0.003*\"brazil\" + 0.003*\"climat\"\n",
      "2022-08-16 17:24:27.067 INFO    gensim.models.ldamodel: topic #2 (0.200): 0.003*\"approach\" + 0.003*\"individu\" + 0.003*\"address\" + 0.003*\"provid\" + 0.003*\"polici\" + 0.003*\"ictu\" + 0.002*\"australia\" + 0.002*\"ipcc\" + 0.002*\"aviat\" + 0.002*\"transpar\"\n",
      "2022-08-16 17:24:27.068 INFO    gensim.models.ldamodel: topic #3 (0.200): 0.005*\"articl\" + 0.004*\"paragraph\" + 0.004*\"target\" + 0.004*\"energi\" + 0.004*\"agreement\" + 0.003*\"sector\" + 0.003*\"emiss\" + 0.003*\"pari\" + 0.003*\"enhanc\" + 0.003*\"european\"\n",
      "2022-08-16 17:24:27.069 INFO    gensim.models.ldamodel: topic #4 (0.200): 0.004*\"australia\" + 0.003*\"protect\" + 0.003*\"updat\" + 0.003*\"transit\" + 0.003*\"brazilian\" + 0.003*\"brazil\" + 0.003*\"australian\" + 0.003*\"climat\" + 0.003*\"commit\" + 0.003*\"european\"\n",
      "2022-08-16 17:24:27.070 INFO    gensim.models.ldamodel: topic diff=0.036675, rho=0.698345\n",
      "2022-08-16 17:24:27.109 INFO    gensim.models.ldamodel: -9.245 per-word bound, 606.7 perplexity estimate based on a held-out corpus of 101 documents with 575 words\n",
      "2022-08-16 17:24:27.136 INFO    gensim.utils: LdaMulticore lifecycle event {'msg': 'trained LdaModel(num_terms=1121, num_topics=5, decay=0.5, chunksize=2000) in 2.68s', 'datetime': '2022-08-16T17:24:27.136212', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "#Generating the lda_model with TF-IDF\n",
    "\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=5, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a2e85433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 17:24:30.410 INFO    gensim.models.ldamodel: topic #0 (0.200): 0.004*\"refer\" + 0.003*\"level\" + 0.003*\"nation\" + 0.003*\"australia\" + 0.003*\"averag\" + 0.003*\"emiss\" + 0.003*\"plan\" + 0.003*\"target\" + 0.003*\"transpar\" + 0.003*\"determin\"\n",
      "2022-08-16 17:24:30.411 INFO    gensim.models.ldamodel: topic #1 (0.200): 0.004*\"plan\" + 0.004*\"account\" + 0.004*\"paragraph\" + 0.004*\"articl\" + 0.004*\"level\" + 0.004*\"forest\" + 0.003*\"adapt\" + 0.003*\"assumpt\" + 0.003*\"brazil\" + 0.003*\"climat\"\n",
      "2022-08-16 17:24:30.412 INFO    gensim.models.ldamodel: topic #2 (0.200): 0.003*\"approach\" + 0.003*\"individu\" + 0.003*\"address\" + 0.003*\"provid\" + 0.003*\"polici\" + 0.003*\"ictu\" + 0.002*\"australia\" + 0.002*\"ipcc\" + 0.002*\"aviat\" + 0.002*\"transpar\"\n",
      "2022-08-16 17:24:30.413 INFO    gensim.models.ldamodel: topic #3 (0.200): 0.005*\"articl\" + 0.004*\"paragraph\" + 0.004*\"target\" + 0.004*\"energi\" + 0.004*\"agreement\" + 0.003*\"sector\" + 0.003*\"emiss\" + 0.003*\"pari\" + 0.003*\"enhanc\" + 0.003*\"european\"\n",
      "2022-08-16 17:24:30.414 INFO    gensim.models.ldamodel: topic #4 (0.200): 0.004*\"australia\" + 0.003*\"protect\" + 0.003*\"updat\" + 0.003*\"transit\" + 0.003*\"brazilian\" + 0.003*\"brazil\" + 0.003*\"australian\" + 0.003*\"climat\" + 0.003*\"commit\" + 0.003*\"european\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.004*\"refer\" + 0.003*\"level\" + 0.003*\"nation\" + 0.003*\"australia\" + 0.003*\"averag\" + 0.003*\"emiss\" + 0.003*\"plan\" + 0.003*\"target\" + 0.003*\"transpar\" + 0.003*\"determin\"\n",
      "Topic: 1 Word: 0.004*\"plan\" + 0.004*\"account\" + 0.004*\"paragraph\" + 0.004*\"articl\" + 0.004*\"level\" + 0.004*\"forest\" + 0.003*\"adapt\" + 0.003*\"assumpt\" + 0.003*\"brazil\" + 0.003*\"climat\"\n",
      "Topic: 2 Word: 0.003*\"approach\" + 0.003*\"individu\" + 0.003*\"address\" + 0.003*\"provid\" + 0.003*\"polici\" + 0.003*\"ictu\" + 0.002*\"australia\" + 0.002*\"ipcc\" + 0.002*\"aviat\" + 0.002*\"transpar\"\n",
      "Topic: 3 Word: 0.005*\"articl\" + 0.004*\"paragraph\" + 0.004*\"target\" + 0.004*\"energi\" + 0.004*\"agreement\" + 0.003*\"sector\" + 0.003*\"emiss\" + 0.003*\"pari\" + 0.003*\"enhanc\" + 0.003*\"european\"\n",
      "Topic: 4 Word: 0.004*\"australia\" + 0.003*\"protect\" + 0.003*\"updat\" + 0.003*\"transit\" + 0.003*\"brazilian\" + 0.003*\"brazil\" + 0.003*\"australian\" + 0.003*\"climat\" + 0.003*\"commit\" + 0.003*\"european\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1cbaec0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9880747199058533\t \n",
      "Topic: 0.005*\"articl\" + 0.004*\"paragraph\" + 0.004*\"target\" + 0.004*\"energi\" + 0.004*\"agreement\" + 0.003*\"sector\" + 0.003*\"emiss\" + 0.003*\"pari\" + 0.003*\"enhanc\" + 0.003*\"european\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[5]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "52be34d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7311464548110962\t Topic: 0.005*\"articl\" + 0.004*\"paragraph\" + 0.004*\"target\" + 0.004*\"energi\" + 0.004*\"agreement\"\n",
      "Score: 0.0676746815443039\t Topic: 0.004*\"refer\" + 0.003*\"level\" + 0.003*\"nation\" + 0.003*\"australia\" + 0.003*\"averag\"\n",
      "Score: 0.06742001324892044\t Topic: 0.004*\"plan\" + 0.004*\"account\" + 0.004*\"paragraph\" + 0.004*\"articl\" + 0.004*\"level\"\n",
      "Score: 0.06688319891691208\t Topic: 0.004*\"australia\" + 0.003*\"protect\" + 0.003*\"updat\" + 0.003*\"transit\" + 0.003*\"brazilian\"\n",
      "Score: 0.06687569618225098\t Topic: 0.003*\"approach\" + 0.003*\"individu\" + 0.003*\"address\" + 0.003*\"provid\" + 0.003*\"polici\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = 'Determining this huge process was quiet nice'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model_tfidf.print_topic(index, 5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
