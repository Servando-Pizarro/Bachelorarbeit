{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "981b8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import logging\n",
    "import string \n",
    "import streamlit as st\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from haystack.utils import convert_files_to_docs, fetch_archive_from_http\n",
    "from haystack.nodes.file_converter import BaseConverter, DocxToTextConverter, PDFToTextConverter, TextConverter\n",
    "from haystack.schema import Document\n",
    "import pdfplumber\n",
    "\n",
    "import pandas as pd\n",
    "from haystack.nodes import PreProcessor\n",
    "import tempfile\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d793d355",
   "metadata": {},
   "source": [
    "# Text import and cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53349185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading txt,pdf and docx files \n",
    "\n",
    "def load_document(\n",
    "    file: str,\n",
    "    encoding: Optional[str] = None,\n",
    "    id_hash_keys: Optional[List[str]] = None,\n",
    ") -> List[Document]:\n",
    "    \n",
    "    \"\"\"\n",
    "    takes docx, txt and pdf files as input and extracts text as well as the filename as metadata. Since haystack\n",
    "    does not take care of all pdf files, pdfplumber is attached to the pipeline in case the pdf extraction fails\n",
    "    via Haystack.\n",
    "\n",
    "    Returns a list of type haystack.schema.Document\n",
    "    \"\"\"\n",
    "\n",
    "    if file.endswith('.pdf'):\n",
    "        converter = PDFToTextConverter(remove_numeric_tables=True)\n",
    "    if file.endswith('.txt'):\n",
    "        converter = TextConverter()\n",
    "    if file.endswith('.docx'):\n",
    "        converter = DocxToTextConverter()\n",
    "\n",
    "    print(converter)\n",
    "    documents = []\n",
    "\n",
    "    logger.info(\"Converting {}\".format(file))\n",
    "    # PDFToTextConverter, TextConverter, and DocxToTextConverter return a list containing a single Document\n",
    "    document = converter.convert(\n",
    "                file_path=file, meta=None, encoding=encoding, id_hash_keys=id_hash_keys\n",
    "            )[0]\n",
    "    text = document.content\n",
    "    documents.append(Document(content=text, meta={\"name\": file}, id_hash_keys=id_hash_keys))\n",
    "    \n",
    "    '''check if text is empty and apply different pdf processor. This can happen whith certain pdf types.'''\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a069b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''basic cleaning - suitable for transformer models'''\n",
    "def basic(s):\n",
    "    \"\"\"\n",
    "    :param s: string to be processed\n",
    "    :return: processed string: see comments in the source code for more info\n",
    "    \"\"\"\n",
    "    # Text Lowercase\n",
    "    s = s.lower() \n",
    "    # Remove punctuation\n",
    "    translator = str.maketrans(' ', ' ', string.punctuation) \n",
    "    s = s.translate(translator)\n",
    "    # Remove URLs\n",
    "    s = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', ' ', s, flags=re.MULTILINE)\n",
    "    s = re.sub(r\"http\\S+\", \" \", s)\n",
    "    # Remove new line characters\n",
    "    s = re.sub('\\n', ' ', s) \n",
    "  \n",
    "    # Remove distracting single quotes\n",
    "    s = re.sub(\"\\'\", \" \", s) \n",
    "    # Remove all remaining numbers and non alphanumeric characters\n",
    "    s = re.sub(r'\\d+', ' ', s) \n",
    "    s = re.sub(r'\\W+', ' ', s)\n",
    "\n",
    "    # define custom words to replace:\n",
    "    #s = re.sub(r'strengthenedstakeholder', 'strengthened stakeholder', s)\n",
    "    \n",
    "    return s.strip()\n",
    "\n",
    " \n",
    "\n",
    "def preprocessing(document):\n",
    "\n",
    "    \"\"\"\n",
    "    takes in haystack document object and splits it into paragraphs and applies simple cleaning.\n",
    "\n",
    "    Returns cleaned list of haystack document objects. One paragraph per object. Also returns pandas df and \n",
    "    list that contains all text joined together.\n",
    "    \"\"\"    \n",
    "\n",
    "    preprocessor = PreProcessor(\n",
    "        clean_empty_lines=True,\n",
    "        clean_whitespace=True,\n",
    "        clean_header_footer=True,\n",
    "        split_by=\"word\",\n",
    "        split_length=120,\n",
    "        split_respect_sentence_boundary=True,\n",
    "        #split_overlap=5\n",
    "    )\n",
    "    for i in document:\n",
    "        docs_processed = preprocessor.process([i])\n",
    "        for item in docs_processed:\n",
    "            item.content = basic(item.content)\n",
    "\n",
    "    print(\"your document has been splitted to\", len(docs_processed), \"paragraphs\")\n",
    "    \n",
    "    # create dataframe of text and list of all text\n",
    "    df = pd.DataFrame(docs_processed)\n",
    "    all_text = \" \".join(df.content.to_list())\n",
    "    par_list = df.content.to_list()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1f03e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\serva\\Downloads\\NDCs\n",
      "Files in 'C:\\\\Users\\\\serva\\\\Downloads\\\\NDCs': ['Australias NDC June 2022 Update.docx', 'BOTSWANA.docx', 'EU_NDC_Submission_December 2020.docx', 'Updated - First NDC - FINAL - PDF.docx']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir('C:\\\\Users\\\\serva\\\\Downloads\\\\NDCs')\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "\n",
    "cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(\"Files in %r: %s\" % (cwd, files))\n",
    "\n",
    "\n",
    "# Safe directory in a var\n",
    "directory_in_str='C:\\\\Users\\\\serva\\\\Downloads\\\\NDCs'\n",
    "directory = os.fsencode(directory_in_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3de94cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:14:31.987 INFO    __main__: Converting Australias NDC June 2022 Update.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<haystack.nodes.file_converter.docx.DocxToTextConverter object at 0x0000016B4CA489A0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 166.06docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your document has been splitted to 14 paragraphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\serva\\AppData\\Local\\Temp\\ipykernel_14536\\2938173432.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(df)\n",
      "2022-08-17 10:14:32.369 INFO    __main__: Converting BOTSWANA.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<haystack.nodes.file_converter.docx.DocxToTextConverter object at 0x0000016B4CA040A0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?docs/s]\n",
      "C:\\Users\\serva\\AppData\\Local\\Temp\\ipykernel_14536\\2938173432.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(df)\n",
      "2022-08-17 10:14:32.485 INFO    __main__: Converting EU_NDC_Submission_December 2020.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your document has been splitted to 9 paragraphs\n",
      "<haystack.nodes.file_converter.docx.DocxToTextConverter object at 0x0000016B49C21880>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                     | 0/1 [00:00<?, ?docs/s]2022-08-17 10:14:32.567 WARNING haystack.nodes.preprocessor.preprocessor: One or more sentence found with word count higher than the split length.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 86.02docs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your document has been splitted to 38 paragraphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serva\\AppData\\Local\\Temp\\ipykernel_14536\\2938173432.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(df)\n",
      "2022-08-17 10:14:32.639 INFO    __main__: Converting Updated - First NDC - FINAL - PDF.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<haystack.nodes.file_converter.docx.DocxToTextConverter object at 0x0000016B49C21880>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                     | 0/1 [00:00<?, ?docs/s]2022-08-17 10:14:32.681 WARNING haystack.nodes.preprocessor.preprocessor: One or more sentence found with word count higher than the split length.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 45.58docs/s]\n",
      "C:\\Users\\serva\\AppData\\Local\\Temp\\ipykernel_14536\\2938173432.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your document has been splitted to 40 paragraphs\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "\"\"\"\"data=pd.DataFrame(columns=[\"content\",\"text\",\"id\",\"meta\",\"score\",\"embedding\"])\n",
    "df=preprocessing(docs)\n",
    "data1=data.append(df)\n",
    "\n",
    "print(data1)\"\"\"\n",
    "\n",
    "#Create an empty df to append the others to\n",
    "\n",
    "data=pd.DataFrame(columns=[\"content\",\"id\",\"meta\",\"score\",\"embedding\"])\n",
    "\n",
    "# Iterate through the files in that directory\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    docs=load_document(filename)\n",
    "    \n",
    "# Using the Preprocessor to create a df and append it to data \n",
    "    df = preprocessing(docs)\n",
    "    df[\"Country\"]=filename\n",
    "    data=data.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "979f884a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "      <th>meta</th>\n",
       "      <th>score</th>\n",
       "      <th>embedding</th>\n",
       "      <th>content_type</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonwealth of australia creative commons attribution international licence...</td>\n",
       "      <td>d2055926c3e3d72d804f0a85ff79b42</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 0}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the full licence terms are available from content contained herein should be...</td>\n",
       "      <td>cedb83948b28dc12f54f342b734deeeb</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 1}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no representation expressed or implied is made as to the currency accuracy r...</td>\n",
       "      <td>470a3cb556e9eb11cb75633cac46e8b2</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 2}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>both targets are economywide emissions reduction commitments covering all se...</td>\n",
       "      <td>677fca625f05d36da91dad3b9fc1de07</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 3}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it reflects the australian government s resolve to urgently step up action a...</td>\n",
       "      <td>4e12db243fde45e6e1b8b99fb865bdad</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 4}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           content  \\\n",
       "0  commonwealth of australia creative commons attribution international licence...   \n",
       "1  the full licence terms are available from content contained herein should be...   \n",
       "2  no representation expressed or implied is made as to the currency accuracy r...   \n",
       "3  both targets are economywide emissions reduction commitments covering all se...   \n",
       "4  it reflects the australian government s resolve to urgently step up action a...   \n",
       "\n",
       "                                 id  \\\n",
       "0   d2055926c3e3d72d804f0a85ff79b42   \n",
       "1  cedb83948b28dc12f54f342b734deeeb   \n",
       "2  470a3cb556e9eb11cb75633cac46e8b2   \n",
       "3  677fca625f05d36da91dad3b9fc1de07   \n",
       "4  4e12db243fde45e6e1b8b99fb865bdad   \n",
       "\n",
       "                                                               meta score  \\\n",
       "0  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 0}  None   \n",
       "1  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 1}  None   \n",
       "2  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 2}  None   \n",
       "3  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 3}  None   \n",
       "4  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 4}  None   \n",
       "\n",
       "  embedding content_type                               Country  \n",
       "0      None         text  Australias NDC June 2022 Update.docx  \n",
       "1      None         text  Australias NDC June 2022 Update.docx  \n",
       "2      None         text  Australias NDC June 2022 Update.docx  \n",
       "3      None         text  Australias NDC June 2022 Update.docx  \n",
       "4      None         text  Australias NDC June 2022 Update.docx  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0988822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>id</th>\n",
       "      <th>meta</th>\n",
       "      <th>score</th>\n",
       "      <th>embedding</th>\n",
       "      <th>content_type</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commonwealth of australia creative commons attribution international licence...</td>\n",
       "      <td>d2055926c3e3d72d804f0a85ff79b42</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 0}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the full licence terms are available from content contained herein should be...</td>\n",
       "      <td>cedb83948b28dc12f54f342b734deeeb</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 1}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no representation expressed or implied is made as to the currency accuracy r...</td>\n",
       "      <td>470a3cb556e9eb11cb75633cac46e8b2</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 2}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>both targets are economywide emissions reduction commitments covering all se...</td>\n",
       "      <td>677fca625f05d36da91dad3b9fc1de07</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 3}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it reflects the australian government s resolve to urgently step up action a...</td>\n",
       "      <td>4e12db243fde45e6e1b8b99fb865bdad</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 4}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the australian government is working to urgently implement these policies to...</td>\n",
       "      <td>c2ee6398537ac65e7591b85b957bdd79</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 5}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a powering the regions fund to support the development of new clean energy i...</td>\n",
       "      <td>604457c5620e049fb968306436885fa3</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 6}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>australia s first national electric vehicle strategy to reduce emissions and...</td>\n",
       "      <td>6d20bd5f94f1c1306614dafac6eb4c4e</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 7}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>these new measures will build on existing emissions reduction and low emissi...</td>\n",
       "      <td>29888d9e51beeface2fe54477104ba68</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 8}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the annual statement and other climate policy will be informed by australia ...</td>\n",
       "      <td>177da64dfdc21898f9fdf2972508994c</td>\n",
       "      <td>{'name': 'Australias NDC June 2022 Update.docx', '_split_id': 9}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>Australias NDC June 2022 Update.docx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              Text  \\\n",
       "0  commonwealth of australia creative commons attribution international licence...   \n",
       "1  the full licence terms are available from content contained herein should be...   \n",
       "2  no representation expressed or implied is made as to the currency accuracy r...   \n",
       "3  both targets are economywide emissions reduction commitments covering all se...   \n",
       "4  it reflects the australian government s resolve to urgently step up action a...   \n",
       "5  the australian government is working to urgently implement these policies to...   \n",
       "6  a powering the regions fund to support the development of new clean energy i...   \n",
       "7  australia s first national electric vehicle strategy to reduce emissions and...   \n",
       "8  these new measures will build on existing emissions reduction and low emissi...   \n",
       "9  the annual statement and other climate policy will be informed by australia ...   \n",
       "\n",
       "                                 id  \\\n",
       "0   d2055926c3e3d72d804f0a85ff79b42   \n",
       "1  cedb83948b28dc12f54f342b734deeeb   \n",
       "2  470a3cb556e9eb11cb75633cac46e8b2   \n",
       "3  677fca625f05d36da91dad3b9fc1de07   \n",
       "4  4e12db243fde45e6e1b8b99fb865bdad   \n",
       "5  c2ee6398537ac65e7591b85b957bdd79   \n",
       "6  604457c5620e049fb968306436885fa3   \n",
       "7  6d20bd5f94f1c1306614dafac6eb4c4e   \n",
       "8  29888d9e51beeface2fe54477104ba68   \n",
       "9  177da64dfdc21898f9fdf2972508994c   \n",
       "\n",
       "                                                               meta score  \\\n",
       "0  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 0}  None   \n",
       "1  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 1}  None   \n",
       "2  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 2}  None   \n",
       "3  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 3}  None   \n",
       "4  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 4}  None   \n",
       "5  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 5}  None   \n",
       "6  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 6}  None   \n",
       "7  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 7}  None   \n",
       "8  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 8}  None   \n",
       "9  {'name': 'Australias NDC June 2022 Update.docx', '_split_id': 9}  None   \n",
       "\n",
       "  embedding content_type                               Country  \n",
       "0      None         text  Australias NDC June 2022 Update.docx  \n",
       "1      None         text  Australias NDC June 2022 Update.docx  \n",
       "2      None         text  Australias NDC June 2022 Update.docx  \n",
       "3      None         text  Australias NDC June 2022 Update.docx  \n",
       "4      None         text  Australias NDC June 2022 Update.docx  \n",
       "5      None         text  Australias NDC June 2022 Update.docx  \n",
       "6      None         text  Australias NDC June 2022 Update.docx  \n",
       "7      None         text  Australias NDC June 2022 Update.docx  \n",
       "8      None         text  Australias NDC June 2022 Update.docx  \n",
       "9      None         text  Australias NDC June 2022 Update.docx  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns \n",
    "\n",
    "data=data.rename(columns = {'content':'Text'})\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7371905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e8ddd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    commonwealth of australia creative commons attribution international licence...\n",
       "1    the full licence terms are available from content contained herein should be...\n",
       "2    no representation expressed or implied is made as to the currency accuracy r...\n",
       "3    both targets are economywide emissions reduction commitments covering all se...\n",
       "4    it reflects the australian government s resolve to urgently step up action a...\n",
       "5    the australian government is working to urgently implement these policies to...\n",
       "6    a powering the regions fund to support the development of new clean energy i...\n",
       "7    australia s first national electric vehicle strategy to reduce emissions and...\n",
       "8    these new measures will build on existing emissions reduction and low emissi...\n",
       "9    the annual statement and other climate policy will be informed by australia ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "documents=data[\"Text\"]\n",
    "\n",
    "documents.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7e7421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89db13ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0662240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_docs = data['Text'].map(preprocess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a64d368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [commonwealth, australia, creativ, common, attribut, intern, licenc, note, c...\n",
       "1    [licenc, term, avail, content, contain, attribut, australia, nation, determi...\n",
       "2    [represent, express, impli, currenc, accuraci, reliabl, complet, inform, con...\n",
       "3    [target, economywid, emiss, reduct, commit, cover, sector, gas, includ, aust...\n",
       "4    [reflect, australian, govern, resolv, urgent, step, action, work, alongsid, ...\n",
       "5    [australian, govern, work, urgent, implement, polici, maximis, emiss, reduct...\n",
       "6    [power, region, fund, support, develop, new, clean, energi, industri, decarb...\n",
       "7    [australia, nation, electr, vehicl, strategi, reduc, emiss, acceler, uptak, ...\n",
       "8    [new, measur, build, exist, emiss, reduct, low, emiss, technolog, acceler, p...\n",
       "9    [annual, statement, climat, polici, inform, australia, climat, chang, author...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5e2c5",
   "metadata": {},
   "source": [
    "# Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ead0e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:16:10.759 INFO    gensim.corpora.dictionary: adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-08-17 10:16:10.767 INFO    gensim.corpora.dictionary: built Dictionary(1152 unique tokens: ['adapt', 'agreement', 'allow', 'arm', 'attribut']...) from 101 documents (total 5635 corpus positions)\n",
      "2022-08-17 10:16:10.768 INFO    gensim.utils: Dictionary lifecycle event {'msg': \"built Dictionary(1152 unique tokens: ['adapt', 'agreement', 'allow', 'arm', 'attribut']...) from 101 documents (total 5635 corpus positions)\", 'datetime': '2022-08-17T10:16:10.768046', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7f250cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (5, 4),\n",
       " (27, 2),\n",
       " (40, 1),\n",
       " (58, 1),\n",
       " (63, 1),\n",
       " (69, 2),\n",
       " (85, 1),\n",
       " (88, 2),\n",
       " (95, 1),\n",
       " (107, 1),\n",
       " (108, 1),\n",
       " (117, 3),\n",
       " (119, 1),\n",
       " (125, 1),\n",
       " (127, 1),\n",
       " (135, 1),\n",
       " (137, 1),\n",
       " (151, 2),\n",
       " (159, 1),\n",
       " (184, 1),\n",
       " (205, 1),\n",
       " (257, 4),\n",
       " (268, 1),\n",
       " (283, 1),\n",
       " (285, 1),\n",
       " (295, 2),\n",
       " (313, 1),\n",
       " (314, 2),\n",
       " (315, 1),\n",
       " (316, 1),\n",
       " (317, 2),\n",
       " (318, 1),\n",
       " (319, 1),\n",
       " (320, 1),\n",
       " (321, 1),\n",
       " (322, 1),\n",
       " (323, 1),\n",
       " (324, 1),\n",
       " (325, 1),\n",
       " (326, 1),\n",
       " (327, 2)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684c677",
   "metadata": {},
   "source": [
    "# TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb77891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:16:13.507 INFO    gensim.models.tfidfmodel: collecting document frequencies\n",
      "2022-08-17 10:16:13.509 INFO    gensim.models.tfidfmodel: PROGRESS: processing document #0\n",
      "2022-08-17 10:16:13.514 INFO    gensim.utils: TfidfModel lifecycle event {'msg': 'calculated IDF weights for 101 documents and 1152 features (4346 matrix non-zeros)', 'datetime': '2022-08-17T10:16:13.514599', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'initialize'}\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75ff88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "545d9de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.0386516605937095),\n",
      " (1, 0.027528524873248885),\n",
      " (2, 0.07945985312622485),\n",
      " (3, 0.11357588818407703),\n",
      " (4, 0.3178394125048994),\n",
      " (5, 0.10484707001246571),\n",
      " (6, 0.056910380511656374),\n",
      " (7, 0.11357588818407703),\n",
      " (8, 0.20844465760547684),\n",
      " (9, 0.2596187101922551),\n",
      " (10, 0.09651787065515095),\n",
      " (11, 0.11357588818407703),\n",
      " (12, 0.11357588818407703),\n",
      " (13, 0.3407276645522311),\n",
      " (14, 0.11357588818407703),\n",
      " (15, 0.11357588818407703),\n",
      " (16, 0.11357588818407703),\n",
      " (17, 0.16369452897972267),\n",
      " (18, 0.48258935327575475),\n",
      " (19, 0.11357588818407703),\n",
      " (20, 0.11357588818407703),\n",
      " (21, 0.22715177636815406),\n",
      " (22, 0.22715177636815406),\n",
      " (23, 0.11357588818407703),\n",
      " (24, 0.03436090789708789),\n",
      " (25, 0.11357588818407703),\n",
      " (26, 0.07396839804058246),\n",
      " (27, 0.05456484299324088),\n",
      " (28, 0.20181489042916792),\n",
      " (29, 0.09651787065515095),\n",
      " (30, 0.11357588818407703),\n",
      " (31, 0.08653957006408501),\n",
      " (32, 0.11357588818407703),\n",
      " (33, 0.11357588818407703),\n",
      " (34, 0.052423535006232855),\n",
      " (35, 0.11357588818407703),\n",
      " (36, 0.09651787065515095),\n",
      " (37, 0.0656879787137015)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "773bb541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:16:33.726 INFO    gensim.models.ldamodel: using symmetric alpha at 0.5\n",
      "2022-08-17 10:16:33.726 INFO    gensim.models.ldamodel: using symmetric eta at 0.5\n",
      "2022-08-17 10:16:33.727 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "2022-08-17 10:16:33.729 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 2 topics, 1 passes over the supplied corpus of 101 documents, updating model once every 101 documents, evaluating perplexity every 101 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:16:33.730 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:16:33.831 INFO    gensim.models.ldamodel: -8.711 per-word bound, 419.2 perplexity estimate based on a held-out corpus of 101 documents with 587 words\n",
      "2022-08-17 10:16:33.832 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #101/101\n",
      "2022-08-17 10:16:33.883 INFO    gensim.models.ldamodel: topic #0 (0.500): 0.003*\"target\" + 0.003*\"climat\" + 0.003*\"refer\" + 0.003*\"emiss\" + 0.003*\"articl\" + 0.003*\"agreement\" + 0.003*\"nation\" + 0.002*\"australia\" + 0.002*\"sector\" + 0.002*\"inform\"\n",
      "2022-08-17 10:16:33.883 INFO    gensim.models.ldamodel: topic #1 (0.500): 0.003*\"target\" + 0.003*\"articl\" + 0.002*\"ndc\" + 0.002*\"plan\" + 0.002*\"emiss\" + 0.002*\"climat\" + 0.002*\"adapt\" + 0.002*\"energi\" + 0.002*\"agreement\" + 0.002*\"brazil\"\n",
      "2022-08-17 10:16:33.884 INFO    gensim.models.ldamodel: topic diff=0.679105, rho=1.000000\n",
      "2022-08-17 10:16:33.885 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=1152, num_topics=2, decay=0.5, chunksize=2000) in 0.16s', 'datetime': '2022-08-17T10:16:33.885240', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:16:33.886 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:16:40.052 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "2022-08-17 10:16:40.064 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 101 virtual documents\n",
      "2022-08-17 10:16:40.113 INFO    gensim.models.ldamodel: using symmetric alpha at 0.3333333333333333\n",
      "2022-08-17 10:16:40.119 INFO    gensim.models.ldamodel: using symmetric eta at 0.3333333333333333\n",
      "2022-08-17 10:16:40.121 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "2022-08-17 10:16:40.122 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 3 topics, 1 passes over the supplied corpus of 101 documents, updating model once every 101 documents, evaluating perplexity every 101 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:16:40.122 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:16:40.204 INFO    gensim.models.ldamodel: -10.341 per-word bound, 1297.2 perplexity estimate based on a held-out corpus of 101 documents with 587 words\n",
      "2022-08-17 10:16:40.204 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #101/101\n",
      "2022-08-17 10:16:40.248 INFO    gensim.models.ldamodel: topic #0 (0.333): 0.003*\"refer\" + 0.003*\"account\" + 0.003*\"agreement\" + 0.003*\"emiss\" + 0.003*\"applic\" + 0.003*\"parti\" + 0.003*\"target\" + 0.003*\"inform\" + 0.003*\"australia\" + 0.003*\"pari\"\n",
      "2022-08-17 10:16:40.251 INFO    gensim.models.ldamodel: topic #1 (0.333): 0.003*\"european\" + 0.003*\"energi\" + 0.002*\"ndc\" + 0.002*\"institut\" + 0.002*\"plan\" + 0.002*\"brazilian\" + 0.002*\"brazil\" + 0.002*\"emiss\" + 0.002*\"climat\" + 0.002*\"adapt\"\n",
      "2022-08-17 10:16:40.251 INFO    gensim.models.ldamodel: topic #2 (0.333): 0.004*\"articl\" + 0.003*\"target\" + 0.003*\"adapt\" + 0.003*\"paragraph\" + 0.003*\"contribut\" + 0.003*\"climat\" + 0.003*\"plan\" + 0.002*\"pari\" + 0.002*\"agreement\" + 0.002*\"achiev\"\n",
      "2022-08-17 10:16:40.252 INFO    gensim.models.ldamodel: topic diff=1.211218, rho=1.000000\n",
      "2022-08-17 10:16:40.252 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=1152, num_topics=3, decay=0.5, chunksize=2000) in 0.13s', 'datetime': '2022-08-17T10:16:40.252720', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:16:40.254 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:16:46.356 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "2022-08-17 10:16:46.366 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 101 virtual documents\n",
      "2022-08-17 10:16:46.447 INFO    gensim.models.ldamodel: using symmetric alpha at 0.25\n",
      "2022-08-17 10:16:46.447 INFO    gensim.models.ldamodel: using symmetric eta at 0.25\n",
      "2022-08-17 10:16:46.455 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "2022-08-17 10:16:46.456 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 4 topics, 1 passes over the supplied corpus of 101 documents, updating model once every 101 documents, evaluating perplexity every 101 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:16:46.457 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:16:46.530 INFO    gensim.models.ldamodel: -12.334 per-word bound, 5162.6 perplexity estimate based on a held-out corpus of 101 documents with 587 words\n",
      "2022-08-17 10:16:46.531 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #101/101\n",
      "2022-08-17 10:16:46.576 INFO    gensim.models.ldamodel: topic #0 (0.250): 0.004*\"emiss\" + 0.004*\"european\" + 0.004*\"account\" + 0.003*\"methodolog\" + 0.003*\"assumpt\" + 0.003*\"remov\" + 0.003*\"refer\" + 0.003*\"polici\" + 0.003*\"approach\" + 0.003*\"regul\"\n",
      "2022-08-17 10:16:46.577 INFO    gensim.models.ldamodel: topic #1 (0.250): 0.003*\"energi\" + 0.002*\"et\" + 0.002*\"brazil\" + 0.002*\"adapt\" + 0.002*\"emiss\" + 0.002*\"approach\" + 0.002*\"reduct\" + 0.002*\"articl\" + 0.002*\"european\" + 0.002*\"target\"\n",
      "2022-08-17 10:16:46.578 INFO    gensim.models.ldamodel: topic #2 (0.250): 0.005*\"articl\" + 0.004*\"paragraph\" + 0.004*\"target\" + 0.003*\"agreement\" + 0.003*\"pari\" + 0.003*\"enhanc\" + 0.003*\"consid\" + 0.003*\"contribut\" + 0.003*\"achiev\" + 0.002*\"reduct\"\n",
      "2022-08-17 10:16:46.579 INFO    gensim.models.ldamodel: topic #3 (0.250): 0.003*\"australia\" + 0.003*\"climat\" + 0.003*\"agreement\" + 0.003*\"articl\" + 0.003*\"applic\" + 0.003*\"transpar\" + 0.003*\"inform\" + 0.003*\"updat\" + 0.003*\"parti\" + 0.003*\"pari\"\n",
      "2022-08-17 10:16:46.580 INFO    gensim.models.ldamodel: topic diff=1.823376, rho=1.000000\n",
      "2022-08-17 10:16:46.581 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=1152, num_topics=4, decay=0.5, chunksize=2000) in 0.13s', 'datetime': '2022-08-17T10:16:46.581822', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:16:46.583 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:16:52.560 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "2022-08-17 10:16:52.573 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 101 virtual documents\n",
      "2022-08-17 10:16:52.673 INFO    gensim.models.ldamodel: using symmetric alpha at 0.2\n",
      "2022-08-17 10:16:52.674 INFO    gensim.models.ldamodel: using symmetric eta at 0.2\n",
      "2022-08-17 10:16:52.674 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "2022-08-17 10:16:52.677 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 5 topics, 1 passes over the supplied corpus of 101 documents, updating model once every 101 documents, evaluating perplexity every 101 documents, iterating 50x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:16:52.677 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:16:52.740 INFO    gensim.models.ldamodel: -14.667 per-word bound, 26005.5 perplexity estimate based on a held-out corpus of 101 documents with 587 words\n",
      "2022-08-17 10:16:52.748 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #101/101\n",
      "2022-08-17 10:16:52.774 INFO    gensim.models.ldamodel: topic #0 (0.200): 0.005*\"refer\" + 0.004*\"applic\" + 0.004*\"account\" + 0.003*\"remov\" + 0.003*\"methodolog\" + 0.003*\"emiss\" + 0.003*\"target\" + 0.003*\"assumpt\" + 0.003*\"agreement\" + 0.003*\"approach\"\n",
      "2022-08-17 10:16:52.782 INFO    gensim.models.ldamodel: topic #1 (0.200): 0.003*\"energi\" + 0.003*\"european\" + 0.002*\"state\" + 0.002*\"member\" + 0.002*\"emiss\" + 0.002*\"institut\" + 0.002*\"chang\" + 0.002*\"climat\" + 0.002*\"water\" + 0.002*\"green\"\n",
      "2022-08-17 10:16:52.783 INFO    gensim.models.ldamodel: topic #2 (0.200): 0.005*\"articl\" + 0.004*\"paragraph\" + 0.004*\"target\" + 0.003*\"polici\" + 0.003*\"forest\" + 0.003*\"address\" + 0.003*\"pari\" + 0.003*\"contribut\" + 0.003*\"goal\" + 0.003*\"object\"\n",
      "2022-08-17 10:16:52.784 INFO    gensim.models.ldamodel: topic #3 (0.200): 0.004*\"transpar\" + 0.004*\"updat\" + 0.004*\"european\" + 0.004*\"ndc\" + 0.003*\"inform\" + 0.003*\"clariti\" + 0.003*\"australia\" + 0.003*\"submiss\" + 0.003*\"understand\" + 0.003*\"climat\"\n",
      "2022-08-17 10:16:52.784 INFO    gensim.models.ldamodel: topic #4 (0.200): 0.003*\"develop\" + 0.003*\"temperatur\" + 0.003*\"botswana\" + 0.003*\"social\" + 0.003*\"increas\" + 0.003*\"averag\" + 0.003*\"adapt\" + 0.003*\"climat\" + 0.003*\"emiss\" + 0.002*\"reduc\"\n",
      "2022-08-17 10:16:52.785 INFO    gensim.models.ldamodel: topic diff=2.509933, rho=1.000000\n",
      "2022-08-17 10:16:52.786 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=1152, num_topics=5, decay=0.5, chunksize=2000) in 0.11s', 'datetime': '2022-08-17T10:16:52.786416', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:16:52.787 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:16:58.792 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "2022-08-17 10:16:58.808 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 101 virtual documents\n",
      "2022-08-17 10:16:58.989 INFO    gensim.models.ldamodel: using symmetric alpha at 0.16666666666666666\n",
      "2022-08-17 10:16:58.992 INFO    gensim.models.ldamodel: using symmetric eta at 0.16666666666666666\n",
      "2022-08-17 10:16:58.993 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "2022-08-17 10:16:58.995 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 6 topics, 1 passes over the supplied corpus of 101 documents, updating model once every 101 documents, evaluating perplexity every 101 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:16:58.995 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:16:59.060 INFO    gensim.models.ldamodel: -17.293 per-word bound, 160566.6 perplexity estimate based on a held-out corpus of 101 documents with 587 words\n",
      "2022-08-17 10:16:59.067 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #101/101\n",
      "2022-08-17 10:16:59.090 INFO    gensim.models.ldamodel: topic #5 (0.167): 0.004*\"approach\" + 0.003*\"ipcc\" + 0.003*\"climat\" + 0.003*\"global\" + 0.003*\"botswana\" + 0.003*\"attribut\" + 0.003*\"applic\" + 0.003*\"methodolog\" + 0.003*\"licenc\" + 0.003*\"temperatur\"\n",
      "2022-08-17 10:16:59.098 INFO    gensim.models.ldamodel: topic #3 (0.167): 0.004*\"ndc\" + 0.004*\"updat\" + 0.004*\"time\" + 0.003*\"agreement\" + 0.003*\"pari\" + 0.003*\"inform\" + 0.003*\"inventori\" + 0.003*\"transpar\" + 0.003*\"enhanc\" + 0.003*\"refer\"\n",
      "2022-08-17 10:16:59.099 INFO    gensim.models.ldamodel: topic #2 (0.167): 0.006*\"articl\" + 0.005*\"paragraph\" + 0.004*\"energi\" + 0.004*\"target\" + 0.004*\"adapt\" + 0.004*\"plan\" + 0.004*\"contribut\" + 0.004*\"address\" + 0.003*\"pari\" + 0.003*\"agreement\"\n",
      "2022-08-17 10:16:59.100 INFO    gensim.models.ldamodel: topic #0 (0.167): 0.004*\"refer\" + 0.004*\"polici\" + 0.004*\"australia\" + 0.003*\"brazilian\" + 0.003*\"assumpt\" + 0.003*\"emiss\" + 0.003*\"european\" + 0.003*\"target\" + 0.003*\"methodolog\" + 0.003*\"account\"\n",
      "2022-08-17 10:16:59.100 INFO    gensim.models.ldamodel: topic #4 (0.167): 0.003*\"develop\" + 0.003*\"agreement\" + 0.003*\"australia\" + 0.003*\"polici\" + 0.003*\"indigen\" + 0.003*\"articl\" + 0.003*\"light\" + 0.003*\"plan\" + 0.003*\"pari\" + 0.002*\"parti\"\n",
      "2022-08-17 10:16:59.101 INFO    gensim.models.ldamodel: topic diff=3.215774, rho=1.000000\n",
      "2022-08-17 10:16:59.102 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=1152, num_topics=6, decay=0.5, chunksize=2000) in 0.11s', 'datetime': '2022-08-17T10:16:59.102545', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:16:59.105 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:17:05.047 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "2022-08-17 10:17:05.072 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 101 virtual documents\n",
      "2022-08-17 10:17:05.236 INFO    gensim.models.ldamodel: using symmetric alpha at 0.14285714285714285\n",
      "2022-08-17 10:17:05.250 INFO    gensim.models.ldamodel: using symmetric eta at 0.14285714285714285\n",
      "2022-08-17 10:17:05.251 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "2022-08-17 10:17:05.253 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 7 topics, 1 passes over the supplied corpus of 101 documents, updating model once every 101 documents, evaluating perplexity every 101 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:17:05.254 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:17:05.303 INFO    gensim.models.ldamodel: -20.179 per-word bound, 1186933.5 perplexity estimate based on a held-out corpus of 101 documents with 587 words\n",
      "2022-08-17 10:17:05.318 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #101/101\n",
      "2022-08-17 10:17:05.353 INFO    gensim.models.ldamodel: topic #6 (0.143): 0.004*\"articl\" + 0.003*\"ndc\" + 0.003*\"adapt\" + 0.003*\"provid\" + 0.003*\"paragraph\" + 0.003*\"et\" + 0.003*\"european\" + 0.003*\"act\" + 0.003*\"prioriti\" + 0.003*\"member\"\n",
      "2022-08-17 10:17:05.358 INFO    gensim.models.ldamodel: topic #4 (0.143): 0.004*\"climat\" + 0.003*\"polici\" + 0.003*\"emiss\" + 0.003*\"public\" + 0.003*\"develop\" + 0.003*\"target\" + 0.003*\"reduct\" + 0.003*\"nation\" + 0.003*\"botswana\" + 0.003*\"methodolog\"\n",
      "2022-08-17 10:17:05.359 INFO    gensim.models.ldamodel: topic #5 (0.143): 0.004*\"member\" + 0.004*\"state\" + 0.003*\"european\" + 0.003*\"ipcc\" + 0.003*\"subsequ\" + 0.003*\"updat\" + 0.003*\"approach\" + 0.003*\"inform\" + 0.003*\"brazilian\" + 0.003*\"valu\"\n",
      "2022-08-17 10:17:05.360 INFO    gensim.models.ldamodel: topic #2 (0.143): 0.006*\"articl\" + 0.005*\"paragraph\" + 0.004*\"agreement\" + 0.004*\"contribut\" + 0.004*\"pari\" + 0.004*\"individu\" + 0.004*\"refer\" + 0.003*\"determin\" + 0.003*\"account\" + 0.003*\"transpar\"\n",
      "2022-08-17 10:17:05.362 INFO    gensim.models.ldamodel: topic #0 (0.143): 0.004*\"refer\" + 0.004*\"adapt\" + 0.004*\"plan\" + 0.004*\"climat\" + 0.003*\"brazil\" + 0.003*\"chang\" + 0.003*\"year\" + 0.003*\"effort\" + 0.003*\"unit\" + 0.003*\"resili\"\n",
      "2022-08-17 10:17:05.363 INFO    gensim.models.ldamodel: topic diff=3.934268, rho=1.000000\n",
      "2022-08-17 10:17:05.364 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=1152, num_topics=7, decay=0.5, chunksize=2000) in 0.11s', 'datetime': '2022-08-17T10:17:05.364471', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:17:05.367 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:17:11.367 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "2022-08-17 10:17:11.384 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 101 virtual documents\n",
      "2022-08-17 10:17:11.567 INFO    gensim.models.ldamodel: using symmetric alpha at 0.125\n",
      "2022-08-17 10:17:11.574 INFO    gensim.models.ldamodel: using symmetric eta at 0.125\n",
      "2022-08-17 10:17:11.575 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "2022-08-17 10:17:11.576 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 8 topics, 1 passes over the supplied corpus of 101 documents, updating model once every 101 documents, evaluating perplexity every 101 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:17:11.577 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:17:11.634 INFO    gensim.models.ldamodel: -23.297 per-word bound, 10304068.5 perplexity estimate based on a held-out corpus of 101 documents with 587 words\n",
      "2022-08-17 10:17:11.643 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #101/101\n",
      "2022-08-17 10:17:11.667 INFO    gensim.models.ldamodel: topic #1 (0.125): 0.005*\"individu\" + 0.004*\"level\" + 0.004*\"temperatur\" + 0.003*\"et\" + 0.003*\"increas\" + 0.003*\"energi\" + 0.003*\"need\" + 0.003*\"respect\" + 0.003*\"histor\" + 0.003*\"target\"\n",
      "2022-08-17 10:17:11.678 INFO    gensim.models.ldamodel: topic #5 (0.125): 0.004*\"articl\" + 0.004*\"paragraph\" + 0.004*\"australia\" + 0.003*\"level\" + 0.003*\"target\" + 0.003*\"fgase\" + 0.003*\"increas\" + 0.003*\"energi\" + 0.003*\"new\" + 0.003*\"emiss\"\n",
      "2022-08-17 10:17:11.679 INFO    gensim.models.ldamodel: topic #4 (0.125): 0.003*\"approach\" + 0.003*\"enhanc\" + 0.003*\"temperatur\" + 0.003*\"global\" + 0.003*\"ipcc\" + 0.003*\"subject\" + 0.003*\"arrang\" + 0.003*\"brazilian\" + 0.003*\"object\" + 0.003*\"growth\"\n",
      "2022-08-17 10:17:11.680 INFO    gensim.models.ldamodel: topic #0 (0.125): 0.004*\"applic\" + 0.004*\"account\" + 0.004*\"methodolog\" + 0.004*\"agreement\" + 0.004*\"brazil\" + 0.004*\"climat\" + 0.004*\"plan\" + 0.003*\"pari\" + 0.003*\"remov\" + 0.003*\"assumpt\"\n",
      "2022-08-17 10:17:11.681 INFO    gensim.models.ldamodel: topic #6 (0.125): 0.004*\"refer\" + 0.004*\"polici\" + 0.004*\"strategi\" + 0.003*\"review\" + 0.003*\"except\" + 0.003*\"relev\" + 0.003*\"plan\" + 0.003*\"ndc\" + 0.003*\"ictu\" + 0.003*\"adapt\"\n",
      "2022-08-17 10:17:11.682 INFO    gensim.models.ldamodel: topic diff=4.726222, rho=1.000000\n",
      "2022-08-17 10:17:11.683 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=1152, num_topics=8, decay=0.5, chunksize=2000) in 0.11s', 'datetime': '2022-08-17T10:17:11.683915', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:17:11.686 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:17:17.684 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "2022-08-17 10:17:17.714 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 101 virtual documents\n",
      "2022-08-17 10:17:17.919 INFO    gensim.models.ldamodel: using symmetric alpha at 0.1111111111111111\n",
      "2022-08-17 10:17:17.919 INFO    gensim.models.ldamodel: using symmetric eta at 0.1111111111111111\n",
      "2022-08-17 10:17:17.920 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "2022-08-17 10:17:17.922 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 9 topics, 1 passes over the supplied corpus of 101 documents, updating model once every 101 documents, evaluating perplexity every 101 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:17:17.923 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:17:17.985 INFO    gensim.models.ldamodel: -26.616 per-word bound, 102834058.8 perplexity estimate based on a held-out corpus of 101 documents with 587 words\n",
      "2022-08-17 10:17:17.994 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #101/101\n",
      "2022-08-17 10:17:18.024 INFO    gensim.models.ldamodel: topic #2 (0.111): 0.004*\"polici\" + 0.004*\"direct\" + 0.003*\"tonn\" + 0.003*\"ictu\" + 0.003*\"forc\" + 0.003*\"set\" + 0.003*\"ipcc\" + 0.003*\"singleyear\" + 0.003*\"target\" + 0.003*\"valu\"\n",
      "2022-08-17 10:17:18.025 INFO    gensim.models.ldamodel: topic #6 (0.111): 0.005*\"target\" + 0.004*\"strategi\" + 0.004*\"reduc\" + 0.004*\"paragraph\" + 0.003*\"reduct\" + 0.003*\"licenc\" + 0.003*\"polici\" + 0.003*\"plan\" + 0.003*\"botswana\" + 0.003*\"combin\"\n",
      "2022-08-17 10:17:18.026 INFO    gensim.models.ldamodel: topic #5 (0.111): 0.005*\"submiss\" + 0.004*\"updat\" + 0.004*\"australia\" + 0.004*\"european\" + 0.004*\"applic\" + 0.004*\"temperatur\" + 0.004*\"provid\" + 0.003*\"increas\" + 0.003*\"institut\" + 0.003*\"averag\"\n",
      "2022-08-17 10:17:18.026 INFO    gensim.models.ldamodel: topic #8 (0.111): 0.007*\"articl\" + 0.005*\"paragraph\" + 0.005*\"adapt\" + 0.004*\"botswana\" + 0.004*\"contribut\" + 0.004*\"nation\" + 0.004*\"transpar\" + 0.004*\"agreement\" + 0.004*\"pari\" + 0.004*\"determin\"\n",
      "2022-08-17 10:17:18.027 INFO    gensim.models.ldamodel: topic #4 (0.111): 0.004*\"brazilian\" + 0.004*\"subject\" + 0.004*\"year\" + 0.004*\"energi\" + 0.004*\"light\" + 0.003*\"forest\" + 0.003*\"develop\" + 0.003*\"govern\" + 0.003*\"plan\" + 0.003*\"public\"\n",
      "2022-08-17 10:17:18.028 INFO    gensim.models.ldamodel: topic diff=5.548827, rho=1.000000\n",
      "2022-08-17 10:17:18.029 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=1152, num_topics=9, decay=0.5, chunksize=2000) in 0.11s', 'datetime': '2022-08-17T10:17:18.029965', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:17:18.032 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:17:24.869 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "2022-08-17 10:17:24.898 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 101 virtual documents\n",
      "2022-08-17 10:17:25.204 INFO    gensim.models.ldamodel: using symmetric alpha at 0.1\n",
      "2022-08-17 10:17:25.204 INFO    gensim.models.ldamodel: using symmetric eta at 0.1\n",
      "2022-08-17 10:17:25.206 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "2022-08-17 10:17:25.208 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 101 documents, updating model once every 101 documents, evaluating perplexity every 101 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:17:25.209 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:17:25.275 INFO    gensim.models.ldamodel: -30.131 per-word bound, 1175807028.7 perplexity estimate based on a held-out corpus of 101 documents with 587 words\n",
      "2022-08-17 10:17:25.276 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #101/101\n",
      "2022-08-17 10:17:25.308 INFO    gensim.models.ldamodel: topic #0 (0.100): 0.005*\"direct\" + 0.005*\"target\" + 0.005*\"emiss\" + 0.004*\"account\" + 0.004*\"plan\" + 0.004*\"level\" + 0.004*\"regul\" + 0.004*\"individu\" + 0.004*\"polici\" + 0.004*\"land\"\n",
      "2022-08-17 10:17:25.309 INFO    gensim.models.ldamodel: topic #9 (0.100): 0.004*\"valu\" + 0.004*\"address\" + 0.003*\"paragraph\" + 0.003*\"updat\" + 0.003*\"parti\" + 0.003*\"articl\" + 0.003*\"pari\" + 0.003*\"describ\" + 0.003*\"ratif\" + 0.003*\"timefram\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:17:25.310 INFO    gensim.models.ldamodel: topic #3 (0.100): 0.005*\"agreement\" + 0.004*\"articl\" + 0.004*\"joint\" + 0.004*\"pari\" + 0.004*\"climat\" + 0.004*\"australia\" + 0.004*\"applic\" + 0.004*\"transpar\" + 0.004*\"transit\" + 0.004*\"econom\"\n",
      "2022-08-17 10:17:25.310 INFO    gensim.models.ldamodel: topic #8 (0.100): 0.004*\"botswana\" + 0.004*\"period\" + 0.004*\"combin\" + 0.004*\"place\" + 0.003*\"energi\" + 0.003*\"frame\" + 0.003*\"intend\" + 0.003*\"achiev\" + 0.003*\"recoveri\" + 0.003*\"refer\"\n",
      "2022-08-17 10:17:25.311 INFO    gensim.models.ldamodel: topic #4 (0.100): 0.004*\"light\" + 0.004*\"subject\" + 0.004*\"develop\" + 0.004*\"inform\" + 0.004*\"temperatur\" + 0.004*\"approach\" + 0.003*\"brazil\" + 0.003*\"brazilian\" + 0.003*\"plan\" + 0.003*\"climat\"\n",
      "2022-08-17 10:17:25.312 INFO    gensim.models.ldamodel: topic diff=6.390325, rho=1.000000\n",
      "2022-08-17 10:17:25.313 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=1152, num_topics=10, decay=0.5, chunksize=2000) in 0.10s', 'datetime': '2022-08-17T10:17:25.313144', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:17:25.316 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:17:31.635 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "2022-08-17 10:17:31.661 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 101 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coherence score is highest (0.38) with 4 topics.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import numpy as np \n",
    "\n",
    "best_num = float('NaN')\n",
    "best_score = 0\n",
    "\n",
    "# compute the coherence scores for each number of topics\n",
    "for i in range(2,11):\n",
    "    \n",
    "    # create lda model with i topics\n",
    "    lda = LdaModel(corpus=corpus_tfidf, num_topics=i, id2word=dictionary, random_state=42)\n",
    "    \n",
    "    # obtain the coherence score\n",
    "    coherence_model = CoherenceModel(model=lda, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = np.round(coherence_model.get_coherence(),2)\n",
    "    if coherence_score > best_score:\n",
    "        best_num = i\n",
    "        best_score = coherence_score\n",
    "\n",
    "print(f'The coherence score is highest ({best_score}) with {best_num} topics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1871436c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:28:14.945 INFO    gensim.models.ldamodel: using symmetric alpha at 0.25\n",
      "2022-08-17 10:28:14.946 INFO    gensim.models.ldamodel: using symmetric eta at 0.25\n",
      "2022-08-17 10:28:14.946 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "2022-08-17 10:28:14.948 INFO    gensim.models.ldamulticore: running online LDA training, 4 topics, 2 passes over the supplied corpus of 101 documents, updating every 8000 documents, evaluating every ~101 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:28:14.949 WARNING gensim.models.ldamulticore: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:28:14.952 INFO    gensim.models.ldamulticore: training LDA model using 4 processes\n",
      "2022-08-17 10:28:15.439 INFO    gensim.models.ldamulticore: PROGRESS: pass 0, dispatched chunk #0 = documents up to #101/101, outstanding queue size 1\n",
      "2022-08-17 10:28:17.529 INFO    gensim.models.ldamodel: topic #0 (0.250): 0.004*\"australia\" + 0.004*\"energi\" + 0.004*\"polici\" + 0.003*\"account\" + 0.003*\"climat\" + 0.003*\"methodolog\" + 0.003*\"target\" + 0.003*\"articl\" + 0.003*\"contribut\" + 0.003*\"report\"\n",
      "2022-08-17 10:28:17.531 INFO    gensim.models.ldamodel: topic #1 (0.250): 0.004*\"paragraph\" + 0.004*\"articl\" + 0.004*\"agreement\" + 0.003*\"pari\" + 0.003*\"refer\" + 0.003*\"parti\" + 0.003*\"target\" + 0.003*\"brazil\" + 0.003*\"applic\" + 0.003*\"increas\"\n",
      "2022-08-17 10:28:17.532 INFO    gensim.models.ldamodel: topic #2 (0.250): 0.003*\"ndc\" + 0.003*\"adapt\" + 0.003*\"european\" + 0.003*\"approach\" + 0.003*\"account\" + 0.002*\"reduct\" + 0.002*\"applic\" + 0.002*\"member\" + 0.002*\"use\" + 0.002*\"nation\"\n",
      "2022-08-17 10:28:17.533 INFO    gensim.models.ldamodel: topic #3 (0.250): 0.003*\"transpar\" + 0.003*\"target\" + 0.003*\"clariti\" + 0.003*\"climat\" + 0.003*\"institut\" + 0.003*\"emiss\" + 0.003*\"understand\" + 0.002*\"expenditur\" + 0.002*\"level\" + 0.002*\"global\"\n",
      "2022-08-17 10:28:17.534 INFO    gensim.models.ldamodel: topic diff=1.826803, rho=1.000000\n",
      "2022-08-17 10:28:17.577 INFO    gensim.models.ldamodel: -8.900 per-word bound, 477.7 perplexity estimate based on a held-out corpus of 101 documents with 587 words\n",
      "2022-08-17 10:28:17.596 INFO    gensim.models.ldamulticore: PROGRESS: pass 1, dispatched chunk #0 = documents up to #101/101, outstanding queue size 1\n",
      "2022-08-17 10:28:17.624 INFO    gensim.models.ldamodel: topic #0 (0.250): 0.004*\"australia\" + 0.004*\"energi\" + 0.004*\"polici\" + 0.003*\"account\" + 0.003*\"climat\" + 0.003*\"methodolog\" + 0.003*\"target\" + 0.003*\"remov\" + 0.003*\"articl\" + 0.003*\"contribut\"\n",
      "2022-08-17 10:28:17.625 INFO    gensim.models.ldamodel: topic #1 (0.250): 0.005*\"paragraph\" + 0.004*\"articl\" + 0.004*\"agreement\" + 0.004*\"pari\" + 0.003*\"brazil\" + 0.003*\"refer\" + 0.003*\"parti\" + 0.003*\"target\" + 0.003*\"increas\" + 0.003*\"emiss\"\n",
      "2022-08-17 10:28:17.626 INFO    gensim.models.ldamodel: topic #2 (0.250): 0.003*\"ndc\" + 0.003*\"approach\" + 0.003*\"adapt\" + 0.003*\"european\" + 0.003*\"applic\" + 0.003*\"account\" + 0.002*\"reduct\" + 0.002*\"member\" + 0.002*\"nation\" + 0.002*\"sector\"\n",
      "2022-08-17 10:28:17.626 INFO    gensim.models.ldamodel: topic #3 (0.250): 0.003*\"transpar\" + 0.003*\"target\" + 0.003*\"clariti\" + 0.003*\"climat\" + 0.003*\"institut\" + 0.003*\"expenditur\" + 0.003*\"understand\" + 0.002*\"emiss\" + 0.002*\"follow\" + 0.002*\"submiss\"\n",
      "2022-08-17 10:28:17.627 INFO    gensim.models.ldamodel: topic diff=0.048959, rho=0.698345\n",
      "2022-08-17 10:28:17.665 INFO    gensim.models.ldamodel: -8.878 per-word bound, 470.5 perplexity estimate based on a held-out corpus of 101 documents with 587 words\n",
      "2022-08-17 10:28:17.689 INFO    gensim.utils: LdaMulticore lifecycle event {'msg': 'trained LdaModel(num_terms=1152, num_topics=4, decay=0.5, chunksize=2000) in 2.74s', 'datetime': '2022-08-17T10:28:17.689041', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "#Generating the lda_model with TF-IDF\n",
    "\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=4, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2e85433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:28:17.708 INFO    gensim.models.ldamodel: topic #0 (0.250): 0.004*\"australia\" + 0.004*\"energi\" + 0.004*\"polici\" + 0.003*\"account\" + 0.003*\"climat\" + 0.003*\"methodolog\" + 0.003*\"target\" + 0.003*\"remov\" + 0.003*\"articl\" + 0.003*\"contribut\"\n",
      "2022-08-17 10:28:17.710 INFO    gensim.models.ldamodel: topic #1 (0.250): 0.005*\"paragraph\" + 0.004*\"articl\" + 0.004*\"agreement\" + 0.004*\"pari\" + 0.003*\"brazil\" + 0.003*\"refer\" + 0.003*\"parti\" + 0.003*\"target\" + 0.003*\"increas\" + 0.003*\"emiss\"\n",
      "2022-08-17 10:28:17.711 INFO    gensim.models.ldamodel: topic #2 (0.250): 0.003*\"ndc\" + 0.003*\"approach\" + 0.003*\"adapt\" + 0.003*\"european\" + 0.003*\"applic\" + 0.003*\"account\" + 0.002*\"reduct\" + 0.002*\"member\" + 0.002*\"nation\" + 0.002*\"sector\"\n",
      "2022-08-17 10:28:17.711 INFO    gensim.models.ldamodel: topic #3 (0.250): 0.003*\"transpar\" + 0.003*\"target\" + 0.003*\"clariti\" + 0.003*\"climat\" + 0.003*\"institut\" + 0.003*\"expenditur\" + 0.003*\"understand\" + 0.002*\"emiss\" + 0.002*\"follow\" + 0.002*\"submiss\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.004*\"australia\" + 0.004*\"energi\" + 0.004*\"polici\" + 0.003*\"account\" + 0.003*\"climat\" + 0.003*\"methodolog\" + 0.003*\"target\" + 0.003*\"remov\" + 0.003*\"articl\" + 0.003*\"contribut\"\n",
      "Topic: 1 Word: 0.005*\"paragraph\" + 0.004*\"articl\" + 0.004*\"agreement\" + 0.004*\"pari\" + 0.003*\"brazil\" + 0.003*\"refer\" + 0.003*\"parti\" + 0.003*\"target\" + 0.003*\"increas\" + 0.003*\"emiss\"\n",
      "Topic: 2 Word: 0.003*\"ndc\" + 0.003*\"approach\" + 0.003*\"adapt\" + 0.003*\"european\" + 0.003*\"applic\" + 0.003*\"account\" + 0.002*\"reduct\" + 0.002*\"member\" + 0.002*\"nation\" + 0.002*\"sector\"\n",
      "Topic: 3 Word: 0.003*\"transpar\" + 0.003*\"target\" + 0.003*\"clariti\" + 0.003*\"climat\" + 0.003*\"institut\" + 0.003*\"expenditur\" + 0.003*\"understand\" + 0.002*\"emiss\" + 0.002*\"follow\" + 0.002*\"submiss\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3681884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:29:02.450 INFO    gensim.models.ldamodel: topic #0 (0.250): 0.004*\"australia\" + 0.004*\"energi\" + 0.004*\"polici\" + 0.003*\"account\" + 0.003*\"climat\" + 0.003*\"methodolog\" + 0.003*\"target\" + 0.003*\"remov\" + 0.003*\"articl\" + 0.003*\"contribut\"\n",
      "2022-08-17 10:29:02.452 INFO    gensim.models.ldamodel: topic #1 (0.250): 0.005*\"paragraph\" + 0.004*\"articl\" + 0.004*\"agreement\" + 0.004*\"pari\" + 0.003*\"brazil\" + 0.003*\"refer\" + 0.003*\"parti\" + 0.003*\"target\" + 0.003*\"increas\" + 0.003*\"emiss\"\n",
      "2022-08-17 10:29:02.453 INFO    gensim.models.ldamodel: topic #2 (0.250): 0.003*\"ndc\" + 0.003*\"approach\" + 0.003*\"adapt\" + 0.003*\"european\" + 0.003*\"applic\" + 0.003*\"account\" + 0.002*\"reduct\" + 0.002*\"member\" + 0.002*\"nation\" + 0.002*\"sector\"\n",
      "2022-08-17 10:29:02.454 INFO    gensim.models.ldamodel: topic #3 (0.250): 0.003*\"transpar\" + 0.003*\"target\" + 0.003*\"clariti\" + 0.003*\"climat\" + 0.003*\"institut\" + 0.003*\"expenditur\" + 0.003*\"understand\" + 0.002*\"emiss\" + 0.002*\"follow\" + 0.002*\"submiss\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.004*\"australia\" + 0.004*\"energi\" + 0.004*\"polici\" + 0.003*\"account\" + 0.003*\"climat\" + 0.003*\"methodolog\" + 0.003*\"target\" + 0.003*\"remov\" + 0.003*\"articl\" + 0.003*\"contribut\"')\n",
      "(1, '0.005*\"paragraph\" + 0.004*\"articl\" + 0.004*\"agreement\" + 0.004*\"pari\" + 0.003*\"brazil\" + 0.003*\"refer\" + 0.003*\"parti\" + 0.003*\"target\" + 0.003*\"increas\" + 0.003*\"emiss\"')\n",
      "(2, '0.003*\"ndc\" + 0.003*\"approach\" + 0.003*\"adapt\" + 0.003*\"european\" + 0.003*\"applic\" + 0.003*\"account\" + 0.002*\"reduct\" + 0.002*\"member\" + 0.002*\"nation\" + 0.002*\"sector\"')\n",
      "(3, '0.003*\"transpar\" + 0.003*\"target\" + 0.003*\"clariti\" + 0.003*\"climat\" + 0.003*\"institut\" + 0.003*\"expenditur\" + 0.003*\"understand\" + 0.002*\"emiss\" + 0.002*\"follow\" + 0.002*\"submiss\"')\n"
     ]
    }
   ],
   "source": [
    "# show the words most strongly associated with each topic\n",
    "for topic in lda_model_tfidf.print_topics():\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1cbaec0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9888909459114075\t \n",
      "Topic: 0.005*\"paragraph\" + 0.004*\"articl\" + 0.004*\"agreement\" + 0.004*\"pari\" + 0.003*\"brazil\" + 0.003*\"refer\" + 0.003*\"parti\" + 0.003*\"target\" + 0.003*\"increas\" + 0.003*\"emiss\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[5]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
