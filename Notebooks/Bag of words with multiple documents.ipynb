{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981b8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, sys; sys.path.append('../src')\n",
    "\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import logging\n",
    "import string \n",
    "import pandas as pd\n",
    "#from keybert import KeyBERT\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "import haystack\n",
    "from haystack.utils import convert_files_to_docs, fetch_archive_from_http\n",
    "from haystack.nodes.file_converter import BaseConverter, DocxToTextConverter, PDFToTextConverter, TextConverter\n",
    "from haystack.schema import Document\n",
    "import pdfplumber\n",
    "\n",
    "from haystack.nodes import PreProcessor\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53349185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading txt,pdf and docx files \n",
    "\n",
    "def load_document(\n",
    "    file: str,\n",
    "    encoding: Optional[str] = None,\n",
    "    id_hash_keys: Optional[List[str]] = None,\n",
    ") -> List[Document]:\n",
    "    \n",
    "    \"\"\"\n",
    "    takes docx, txt and pdf files as input and extracts text as well as the filename as metadata. Since haystack\n",
    "    does not take care of all pdf files, pdfplumber is attached to the pipeline in case the pdf extraction fails\n",
    "    via Haystack.\n",
    "\n",
    "    Returns a list of type haystack.schema.Document\n",
    "    \"\"\"\n",
    "\n",
    "    if file.endswith('.pdf'):\n",
    "        converter = PDFToTextConverter(remove_numeric_tables=True)\n",
    "    if file.endswith('.txt'):\n",
    "        converter = TextConverter()\n",
    "    if file.endswith('.docx'):\n",
    "        converter = DocxToTextConverter()\n",
    "\n",
    "    print(converter)\n",
    "    documents = []\n",
    "\n",
    "    logger.info(\"Converting {}\".format(file))\n",
    "    # PDFToTextConverter, TextConverter, and DocxToTextConverter return a list containing a single Document\n",
    "    document = converter.convert(\n",
    "                file_path=file, meta=None, encoding=encoding, id_hash_keys=id_hash_keys\n",
    "            )[0]\n",
    "    text = document.content\n",
    "    documents.append(Document(content=text, meta={\"name\": file}, id_hash_keys=id_hash_keys))\n",
    "    \n",
    "    '''check if text is empty and apply different pdf processor. This can happen whith certain pdf types.'''\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a069b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''basic cleaning - suitable for transformer models'''\n",
    "def basic(s):\n",
    "    \"\"\"\n",
    "    :param s: string to be processed\n",
    "    :return: processed string: see comments in the source code for more info\n",
    "    \"\"\"\n",
    "    # Text Lowercase\n",
    "    s = s.lower() \n",
    "    # Remove punctuation\n",
    "    translator = str.maketrans(' ', ' ', string.punctuation) \n",
    "    s = s.translate(translator)\n",
    "    # Remove URLs\n",
    "    s = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', ' ', s, flags=re.MULTILINE)\n",
    "    s = re.sub(r\"http\\S+\", \" \", s)\n",
    "    # Remove new line characters\n",
    "    s = re.sub('\\n', ' ', s) \n",
    "  \n",
    "    # Remove distracting single quotes\n",
    "    s = re.sub(\"\\'\", \" \", s) \n",
    "    # Remove all remaining numbers and non alphanumeric characters\n",
    "    s = re.sub(r'\\d+', ' ', s) \n",
    "    s = re.sub(r'\\W+', ' ', s)\n",
    "\n",
    "    # define custom words to replace:\n",
    "    #s = re.sub(r'strengthenedstakeholder', 'strengthened stakeholder', s)\n",
    "    \n",
    "    return s.strip()\n",
    "\n",
    " \n",
    "\n",
    "def preprocessing(document):\n",
    "\n",
    "    \"\"\"\n",
    "    takes in haystack document object and splits it into paragraphs and applies simple cleaning.\n",
    "\n",
    "    Returns cleaned list of haystack document objects. One paragraph per object. Also returns pandas df and \n",
    "    list that contains all text joined together.\n",
    "    \"\"\"    \n",
    "\n",
    "    preprocessor = PreProcessor(\n",
    "        clean_empty_lines=True,\n",
    "        clean_whitespace=True,\n",
    "        clean_header_footer=True,\n",
    "        split_by=\"word\",\n",
    "        split_length=120,\n",
    "        split_respect_sentence_boundary=True,\n",
    "        #split_overlap=5\n",
    "    )\n",
    "    for i in document:\n",
    "        docs_processed = preprocessor.process([i])\n",
    "        for item in docs_processed:\n",
    "            item.content = basic(item.content)\n",
    "\n",
    "    print(\"your document has been splitted to\", len(docs_processed), \"paragraphs\")\n",
    "    \n",
    "    # create dataframe of text and list of all text\n",
    "    df = pd.DataFrame(docs_processed)\n",
    "    all_text = \" \".join(df.content.to_list())\n",
    "    par_list = df.content.to_list()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb0bce5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\serva\\Downloads\\NDCs\n",
      "Files in 'C:\\\\Users\\\\serva\\\\Downloads\\\\NDCs': ['Australias NDC June 2022 Update.docx', 'BOTSWANA.docx', 'EU_NDC_Submission_December 2020.docx', 'Updated - First NDC - FINAL - PDF.docx']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir('C:\\\\Users\\\\serva\\\\Downloads\\\\NDCs')\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "\n",
    "cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(\"Files in %r: %s\" % (cwd, files))\n",
    "\n",
    "\n",
    "# Safe directory in a var\n",
    "directory_in_str='C:\\\\Users\\\\serva\\\\Downloads\\\\NDCs'\n",
    "directory = os.fsencode(directory_in_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f03e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - __main__ -  Converting Australias NDC June 2022 Update.docx\n",
      "2022-08-17 10:04:28.839 INFO    __main__: Converting Australias NDC June 2022 Update.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<haystack.nodes.file_converter.docx.DocxToTextConverter object at 0x0000023933D4C6A0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 91.33docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your document has been splitted to 14 paragraphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\serva\\AppData\\Local\\Temp\\ipykernel_3748\\3120851790.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(df)\n",
      "INFO - __main__ -  Converting BOTSWANA.docx\n",
      "2022-08-17 10:04:30.163 INFO    __main__: Converting BOTSWANA.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<haystack.nodes.file_converter.docx.DocxToTextConverter object at 0x000002391F2E4550>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 499.98docs/s]\n",
      "C:\\Users\\serva\\AppData\\Local\\Temp\\ipykernel_3748\\3120851790.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(df)\n",
      "INFO - __main__ -  Converting EU_NDC_Submission_December 2020.docx\n",
      "2022-08-17 10:04:30.214 INFO    __main__: Converting EU_NDC_Submission_December 2020.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your document has been splitted to 9 paragraphs\n",
      "<haystack.nodes.file_converter.docx.DocxToTextConverter object at 0x000002391F2E4550>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                     | 0/1 [00:00<?, ?docs/s]WARNING - haystack.nodes.preprocessor.preprocessor -  One or more sentence found with word count higher than the split length.\n",
      "2022-08-17 10:04:30.255 WARNING haystack.nodes.preprocessor.preprocessor: One or more sentence found with word count higher than the split length.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 199.47docs/s]\n",
      "C:\\Users\\serva\\AppData\\Local\\Temp\\ipykernel_3748\\3120851790.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(df)\n",
      "INFO - __main__ -  Converting Updated - First NDC - FINAL - PDF.docx\n",
      "2022-08-17 10:04:30.288 INFO    __main__: Converting Updated - First NDC - FINAL - PDF.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your document has been splitted to 38 paragraphs\n",
      "<haystack.nodes.file_converter.docx.DocxToTextConverter object at 0x0000023933DA9FD0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                     | 0/1 [00:00<?, ?docs/s]WARNING - haystack.nodes.preprocessor.preprocessor -  One or more sentence found with word count higher than the split length.\n",
      "2022-08-17 10:04:30.304 WARNING haystack.nodes.preprocessor.preprocessor: One or more sentence found with word count higher than the split length.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 152.02docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your document has been splitted to 40 paragraphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\serva\\AppData\\Local\\Temp\\ipykernel_3748\\3120851790.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(df)\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "\"\"\"\"data=pd.DataFrame(columns=[\"content\",\"id\",\"meta\",\"score\",\"embedding\"])\n",
    "df=preprocessing(docs)\n",
    "data1=data.append(df)\n",
    "\n",
    "print(data1)\"\"\"\n",
    "\n",
    "data=pd.DataFrame(columns=[\"content\",\"id\",\"meta\",\"score\",\"embedding\"])\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    docs=load_document(filename)\n",
    "# Using the Preprocessor to create df and text \n",
    "    df = preprocessing(docs)\n",
    "    df[\"Country\"]=filename\n",
    "    data=data.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3de94cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0988822a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>content_type</th>\n",
       "      <th>id</th>\n",
       "      <th>meta</th>\n",
       "      <th>score</th>\n",
       "      <th>embedding</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>federative republic of brazil paris agreement nationally determined contribu...</td>\n",
       "      <td>text</td>\n",
       "      <td>986c33e39b7ad3e80d26bb72742c73d6</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 0}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brazil s updated ndc is broad in scope and includes a consideration of means...</td>\n",
       "      <td>text</td>\n",
       "      <td>76065630447e731a0abdb92a88f14ea2</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 1}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annex information to facilitate clarity transparency and understanding of br...</td>\n",
       "      <td>text</td>\n",
       "      <td>7165ebf036a1aa030c7d5ce64244c15b</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 2}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brazil will adopt the latest national inventory report available and submitt...</td>\n",
       "      <td>text</td>\n",
       "      <td>ac64b0d84efa5f32553ac705532ba503</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 3}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>information on sources of data used in quantifying the reference points nati...</td>\n",
       "      <td>text</td>\n",
       "      <td>d93c9fc0d4b66988120244c50593d662</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 4}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>net emissions from to compared with net emissions from to whether it is a si...</td>\n",
       "      <td>text</td>\n",
       "      <td>f4192996eea8b1b3d7955372b5815946</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 5}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>how the party has taken into consideration paragraph c and d of decision cp ...</td>\n",
       "      <td>text</td>\n",
       "      <td>ecbf8a1825265edc67e394a357c8c9f3</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 6}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>according to the working group i contribution to the sixth assessment report...</td>\n",
       "      <td>text</td>\n",
       "      <td>783a824d994caeffb6b4e40378471545</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 7}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adaptation actions implemented in the context of this ndc will aim at reduci...</td>\n",
       "      <td>text</td>\n",
       "      <td>87727313fe09b33ffe8f651608b87c50</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 8}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>adaptation policies will be based on the best available science regarding cl...</td>\n",
       "      <td>text</td>\n",
       "      <td>3a502ab088e2c33f7ce088babee719a</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 9}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              Text  \\\n",
       "0  federative republic of brazil paris agreement nationally determined contribu...   \n",
       "1  brazil s updated ndc is broad in scope and includes a consideration of means...   \n",
       "2  annex information to facilitate clarity transparency and understanding of br...   \n",
       "3  brazil will adopt the latest national inventory report available and submitt...   \n",
       "4  information on sources of data used in quantifying the reference points nati...   \n",
       "5  net emissions from to compared with net emissions from to whether it is a si...   \n",
       "6  how the party has taken into consideration paragraph c and d of decision cp ...   \n",
       "7  according to the working group i contribution to the sixth assessment report...   \n",
       "8  adaptation actions implemented in the context of this ndc will aim at reduci...   \n",
       "9  adaptation policies will be based on the best available science regarding cl...   \n",
       "\n",
       "  content_type                                id  \\\n",
       "0         text  986c33e39b7ad3e80d26bb72742c73d6   \n",
       "1         text  76065630447e731a0abdb92a88f14ea2   \n",
       "2         text  7165ebf036a1aa030c7d5ce64244c15b   \n",
       "3         text  ac64b0d84efa5f32553ac705532ba503   \n",
       "4         text  d93c9fc0d4b66988120244c50593d662   \n",
       "5         text  f4192996eea8b1b3d7955372b5815946   \n",
       "6         text  ecbf8a1825265edc67e394a357c8c9f3   \n",
       "7         text  783a824d994caeffb6b4e40378471545   \n",
       "8         text  87727313fe09b33ffe8f651608b87c50   \n",
       "9         text   3a502ab088e2c33f7ce088babee719a   \n",
       "\n",
       "                                                                 meta score  \\\n",
       "0  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 0}  None   \n",
       "1  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 1}  None   \n",
       "2  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 2}  None   \n",
       "3  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 3}  None   \n",
       "4  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 4}  None   \n",
       "5  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 5}  None   \n",
       "6  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 6}  None   \n",
       "7  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 7}  None   \n",
       "8  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 8}  None   \n",
       "9  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 9}  None   \n",
       "\n",
       "  embedding                                 Country  \n",
       "0      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "1      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "2      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "3      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "4      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "5      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "6      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "7      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "8      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "9      None  Updated - First NDC - FINAL - PDF.docx  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns \n",
    "\n",
    "data=df.rename(columns = {'content':'Text'})\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "847f4653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>content_type</th>\n",
       "      <th>id</th>\n",
       "      <th>meta</th>\n",
       "      <th>score</th>\n",
       "      <th>embedding</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>federative republic of brazil paris agreement nationally determined contribu...</td>\n",
       "      <td>text</td>\n",
       "      <td>986c33e39b7ad3e80d26bb72742c73d6</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 0}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brazil s updated ndc is broad in scope and includes a consideration of means...</td>\n",
       "      <td>text</td>\n",
       "      <td>76065630447e731a0abdb92a88f14ea2</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 1}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annex information to facilitate clarity transparency and understanding of br...</td>\n",
       "      <td>text</td>\n",
       "      <td>7165ebf036a1aa030c7d5ce64244c15b</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 2}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brazil will adopt the latest national inventory report available and submitt...</td>\n",
       "      <td>text</td>\n",
       "      <td>ac64b0d84efa5f32553ac705532ba503</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 3}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>information on sources of data used in quantifying the reference points nati...</td>\n",
       "      <td>text</td>\n",
       "      <td>d93c9fc0d4b66988120244c50593d662</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 4}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>net emissions from to compared with net emissions from to whether it is a si...</td>\n",
       "      <td>text</td>\n",
       "      <td>f4192996eea8b1b3d7955372b5815946</td>\n",
       "      <td>{'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 5}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Updated - First NDC - FINAL - PDF.docx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              text  \\\n",
       "0  federative republic of brazil paris agreement nationally determined contribu...   \n",
       "1  brazil s updated ndc is broad in scope and includes a consideration of means...   \n",
       "2  annex information to facilitate clarity transparency and understanding of br...   \n",
       "3  brazil will adopt the latest national inventory report available and submitt...   \n",
       "4  information on sources of data used in quantifying the reference points nati...   \n",
       "5  net emissions from to compared with net emissions from to whether it is a si...   \n",
       "\n",
       "  content_type                                id  \\\n",
       "0         text  986c33e39b7ad3e80d26bb72742c73d6   \n",
       "1         text  76065630447e731a0abdb92a88f14ea2   \n",
       "2         text  7165ebf036a1aa030c7d5ce64244c15b   \n",
       "3         text  ac64b0d84efa5f32553ac705532ba503   \n",
       "4         text  d93c9fc0d4b66988120244c50593d662   \n",
       "5         text  f4192996eea8b1b3d7955372b5815946   \n",
       "\n",
       "                                                                 meta score  \\\n",
       "0  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 0}  None   \n",
       "1  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 1}  None   \n",
       "2  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 2}  None   \n",
       "3  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 3}  None   \n",
       "4  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 4}  None   \n",
       "5  {'name': 'Updated - First NDC - FINAL - PDF.docx', '_split_id': 5}  None   \n",
       "\n",
       "  embedding                                 country  \n",
       "0      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "1      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "2      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "3      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "4      None  Updated - First NDC - FINAL - PDF.docx  \n",
       "5      None  Updated - First NDC - FINAL - PDF.docx  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = map(str.lower, data.columns)\n",
    "data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7371905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8ddd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    federative republic of brazil paris agreement nationally determined contribu...\n",
       "1    brazil s updated ndc is broad in scope and includes a consideration of means...\n",
       "2    annex information to facilitate clarity transparency and understanding of br...\n",
       "3    brazil will adopt the latest national inventory report available and submitt...\n",
       "4    information on sources of data used in quantifying the reference points nati...\n",
       "5    net emissions from to compared with net emissions from to whether it is a si...\n",
       "6    how the party has taken into consideration paragraph c and d of decision cp ...\n",
       "7    according to the working group i contribution to the sixth assessment report...\n",
       "8    adaptation actions implemented in the context of this ndc will aim at reduci...\n",
       "9    adaptation policies will be based on the best available science regarding cl...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "documents=data[\"text\"]\n",
    "\n",
    "documents.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7e7421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89db13ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0662240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_docs = data['text'].map(preprocess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a64d368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [feder, republ, brazil, pari, agreement, nation, determin, contribut, brasíl...\n",
       "1    [brazil, updat, broad, scope, includ, consider, mean, implement, implement, ...\n",
       "2    [annex, inform, facilit, clariti, transpar, understand, brazil, quantifi, in...\n",
       "3    [brazil, adopt, latest, nation, inventori, report, avail, submit, unfccc, ti...\n",
       "4    [inform, sourc, data, quantifi, refer, point, nation, inventori, anthropogen...\n",
       "5    [emiss, compar, emiss, singleyear, multiyear, target, applic, singleyear, ta...\n",
       "6    [parti, take, consider, paragraph, decis, gas, previous, indic, indc, keep, ...\n",
       "7    [accord, work, group, contribut, sixth, assess, report, ipcc, publish, augus...\n",
       "8    [adapt, action, implement, context, reduc, vulner, term, water, energi, food...\n",
       "9    [adapt, polici, base, best, avail, scienc, climat, chang, nation, circumst, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5e2c5",
   "metadata": {},
   "source": [
    "# Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c254a047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - gensim.corpora.dictionary -  adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-08-17 10:04:35.398 INFO    gensim.corpora.dictionary: adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO - gensim.corpora.dictionary -  built Dictionary(631 unique tokens: ['achiev', 'addit', 'adopt', 'agreement', 'brasília']...) from 40 documents (total 2198 corpus positions)\n",
      "2022-08-17 10:04:35.401 INFO    gensim.corpora.dictionary: built Dictionary(631 unique tokens: ['achiev', 'addit', 'adopt', 'agreement', 'brasília']...) from 40 documents (total 2198 corpus positions)\n",
      "INFO - gensim.utils -  Dictionary lifecycle event {'msg': \"built Dictionary(631 unique tokens: ['achiev', 'addit', 'adopt', 'agreement', 'brasília']...) from 40 documents (total 2198 corpus positions)\", 'datetime': '2022-08-17T10:04:35.402556', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:04:35.402 INFO    gensim.utils: Dictionary lifecycle event {'msg': \"built Dictionary(631 unique tokens: ['achiev', 'addit', 'adopt', 'agreement', 'brasília']...) from 40 documents (total 2198 corpus positions)\", 'datetime': '2022-08-17T10:04:35.402556', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c9feae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 1),\n",
       " (7, 1),\n",
       " (18, 1),\n",
       " (21, 1),\n",
       " (26, 1),\n",
       " (40, 2),\n",
       " (71, 1),\n",
       " (115, 3),\n",
       " (153, 1),\n",
       " (163, 2),\n",
       " (221, 1),\n",
       " (249, 1),\n",
       " (254, 1),\n",
       " (255, 1),\n",
       " (256, 1),\n",
       " (257, 1),\n",
       " (258, 1),\n",
       " (259, 1),\n",
       " (260, 1),\n",
       " (261, 1),\n",
       " (262, 1),\n",
       " (263, 1),\n",
       " (264, 1)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b4f02e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - gensim.models.ldamodel -  using symmetric alpha at 0.5\n",
      "2022-08-17 10:14:07.877 INFO    gensim.models.ldamodel: using symmetric alpha at 0.5\n",
      "INFO - gensim.models.ldamodel -  using symmetric eta at 0.5\n",
      "2022-08-17 10:14:07.879 INFO    gensim.models.ldamodel: using symmetric eta at 0.5\n",
      "INFO - gensim.models.ldamodel -  using serial LDA version on this node\n",
      "2022-08-17 10:14:07.882 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "INFO - gensim.models.ldamodel -  running online (single-pass) LDA training, 2 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:14:07.883 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 2 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING - gensim.models.ldamodel -  too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:14:07.884 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO - gensim.models.ldamodel -  -7.007 per-word bound, 128.6 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "2022-08-17 10:14:07.953 INFO    gensim.models.ldamodel: -7.007 per-word bound, 128.6 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "INFO - gensim.models.ldamodel -  PROGRESS: pass 0, at document #40/40\n",
      "2022-08-17 10:14:07.954 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #40/40\n",
      "INFO - gensim.models.ldamodel -  topic #0 (0.500): 0.015*\"climat\" + 0.014*\"implement\" + 0.013*\"nation\" + 0.012*\"adapt\" + 0.011*\"chang\" + 0.011*\"brazil\" + 0.011*\"plan\" + 0.011*\"includ\" + 0.009*\"emiss\" + 0.009*\"brazilian\"\n",
      "2022-08-17 10:14:07.981 INFO    gensim.models.ldamodel: topic #0 (0.500): 0.015*\"climat\" + 0.014*\"implement\" + 0.013*\"nation\" + 0.012*\"adapt\" + 0.011*\"chang\" + 0.011*\"brazil\" + 0.011*\"plan\" + 0.011*\"includ\" + 0.009*\"emiss\" + 0.009*\"brazilian\"\n",
      "INFO - gensim.models.ldamodel -  topic #1 (0.500): 0.019*\"nation\" + 0.019*\"brazil\" + 0.018*\"contribut\" + 0.016*\"climat\" + 0.015*\"emiss\" + 0.013*\"agreement\" + 0.012*\"brazilian\" + 0.011*\"chang\" + 0.011*\"articl\" + 0.011*\"pari\"\n",
      "2022-08-17 10:14:07.983 INFO    gensim.models.ldamodel: topic #1 (0.500): 0.019*\"nation\" + 0.019*\"brazil\" + 0.018*\"contribut\" + 0.016*\"climat\" + 0.015*\"emiss\" + 0.013*\"agreement\" + 0.012*\"brazilian\" + 0.011*\"chang\" + 0.011*\"articl\" + 0.011*\"pari\"\n",
      "INFO - gensim.models.ldamodel -  topic diff=0.888760, rho=1.000000\n",
      "2022-08-17 10:14:07.985 INFO    gensim.models.ldamodel: topic diff=0.888760, rho=1.000000\n",
      "INFO - gensim.utils -  LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=2, decay=0.5, chunksize=2000) in 0.10s', 'datetime': '2022-08-17T10:14:07.987656', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:14:07.987 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=2, decay=0.5, chunksize=2000) in 0.10s', 'datetime': '2022-08-17T10:14:07.987656', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "INFO - gensim.topic_coherence.probability_estimation -  using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:14:07.989 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "INFO - gensim.topic_coherence.text_analysis -  15 accumulators retrieved from output queue\n",
      "2022-08-17 10:14:14.085 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "INFO - gensim.topic_coherence.text_analysis -  accumulated word occurrence stats for 40 virtual documents\n",
      "2022-08-17 10:14:14.100 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 40 virtual documents\n",
      "INFO - gensim.models.ldamodel -  using symmetric alpha at 0.3333333333333333\n",
      "2022-08-17 10:14:14.148 INFO    gensim.models.ldamodel: using symmetric alpha at 0.3333333333333333\n",
      "INFO - gensim.models.ldamodel -  using symmetric eta at 0.3333333333333333\n",
      "2022-08-17 10:14:14.151 INFO    gensim.models.ldamodel: using symmetric eta at 0.3333333333333333\n",
      "INFO - gensim.models.ldamodel -  using serial LDA version on this node\n",
      "2022-08-17 10:14:14.153 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "INFO - gensim.models.ldamodel -  running online (single-pass) LDA training, 3 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:14:14.155 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 3 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING - gensim.models.ldamodel -  too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:14:14.156 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO - gensim.models.ldamodel -  -7.298 per-word bound, 157.3 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "2022-08-17 10:14:14.210 INFO    gensim.models.ldamodel: -7.298 per-word bound, 157.3 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "INFO - gensim.models.ldamodel -  PROGRESS: pass 0, at document #40/40\n",
      "2022-08-17 10:14:14.211 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #40/40\n",
      "INFO - gensim.models.ldamodel -  topic #0 (0.333): 0.017*\"climat\" + 0.014*\"adapt\" + 0.014*\"nation\" + 0.013*\"implement\" + 0.012*\"chang\" + 0.012*\"plan\" + 0.011*\"includ\" + 0.011*\"brazil\" + 0.009*\"develop\" + 0.009*\"emiss\"\n",
      "2022-08-17 10:14:14.242 INFO    gensim.models.ldamodel: topic #0 (0.333): 0.017*\"climat\" + 0.014*\"adapt\" + 0.014*\"nation\" + 0.013*\"implement\" + 0.012*\"chang\" + 0.012*\"plan\" + 0.011*\"includ\" + 0.011*\"brazil\" + 0.009*\"develop\" + 0.009*\"emiss\"\n",
      "INFO - gensim.models.ldamodel -  topic #1 (0.333): 0.022*\"brazil\" + 0.021*\"nation\" + 0.020*\"contribut\" + 0.017*\"climat\" + 0.016*\"emiss\" + 0.015*\"agreement\" + 0.013*\"articl\" + 0.013*\"pari\" + 0.011*\"determin\" + 0.011*\"parti\"\n",
      "2022-08-17 10:14:14.244 INFO    gensim.models.ldamodel: topic #1 (0.333): 0.022*\"brazil\" + 0.021*\"nation\" + 0.020*\"contribut\" + 0.017*\"climat\" + 0.016*\"emiss\" + 0.015*\"agreement\" + 0.013*\"articl\" + 0.013*\"pari\" + 0.011*\"determin\" + 0.011*\"parti\"\n",
      "INFO - gensim.models.ldamodel -  topic #2 (0.333): 0.016*\"brazilian\" + 0.016*\"implement\" + 0.014*\"nation\" + 0.013*\"climat\" + 0.012*\"chang\" + 0.011*\"emiss\" + 0.010*\"brazil\" + 0.010*\"contribut\" + 0.009*\"plan\" + 0.009*\"includ\"\n",
      "2022-08-17 10:14:14.245 INFO    gensim.models.ldamodel: topic #2 (0.333): 0.016*\"brazilian\" + 0.016*\"implement\" + 0.014*\"nation\" + 0.013*\"climat\" + 0.012*\"chang\" + 0.011*\"emiss\" + 0.010*\"brazil\" + 0.010*\"contribut\" + 0.009*\"plan\" + 0.009*\"includ\"\n",
      "INFO - gensim.models.ldamodel -  topic diff=1.232984, rho=1.000000\n",
      "2022-08-17 10:14:14.246 INFO    gensim.models.ldamodel: topic diff=1.232984, rho=1.000000\n",
      "INFO - gensim.utils -  LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=3, decay=0.5, chunksize=2000) in 0.09s', 'datetime': '2022-08-17T10:14:14.247619', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:14:14.247 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=3, decay=0.5, chunksize=2000) in 0.09s', 'datetime': '2022-08-17T10:14:14.247619', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "INFO - gensim.topic_coherence.probability_estimation -  using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:14:14.249 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "INFO - gensim.topic_coherence.text_analysis -  15 accumulators retrieved from output queue\n",
      "2022-08-17 10:14:20.756 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "INFO - gensim.topic_coherence.text_analysis -  accumulated word occurrence stats for 40 virtual documents\n",
      "2022-08-17 10:14:20.765 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 40 virtual documents\n",
      "INFO - gensim.models.ldamodel -  using symmetric alpha at 0.25\n",
      "2022-08-17 10:14:20.827 INFO    gensim.models.ldamodel: using symmetric alpha at 0.25\n",
      "INFO - gensim.models.ldamodel -  using symmetric eta at 0.25\n",
      "2022-08-17 10:14:20.839 INFO    gensim.models.ldamodel: using symmetric eta at 0.25\n",
      "INFO - gensim.models.ldamodel -  using serial LDA version on this node\n",
      "2022-08-17 10:14:20.842 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "INFO - gensim.models.ldamodel -  running online (single-pass) LDA training, 4 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:14:20.845 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 4 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING - gensim.models.ldamodel -  too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:14:20.846 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO - gensim.models.ldamodel -  -7.626 per-word bound, 197.6 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "2022-08-17 10:14:20.874 INFO    gensim.models.ldamodel: -7.626 per-word bound, 197.6 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "INFO - gensim.models.ldamodel -  PROGRESS: pass 0, at document #40/40\n",
      "2022-08-17 10:14:20.875 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #40/40\n",
      "INFO - gensim.models.ldamodel -  topic #0 (0.250): 0.018*\"nation\" + 0.014*\"adapt\" + 0.013*\"includ\" + 0.013*\"climat\" + 0.012*\"implement\" + 0.012*\"inform\" + 0.011*\"brazil\" + 0.010*\"develop\" + 0.010*\"plan\" + 0.010*\"parti\"\n",
      "2022-08-17 10:14:20.898 INFO    gensim.models.ldamodel: topic #0 (0.250): 0.018*\"nation\" + 0.014*\"adapt\" + 0.013*\"includ\" + 0.013*\"climat\" + 0.012*\"implement\" + 0.012*\"inform\" + 0.011*\"brazil\" + 0.010*\"develop\" + 0.010*\"plan\" + 0.010*\"parti\"\n",
      "INFO - gensim.models.ldamodel -  topic #1 (0.250): 0.023*\"brazil\" + 0.023*\"nation\" + 0.021*\"contribut\" + 0.017*\"emiss\" + 0.016*\"agreement\" + 0.015*\"articl\" + 0.015*\"climat\" + 0.015*\"pari\" + 0.013*\"determin\" + 0.012*\"parti\"\n",
      "2022-08-17 10:14:20.901 INFO    gensim.models.ldamodel: topic #1 (0.250): 0.023*\"brazil\" + 0.023*\"nation\" + 0.021*\"contribut\" + 0.017*\"emiss\" + 0.016*\"agreement\" + 0.015*\"articl\" + 0.015*\"climat\" + 0.015*\"pari\" + 0.013*\"determin\" + 0.012*\"parti\"\n",
      "INFO - gensim.models.ldamodel -  topic #2 (0.250): 0.017*\"brazilian\" + 0.016*\"implement\" + 0.016*\"nation\" + 0.011*\"chang\" + 0.011*\"emiss\" + 0.011*\"brazil\" + 0.010*\"contribut\" + 0.010*\"climat\" + 0.010*\"adapt\" + 0.010*\"target\"\n",
      "2022-08-17 10:14:20.903 INFO    gensim.models.ldamodel: topic #2 (0.250): 0.017*\"brazilian\" + 0.016*\"implement\" + 0.016*\"nation\" + 0.011*\"chang\" + 0.011*\"emiss\" + 0.011*\"brazil\" + 0.010*\"contribut\" + 0.010*\"climat\" + 0.010*\"adapt\" + 0.010*\"target\"\n",
      "INFO - gensim.models.ldamodel -  topic #3 (0.250): 0.027*\"climat\" + 0.019*\"chang\" + 0.016*\"global\" + 0.013*\"plan\" + 0.013*\"brazilian\" + 0.012*\"implement\" + 0.012*\"temperatur\" + 0.012*\"increas\" + 0.009*\"brazil\" + 0.009*\"adapt\"\n",
      "2022-08-17 10:14:20.904 INFO    gensim.models.ldamodel: topic #3 (0.250): 0.027*\"climat\" + 0.019*\"chang\" + 0.016*\"global\" + 0.013*\"plan\" + 0.013*\"brazilian\" + 0.012*\"implement\" + 0.012*\"temperatur\" + 0.012*\"increas\" + 0.009*\"brazil\" + 0.009*\"adapt\"\n",
      "INFO - gensim.models.ldamodel -  topic diff=1.680810, rho=1.000000\n",
      "2022-08-17 10:14:20.905 INFO    gensim.models.ldamodel: topic diff=1.680810, rho=1.000000\n",
      "INFO - gensim.utils -  LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=4, decay=0.5, chunksize=2000) in 0.06s', 'datetime': '2022-08-17T10:14:20.907919', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:14:20.907 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=4, decay=0.5, chunksize=2000) in 0.06s', 'datetime': '2022-08-17T10:14:20.907919', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "INFO - gensim.topic_coherence.probability_estimation -  using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:14:20.909 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "INFO - gensim.topic_coherence.text_analysis -  15 accumulators retrieved from output queue\n",
      "2022-08-17 10:14:27.212 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "INFO - gensim.topic_coherence.text_analysis -  accumulated word occurrence stats for 40 virtual documents\n",
      "2022-08-17 10:14:27.225 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 40 virtual documents\n",
      "INFO - gensim.models.ldamodel -  using symmetric alpha at 0.2\n",
      "2022-08-17 10:14:27.309 INFO    gensim.models.ldamodel: using symmetric alpha at 0.2\n",
      "INFO - gensim.models.ldamodel -  using symmetric eta at 0.2\n",
      "2022-08-17 10:14:27.310 INFO    gensim.models.ldamodel: using symmetric eta at 0.2\n",
      "INFO - gensim.models.ldamodel -  using serial LDA version on this node\n",
      "2022-08-17 10:14:27.312 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "INFO - gensim.models.ldamodel -  running online (single-pass) LDA training, 5 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:14:27.313 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 5 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING - gensim.models.ldamodel -  too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:14:27.314 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO - gensim.models.ldamodel -  -7.993 per-word bound, 254.7 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "2022-08-17 10:14:27.342 INFO    gensim.models.ldamodel: -7.993 per-word bound, 254.7 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - gensim.models.ldamodel -  PROGRESS: pass 0, at document #40/40\n",
      "2022-08-17 10:14:27.348 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #40/40\n",
      "INFO - gensim.models.ldamodel -  topic #0 (0.200): 0.017*\"nation\" + 0.013*\"adapt\" + 0.013*\"implement\" + 0.012*\"includ\" + 0.011*\"brazil\" + 0.010*\"inform\" + 0.010*\"account\" + 0.010*\"develop\" + 0.010*\"plan\" + 0.010*\"polici\"\n",
      "2022-08-17 10:14:27.374 INFO    gensim.models.ldamodel: topic #0 (0.200): 0.017*\"nation\" + 0.013*\"adapt\" + 0.013*\"implement\" + 0.012*\"includ\" + 0.011*\"brazil\" + 0.010*\"inform\" + 0.010*\"account\" + 0.010*\"develop\" + 0.010*\"plan\" + 0.010*\"polici\"\n",
      "INFO - gensim.models.ldamodel -  topic #1 (0.200): 0.025*\"brazil\" + 0.022*\"contribut\" + 0.021*\"nation\" + 0.019*\"agreement\" + 0.018*\"emiss\" + 0.018*\"articl\" + 0.017*\"pari\" + 0.013*\"parti\" + 0.013*\"determin\" + 0.013*\"climat\"\n",
      "2022-08-17 10:14:27.377 INFO    gensim.models.ldamodel: topic #1 (0.200): 0.025*\"brazil\" + 0.022*\"contribut\" + 0.021*\"nation\" + 0.019*\"agreement\" + 0.018*\"emiss\" + 0.018*\"articl\" + 0.017*\"pari\" + 0.013*\"parti\" + 0.013*\"determin\" + 0.013*\"climat\"\n",
      "INFO - gensim.models.ldamodel -  topic #2 (0.200): 0.017*\"implement\" + 0.017*\"brazilian\" + 0.014*\"nation\" + 0.012*\"emiss\" + 0.012*\"target\" + 0.011*\"brazil\" + 0.010*\"adapt\" + 0.010*\"contribut\" + 0.010*\"chang\" + 0.009*\"sector\"\n",
      "2022-08-17 10:14:27.378 INFO    gensim.models.ldamodel: topic #2 (0.200): 0.017*\"implement\" + 0.017*\"brazilian\" + 0.014*\"nation\" + 0.012*\"emiss\" + 0.012*\"target\" + 0.011*\"brazil\" + 0.010*\"adapt\" + 0.010*\"contribut\" + 0.010*\"chang\" + 0.009*\"sector\"\n",
      "INFO - gensim.models.ldamodel -  topic #3 (0.200): 0.025*\"climat\" + 0.018*\"global\" + 0.018*\"chang\" + 0.015*\"brazilian\" + 0.015*\"temperatur\" + 0.014*\"implement\" + 0.014*\"increas\" + 0.011*\"emiss\" + 0.010*\"brazil\" + 0.009*\"anthropogen\"\n",
      "2022-08-17 10:14:27.378 INFO    gensim.models.ldamodel: topic #3 (0.200): 0.025*\"climat\" + 0.018*\"global\" + 0.018*\"chang\" + 0.015*\"brazilian\" + 0.015*\"temperatur\" + 0.014*\"implement\" + 0.014*\"increas\" + 0.011*\"emiss\" + 0.010*\"brazil\" + 0.009*\"anthropogen\"\n",
      "INFO - gensim.models.ldamodel -  topic #4 (0.200): 0.026*\"nation\" + 0.025*\"climat\" + 0.020*\"chang\" + 0.019*\"plan\" + 0.014*\"includ\" + 0.014*\"adapt\" + 0.012*\"contribut\" + 0.010*\"brazil\" + 0.010*\"determin\" + 0.010*\"inform\"\n",
      "2022-08-17 10:14:27.380 INFO    gensim.models.ldamodel: topic #4 (0.200): 0.026*\"nation\" + 0.025*\"climat\" + 0.020*\"chang\" + 0.019*\"plan\" + 0.014*\"includ\" + 0.014*\"adapt\" + 0.012*\"contribut\" + 0.010*\"brazil\" + 0.010*\"determin\" + 0.010*\"inform\"\n",
      "INFO - gensim.models.ldamodel -  topic diff=2.229993, rho=1.000000\n",
      "2022-08-17 10:14:27.381 INFO    gensim.models.ldamodel: topic diff=2.229993, rho=1.000000\n",
      "INFO - gensim.utils -  LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=5, decay=0.5, chunksize=2000) in 0.07s', 'datetime': '2022-08-17T10:14:27.383426', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:14:27.383 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=5, decay=0.5, chunksize=2000) in 0.07s', 'datetime': '2022-08-17T10:14:27.383426', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "INFO - gensim.topic_coherence.probability_estimation -  using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:14:27.386 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "INFO - gensim.topic_coherence.text_analysis -  15 accumulators retrieved from output queue\n",
      "2022-08-17 10:14:34.103 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "INFO - gensim.topic_coherence.text_analysis -  accumulated word occurrence stats for 40 virtual documents\n",
      "2022-08-17 10:14:34.120 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 40 virtual documents\n",
      "INFO - gensim.models.ldamodel -  using symmetric alpha at 0.16666666666666666\n",
      "2022-08-17 10:14:34.223 INFO    gensim.models.ldamodel: using symmetric alpha at 0.16666666666666666\n",
      "INFO - gensim.models.ldamodel -  using symmetric eta at 0.16666666666666666\n",
      "2022-08-17 10:14:34.232 INFO    gensim.models.ldamodel: using symmetric eta at 0.16666666666666666\n",
      "INFO - gensim.models.ldamodel -  using serial LDA version on this node\n",
      "2022-08-17 10:14:34.235 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "INFO - gensim.models.ldamodel -  running online (single-pass) LDA training, 6 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:14:34.237 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 6 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING - gensim.models.ldamodel -  too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:14:34.238 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO - gensim.models.ldamodel -  -8.396 per-word bound, 336.9 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "2022-08-17 10:14:34.289 INFO    gensim.models.ldamodel: -8.396 per-word bound, 336.9 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "INFO - gensim.models.ldamodel -  PROGRESS: pass 0, at document #40/40\n",
      "2022-08-17 10:14:34.291 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #40/40\n",
      "INFO - gensim.models.ldamodel -  topic #1 (0.167): 0.026*\"brazil\" + 0.022*\"contribut\" + 0.020*\"nation\" + 0.019*\"agreement\" + 0.018*\"articl\" + 0.018*\"emiss\" + 0.017*\"pari\" + 0.014*\"climat\" + 0.013*\"determin\" + 0.012*\"parti\"\n",
      "2022-08-17 10:14:34.314 INFO    gensim.models.ldamodel: topic #1 (0.167): 0.026*\"brazil\" + 0.022*\"contribut\" + 0.020*\"nation\" + 0.019*\"agreement\" + 0.018*\"articl\" + 0.018*\"emiss\" + 0.017*\"pari\" + 0.014*\"climat\" + 0.013*\"determin\" + 0.012*\"parti\"\n",
      "INFO - gensim.models.ldamodel -  topic #0 (0.167): 0.015*\"implement\" + 0.013*\"nation\" + 0.013*\"polici\" + 0.012*\"account\" + 0.012*\"adapt\" + 0.012*\"includ\" + 0.011*\"climat\" + 0.010*\"emiss\" + 0.010*\"plan\" + 0.009*\"brazil\"\n",
      "2022-08-17 10:14:34.317 INFO    gensim.models.ldamodel: topic #0 (0.167): 0.015*\"implement\" + 0.013*\"nation\" + 0.013*\"polici\" + 0.012*\"account\" + 0.012*\"adapt\" + 0.012*\"includ\" + 0.011*\"climat\" + 0.010*\"emiss\" + 0.010*\"plan\" + 0.009*\"brazil\"\n",
      "INFO - gensim.models.ldamodel -  topic #2 (0.167): 0.021*\"implement\" + 0.020*\"brazilian\" + 0.012*\"emiss\" + 0.012*\"brazil\" + 0.011*\"nation\" + 0.011*\"contribut\" + 0.010*\"adapt\" + 0.010*\"chang\" + 0.009*\"greenhous\" + 0.009*\"includ\"\n",
      "2022-08-17 10:14:34.319 INFO    gensim.models.ldamodel: topic #2 (0.167): 0.021*\"implement\" + 0.020*\"brazilian\" + 0.012*\"emiss\" + 0.012*\"brazil\" + 0.011*\"nation\" + 0.011*\"contribut\" + 0.010*\"adapt\" + 0.010*\"chang\" + 0.009*\"greenhous\" + 0.009*\"includ\"\n",
      "INFO - gensim.models.ldamodel -  topic #3 (0.167): 0.028*\"climat\" + 0.020*\"global\" + 0.019*\"chang\" + 0.018*\"temperatur\" + 0.016*\"increas\" + 0.014*\"brazilian\" + 0.012*\"implement\" + 0.011*\"emiss\" + 0.011*\"brazil\" + 0.010*\"anthropogen\"\n",
      "2022-08-17 10:14:34.320 INFO    gensim.models.ldamodel: topic #3 (0.167): 0.028*\"climat\" + 0.020*\"global\" + 0.019*\"chang\" + 0.018*\"temperatur\" + 0.016*\"increas\" + 0.014*\"brazilian\" + 0.012*\"implement\" + 0.011*\"emiss\" + 0.011*\"brazil\" + 0.010*\"anthropogen\"\n",
      "INFO - gensim.models.ldamodel -  topic #4 (0.167): 0.027*\"climat\" + 0.022*\"chang\" + 0.021*\"nation\" + 0.017*\"plan\" + 0.015*\"adapt\" + 0.014*\"includ\" + 0.011*\"brazil\" + 0.011*\"contribut\" + 0.010*\"inform\" + 0.010*\"refer\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:14:34.321 INFO    gensim.models.ldamodel: topic #4 (0.167): 0.027*\"climat\" + 0.022*\"chang\" + 0.021*\"nation\" + 0.017*\"plan\" + 0.015*\"adapt\" + 0.014*\"includ\" + 0.011*\"brazil\" + 0.011*\"contribut\" + 0.010*\"inform\" + 0.010*\"refer\"\n",
      "INFO - gensim.models.ldamodel -  topic diff=2.827023, rho=1.000000\n",
      "2022-08-17 10:14:34.323 INFO    gensim.models.ldamodel: topic diff=2.827023, rho=1.000000\n",
      "INFO - gensim.utils -  LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=6, decay=0.5, chunksize=2000) in 0.09s', 'datetime': '2022-08-17T10:14:34.324088', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:14:34.324 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=6, decay=0.5, chunksize=2000) in 0.09s', 'datetime': '2022-08-17T10:14:34.324088', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "INFO - gensim.topic_coherence.probability_estimation -  using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:14:34.327 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "INFO - gensim.topic_coherence.text_analysis -  15 accumulators retrieved from output queue\n",
      "2022-08-17 10:14:40.743 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "INFO - gensim.topic_coherence.text_analysis -  accumulated word occurrence stats for 40 virtual documents\n",
      "2022-08-17 10:14:40.760 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 40 virtual documents\n",
      "INFO - gensim.models.ldamodel -  using symmetric alpha at 0.14285714285714285\n",
      "2022-08-17 10:14:40.891 INFO    gensim.models.ldamodel: using symmetric alpha at 0.14285714285714285\n",
      "INFO - gensim.models.ldamodel -  using symmetric eta at 0.14285714285714285\n",
      "2022-08-17 10:14:40.892 INFO    gensim.models.ldamodel: using symmetric eta at 0.14285714285714285\n",
      "INFO - gensim.models.ldamodel -  using serial LDA version on this node\n",
      "2022-08-17 10:14:40.893 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "INFO - gensim.models.ldamodel -  running online (single-pass) LDA training, 7 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:14:40.894 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 7 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING - gensim.models.ldamodel -  too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:14:40.896 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO - gensim.models.ldamodel -  -8.830 per-word bound, 455.0 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "2022-08-17 10:14:40.940 INFO    gensim.models.ldamodel: -8.830 per-word bound, 455.0 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "INFO - gensim.models.ldamodel -  PROGRESS: pass 0, at document #40/40\n",
      "2022-08-17 10:14:40.941 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #40/40\n",
      "INFO - gensim.models.ldamodel -  topic #3 (0.143): 0.028*\"climat\" + 0.020*\"global\" + 0.020*\"chang\" + 0.017*\"brazilian\" + 0.017*\"increas\" + 0.016*\"temperatur\" + 0.013*\"implement\" + 0.011*\"brazil\" + 0.011*\"plan\" + 0.010*\"emiss\"\n",
      "2022-08-17 10:14:40.973 INFO    gensim.models.ldamodel: topic #3 (0.143): 0.028*\"climat\" + 0.020*\"global\" + 0.020*\"chang\" + 0.017*\"brazilian\" + 0.017*\"increas\" + 0.016*\"temperatur\" + 0.013*\"implement\" + 0.011*\"brazil\" + 0.011*\"plan\" + 0.010*\"emiss\"\n",
      "INFO - gensim.models.ldamodel -  topic #5 (0.143): 0.030*\"nation\" + 0.019*\"plan\" + 0.014*\"sector\" + 0.013*\"adapt\" + 0.013*\"develop\" + 0.012*\"contribut\" + 0.012*\"brazil\" + 0.012*\"parti\" + 0.011*\"determin\" + 0.010*\"includ\"\n",
      "2022-08-17 10:14:40.975 INFO    gensim.models.ldamodel: topic #5 (0.143): 0.030*\"nation\" + 0.019*\"plan\" + 0.014*\"sector\" + 0.013*\"adapt\" + 0.013*\"develop\" + 0.012*\"contribut\" + 0.012*\"brazil\" + 0.012*\"parti\" + 0.011*\"determin\" + 0.010*\"includ\"\n",
      "INFO - gensim.models.ldamodel -  topic #2 (0.143): 0.022*\"implement\" + 0.019*\"brazilian\" + 0.013*\"adapt\" + 0.012*\"contribut\" + 0.011*\"brazil\" + 0.011*\"chang\" + 0.011*\"nation\" + 0.010*\"emiss\" + 0.010*\"plan\" + 0.010*\"climat\"\n",
      "2022-08-17 10:14:40.976 INFO    gensim.models.ldamodel: topic #2 (0.143): 0.022*\"implement\" + 0.019*\"brazilian\" + 0.013*\"adapt\" + 0.012*\"contribut\" + 0.011*\"brazil\" + 0.011*\"chang\" + 0.011*\"nation\" + 0.010*\"emiss\" + 0.010*\"plan\" + 0.010*\"climat\"\n",
      "INFO - gensim.models.ldamodel -  topic #4 (0.143): 0.027*\"climat\" + 0.022*\"nation\" + 0.022*\"chang\" + 0.014*\"year\" + 0.013*\"plan\" + 0.013*\"brazil\" + 0.011*\"includ\" + 0.011*\"adapt\" + 0.010*\"polici\" + 0.009*\"refer\"\n",
      "2022-08-17 10:14:40.978 INFO    gensim.models.ldamodel: topic #4 (0.143): 0.027*\"climat\" + 0.022*\"nation\" + 0.022*\"chang\" + 0.014*\"year\" + 0.013*\"plan\" + 0.013*\"brazil\" + 0.011*\"includ\" + 0.011*\"adapt\" + 0.010*\"polici\" + 0.009*\"refer\"\n",
      "INFO - gensim.models.ldamodel -  topic #1 (0.143): 0.030*\"brazil\" + 0.023*\"contribut\" + 0.020*\"nation\" + 0.019*\"emiss\" + 0.017*\"articl\" + 0.016*\"agreement\" + 0.015*\"pari\" + 0.014*\"climat\" + 0.013*\"level\" + 0.012*\"determin\"\n",
      "2022-08-17 10:14:40.980 INFO    gensim.models.ldamodel: topic #1 (0.143): 0.030*\"brazil\" + 0.023*\"contribut\" + 0.020*\"nation\" + 0.019*\"emiss\" + 0.017*\"articl\" + 0.016*\"agreement\" + 0.015*\"pari\" + 0.014*\"climat\" + 0.013*\"level\" + 0.012*\"determin\"\n",
      "INFO - gensim.models.ldamodel -  topic diff=3.574481, rho=1.000000\n",
      "2022-08-17 10:14:40.981 INFO    gensim.models.ldamodel: topic diff=3.574481, rho=1.000000\n",
      "INFO - gensim.utils -  LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=7, decay=0.5, chunksize=2000) in 0.09s', 'datetime': '2022-08-17T10:14:40.982556', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:14:40.982 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=7, decay=0.5, chunksize=2000) in 0.09s', 'datetime': '2022-08-17T10:14:40.982556', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "INFO - gensim.topic_coherence.probability_estimation -  using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:14:40.986 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "INFO - gensim.topic_coherence.text_analysis -  15 accumulators retrieved from output queue\n",
      "2022-08-17 10:14:47.351 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "INFO - gensim.topic_coherence.text_analysis -  accumulated word occurrence stats for 40 virtual documents\n",
      "2022-08-17 10:14:47.363 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 40 virtual documents\n",
      "INFO - gensim.models.ldamodel -  using symmetric alpha at 0.125\n",
      "2022-08-17 10:14:47.501 INFO    gensim.models.ldamodel: using symmetric alpha at 0.125\n",
      "INFO - gensim.models.ldamodel -  using symmetric eta at 0.125\n",
      "2022-08-17 10:14:47.506 INFO    gensim.models.ldamodel: using symmetric eta at 0.125\n",
      "INFO - gensim.models.ldamodel -  using serial LDA version on this node\n",
      "2022-08-17 10:14:47.507 INFO    gensim.models.ldamodel: using serial LDA version on this node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - gensim.models.ldamodel -  running online (single-pass) LDA training, 8 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:14:47.509 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 8 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING - gensim.models.ldamodel -  too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:14:47.510 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO - gensim.models.ldamodel -  -9.301 per-word bound, 630.7 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "2022-08-17 10:14:47.550 INFO    gensim.models.ldamodel: -9.301 per-word bound, 630.7 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "INFO - gensim.models.ldamodel -  PROGRESS: pass 0, at document #40/40\n",
      "2022-08-17 10:14:47.551 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #40/40\n",
      "INFO - gensim.models.ldamodel -  topic #3 (0.125): 0.030*\"climat\" + 0.020*\"chang\" + 0.018*\"global\" + 0.017*\"brazilian\" + 0.016*\"temperatur\" + 0.015*\"implement\" + 0.014*\"increas\" + 0.009*\"govern\" + 0.009*\"plan\" + 0.009*\"anthropogen\"\n",
      "2022-08-17 10:14:47.582 INFO    gensim.models.ldamodel: topic #3 (0.125): 0.030*\"climat\" + 0.020*\"chang\" + 0.018*\"global\" + 0.017*\"brazilian\" + 0.016*\"temperatur\" + 0.015*\"implement\" + 0.014*\"increas\" + 0.009*\"govern\" + 0.009*\"plan\" + 0.009*\"anthropogen\"\n",
      "INFO - gensim.models.ldamodel -  topic #5 (0.125): 0.028*\"nation\" + 0.026*\"plan\" + 0.015*\"sector\" + 0.015*\"adapt\" + 0.013*\"develop\" + 0.012*\"brazil\" + 0.010*\"parti\" + 0.010*\"contribut\" + 0.010*\"effort\" + 0.009*\"determin\"\n",
      "2022-08-17 10:14:47.583 INFO    gensim.models.ldamodel: topic #5 (0.125): 0.028*\"nation\" + 0.026*\"plan\" + 0.015*\"sector\" + 0.015*\"adapt\" + 0.013*\"develop\" + 0.012*\"brazil\" + 0.010*\"parti\" + 0.010*\"contribut\" + 0.010*\"effort\" + 0.009*\"determin\"\n",
      "INFO - gensim.models.ldamodel -  topic #0 (0.125): 0.019*\"account\" + 0.018*\"implement\" + 0.012*\"polici\" + 0.011*\"brazil\" + 0.011*\"emiss\" + 0.011*\"nation\" + 0.009*\"measur\" + 0.009*\"methodolog\" + 0.009*\"adapt\" + 0.008*\"assumpt\"\n",
      "2022-08-17 10:14:47.584 INFO    gensim.models.ldamodel: topic #0 (0.125): 0.019*\"account\" + 0.018*\"implement\" + 0.012*\"polici\" + 0.011*\"brazil\" + 0.011*\"emiss\" + 0.011*\"nation\" + 0.009*\"measur\" + 0.009*\"methodolog\" + 0.009*\"adapt\" + 0.008*\"assumpt\"\n",
      "INFO - gensim.models.ldamodel -  topic #7 (0.125): 0.023*\"climat\" + 0.020*\"brazil\" + 0.019*\"agreement\" + 0.018*\"chang\" + 0.017*\"increas\" + 0.015*\"nation\" + 0.013*\"temperatur\" + 0.013*\"contribut\" + 0.013*\"global\" + 0.012*\"includ\"\n",
      "2022-08-17 10:14:47.585 INFO    gensim.models.ldamodel: topic #7 (0.125): 0.023*\"climat\" + 0.020*\"brazil\" + 0.019*\"agreement\" + 0.018*\"chang\" + 0.017*\"increas\" + 0.015*\"nation\" + 0.013*\"temperatur\" + 0.013*\"contribut\" + 0.013*\"global\" + 0.012*\"includ\"\n",
      "INFO - gensim.models.ldamodel -  topic #6 (0.125): 0.034*\"applic\" + 0.024*\"emiss\" + 0.023*\"parti\" + 0.023*\"approach\" + 0.021*\"inform\" + 0.020*\"includ\" + 0.019*\"target\" + 0.016*\"agreement\" + 0.015*\"contribut\" + 0.015*\"pari\"\n",
      "2022-08-17 10:14:47.587 INFO    gensim.models.ldamodel: topic #6 (0.125): 0.034*\"applic\" + 0.024*\"emiss\" + 0.023*\"parti\" + 0.023*\"approach\" + 0.021*\"inform\" + 0.020*\"includ\" + 0.019*\"target\" + 0.016*\"agreement\" + 0.015*\"contribut\" + 0.015*\"pari\"\n",
      "INFO - gensim.models.ldamodel -  topic diff=4.151986, rho=1.000000\n",
      "2022-08-17 10:14:47.588 INFO    gensim.models.ldamodel: topic diff=4.151986, rho=1.000000\n",
      "INFO - gensim.utils -  LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=8, decay=0.5, chunksize=2000) in 0.08s', 'datetime': '2022-08-17T10:14:47.589980', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:14:47.589 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=8, decay=0.5, chunksize=2000) in 0.08s', 'datetime': '2022-08-17T10:14:47.589980', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "INFO - gensim.topic_coherence.probability_estimation -  using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:14:47.593 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "INFO - gensim.topic_coherence.text_analysis -  15 accumulators retrieved from output queue\n",
      "2022-08-17 10:14:53.982 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "INFO - gensim.topic_coherence.text_analysis -  accumulated word occurrence stats for 40 virtual documents\n",
      "2022-08-17 10:14:53.996 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 40 virtual documents\n",
      "INFO - gensim.models.ldamodel -  using symmetric alpha at 0.1111111111111111\n",
      "2022-08-17 10:14:54.199 INFO    gensim.models.ldamodel: using symmetric alpha at 0.1111111111111111\n",
      "INFO - gensim.models.ldamodel -  using symmetric eta at 0.1111111111111111\n",
      "2022-08-17 10:14:54.201 INFO    gensim.models.ldamodel: using symmetric eta at 0.1111111111111111\n",
      "INFO - gensim.models.ldamodel -  using serial LDA version on this node\n",
      "2022-08-17 10:14:54.203 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "INFO - gensim.models.ldamodel -  running online (single-pass) LDA training, 9 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:14:54.205 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 9 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING - gensim.models.ldamodel -  too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:14:54.206 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO - gensim.models.ldamodel -  -9.796 per-word bound, 888.9 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "2022-08-17 10:14:54.236 INFO    gensim.models.ldamodel: -9.796 per-word bound, 888.9 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "INFO - gensim.models.ldamodel -  PROGRESS: pass 0, at document #40/40\n",
      "2022-08-17 10:14:54.241 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #40/40\n",
      "INFO - gensim.models.ldamodel -  topic #1 (0.111): 0.029*\"brazil\" + 0.023*\"contribut\" + 0.020*\"nation\" + 0.019*\"emiss\" + 0.016*\"climat\" + 0.015*\"agreement\" + 0.015*\"pari\" + 0.015*\"articl\" + 0.014*\"brazilian\" + 0.014*\"level\"\n",
      "2022-08-17 10:14:54.266 INFO    gensim.models.ldamodel: topic #1 (0.111): 0.029*\"brazil\" + 0.023*\"contribut\" + 0.020*\"nation\" + 0.019*\"emiss\" + 0.016*\"climat\" + 0.015*\"agreement\" + 0.015*\"pari\" + 0.015*\"articl\" + 0.014*\"brazilian\" + 0.014*\"level\"\n",
      "INFO - gensim.models.ldamodel -  topic #8 (0.111): 0.029*\"refer\" + 0.022*\"emiss\" + 0.020*\"year\" + 0.018*\"inform\" + 0.017*\"brazil\" + 0.016*\"parti\" + 0.014*\"plan\" + 0.014*\"implement\" + 0.013*\"agreement\" + 0.013*\"includ\"\n",
      "2022-08-17 10:14:54.268 INFO    gensim.models.ldamodel: topic #8 (0.111): 0.029*\"refer\" + 0.022*\"emiss\" + 0.020*\"year\" + 0.018*\"inform\" + 0.017*\"brazil\" + 0.016*\"parti\" + 0.014*\"plan\" + 0.014*\"implement\" + 0.013*\"agreement\" + 0.013*\"includ\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - gensim.models.ldamodel -  topic #6 (0.111): 0.039*\"applic\" + 0.023*\"target\" + 0.020*\"agreement\" + 0.020*\"inform\" + 0.020*\"includ\" + 0.020*\"contribut\" + 0.019*\"emiss\" + 0.019*\"nation\" + 0.019*\"determin\" + 0.019*\"pari\"\n",
      "2022-08-17 10:14:54.269 INFO    gensim.models.ldamodel: topic #6 (0.111): 0.039*\"applic\" + 0.023*\"target\" + 0.020*\"agreement\" + 0.020*\"inform\" + 0.020*\"includ\" + 0.020*\"contribut\" + 0.019*\"emiss\" + 0.019*\"nation\" + 0.019*\"determin\" + 0.019*\"pari\"\n",
      "INFO - gensim.models.ldamodel -  topic #2 (0.111): 0.028*\"brazilian\" + 0.018*\"implement\" + 0.012*\"nation\" + 0.011*\"energi\" + 0.010*\"emiss\" + 0.010*\"protect\" + 0.010*\"polici\" + 0.010*\"account\" + 0.009*\"govern\" + 0.009*\"brazil\"\n",
      "2022-08-17 10:14:54.270 INFO    gensim.models.ldamodel: topic #2 (0.111): 0.028*\"brazilian\" + 0.018*\"implement\" + 0.012*\"nation\" + 0.011*\"energi\" + 0.010*\"emiss\" + 0.010*\"protect\" + 0.010*\"polici\" + 0.010*\"account\" + 0.009*\"govern\" + 0.009*\"brazil\"\n",
      "INFO - gensim.models.ldamodel -  topic #5 (0.111): 0.034*\"nation\" + 0.021*\"develop\" + 0.016*\"contribut\" + 0.015*\"parti\" + 0.014*\"brazil\" + 0.013*\"determin\" + 0.012*\"plan\" + 0.011*\"adapt\" + 0.011*\"includ\" + 0.010*\"social\"\n",
      "2022-08-17 10:14:54.271 INFO    gensim.models.ldamodel: topic #5 (0.111): 0.034*\"nation\" + 0.021*\"develop\" + 0.016*\"contribut\" + 0.015*\"parti\" + 0.014*\"brazil\" + 0.013*\"determin\" + 0.012*\"plan\" + 0.011*\"adapt\" + 0.011*\"includ\" + 0.010*\"social\"\n",
      "INFO - gensim.models.ldamodel -  topic diff=4.934453, rho=1.000000\n",
      "2022-08-17 10:14:54.272 INFO    gensim.models.ldamodel: topic diff=4.934453, rho=1.000000\n",
      "INFO - gensim.utils -  LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=9, decay=0.5, chunksize=2000) in 0.07s', 'datetime': '2022-08-17T10:14:54.274174', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:14:54.274 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=9, decay=0.5, chunksize=2000) in 0.07s', 'datetime': '2022-08-17T10:14:54.274174', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "INFO - gensim.topic_coherence.probability_estimation -  using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-08-17 10:14:54.278 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "INFO - gensim.topic_coherence.text_analysis -  15 accumulators retrieved from output queue\n",
      "2022-08-17 10:15:00.615 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "INFO - gensim.topic_coherence.text_analysis -  accumulated word occurrence stats for 40 virtual documents\n",
      "2022-08-17 10:15:00.632 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 40 virtual documents\n",
      "INFO - gensim.models.ldamodel -  using symmetric alpha at 0.1\n",
      "2022-08-17 10:15:00.845 INFO    gensim.models.ldamodel: using symmetric alpha at 0.1\n",
      "INFO - gensim.models.ldamodel -  using symmetric eta at 0.1\n",
      "2022-08-17 10:15:00.851 INFO    gensim.models.ldamodel: using symmetric eta at 0.1\n",
      "INFO - gensim.models.ldamodel -  using serial LDA version on this node\n",
      "2022-08-17 10:15:00.853 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "INFO - gensim.models.ldamodel -  running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:15:00.855 INFO    gensim.models.ldamodel: running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 40 documents, updating model once every 40 documents, evaluating perplexity every 40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING - gensim.models.ldamodel -  too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:15:00.856 WARNING gensim.models.ldamodel: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO - gensim.models.ldamodel -  -10.316 per-word bound, 1275.0 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "2022-08-17 10:15:00.882 INFO    gensim.models.ldamodel: -10.316 per-word bound, 1275.0 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "INFO - gensim.models.ldamodel -  PROGRESS: pass 0, at document #40/40\n",
      "2022-08-17 10:15:00.891 INFO    gensim.models.ldamodel: PROGRESS: pass 0, at document #40/40\n",
      "INFO - gensim.models.ldamodel -  topic #1 (0.100): 0.031*\"brazil\" + 0.029*\"contribut\" + 0.026*\"nation\" + 0.019*\"climat\" + 0.018*\"articl\" + 0.017*\"emiss\" + 0.016*\"brazilian\" + 0.016*\"agreement\" + 0.015*\"determin\" + 0.015*\"pari\"\n",
      "2022-08-17 10:15:00.918 INFO    gensim.models.ldamodel: topic #1 (0.100): 0.031*\"brazil\" + 0.029*\"contribut\" + 0.026*\"nation\" + 0.019*\"climat\" + 0.018*\"articl\" + 0.017*\"emiss\" + 0.016*\"brazilian\" + 0.016*\"agreement\" + 0.015*\"determin\" + 0.015*\"pari\"\n",
      "INFO - gensim.models.ldamodel -  topic #4 (0.100): 0.028*\"climat\" + 0.027*\"plan\" + 0.023*\"adapt\" + 0.022*\"chang\" + 0.018*\"nation\" + 0.012*\"sector\" + 0.012*\"resourc\" + 0.009*\"polici\" + 0.008*\"human\" + 0.008*\"effect\"\n",
      "2022-08-17 10:15:00.921 INFO    gensim.models.ldamodel: topic #4 (0.100): 0.028*\"climat\" + 0.027*\"plan\" + 0.023*\"adapt\" + 0.022*\"chang\" + 0.018*\"nation\" + 0.012*\"sector\" + 0.012*\"resourc\" + 0.009*\"polici\" + 0.008*\"human\" + 0.008*\"effect\"\n",
      "INFO - gensim.models.ldamodel -  topic #7 (0.100): 0.030*\"climat\" + 0.025*\"chang\" + 0.019*\"increas\" + 0.018*\"brazil\" + 0.016*\"nation\" + 0.015*\"global\" + 0.015*\"temperatur\" + 0.013*\"implement\" + 0.012*\"includ\" + 0.012*\"contribut\"\n",
      "2022-08-17 10:15:00.923 INFO    gensim.models.ldamodel: topic #7 (0.100): 0.030*\"climat\" + 0.025*\"chang\" + 0.019*\"increas\" + 0.018*\"brazil\" + 0.016*\"nation\" + 0.015*\"global\" + 0.015*\"temperatur\" + 0.013*\"implement\" + 0.012*\"includ\" + 0.012*\"contribut\"\n",
      "INFO - gensim.models.ldamodel -  topic #9 (0.100): 0.018*\"sourc\" + 0.013*\"sector\" + 0.012*\"transport\" + 0.012*\"renew\" + 0.012*\"account\" + 0.011*\"demand\" + 0.009*\"time\" + 0.009*\"promot\" + 0.008*\"nation\" + 0.008*\"develop\"\n",
      "2022-08-17 10:15:00.924 INFO    gensim.models.ldamodel: topic #9 (0.100): 0.018*\"sourc\" + 0.013*\"sector\" + 0.012*\"transport\" + 0.012*\"renew\" + 0.012*\"account\" + 0.011*\"demand\" + 0.009*\"time\" + 0.009*\"promot\" + 0.008*\"nation\" + 0.008*\"develop\"\n",
      "INFO - gensim.models.ldamodel -  topic #5 (0.100): 0.038*\"nation\" + 0.018*\"develop\" + 0.016*\"plan\" + 0.014*\"contribut\" + 0.013*\"determin\" + 0.013*\"parti\" + 0.012*\"brazil\" + 0.011*\"includ\" + 0.011*\"adapt\" + 0.010*\"ambiti\"\n",
      "2022-08-17 10:15:00.925 INFO    gensim.models.ldamodel: topic #5 (0.100): 0.038*\"nation\" + 0.018*\"develop\" + 0.016*\"plan\" + 0.014*\"contribut\" + 0.013*\"determin\" + 0.013*\"parti\" + 0.012*\"brazil\" + 0.011*\"includ\" + 0.011*\"adapt\" + 0.010*\"ambiti\"\n",
      "INFO - gensim.models.ldamodel -  topic diff=5.714431, rho=1.000000\n",
      "2022-08-17 10:15:00.927 INFO    gensim.models.ldamodel: topic diff=5.714431, rho=1.000000\n",
      "INFO - gensim.utils -  LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=10, decay=0.5, chunksize=2000) in 0.07s', 'datetime': '2022-08-17T10:15:00.929667', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:15:00.929 INFO    gensim.utils: LdaModel lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=10, decay=0.5, chunksize=2000) in 0.07s', 'datetime': '2022-08-17T10:15:00.929667', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "INFO - gensim.topic_coherence.probability_estimation -  using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 10:15:00.934 INFO    gensim.topic_coherence.probability_estimation: using ParallelWordOccurrenceAccumulator(processes=15, batch_size=64) to estimate probabilities from sliding windows\n",
      "INFO - gensim.topic_coherence.text_analysis -  15 accumulators retrieved from output queue\n",
      "2022-08-17 10:15:07.308 INFO    gensim.topic_coherence.text_analysis: 15 accumulators retrieved from output queue\n",
      "INFO - gensim.topic_coherence.text_analysis -  accumulated word occurrence stats for 40 virtual documents\n",
      "2022-08-17 10:15:07.331 INFO    gensim.topic_coherence.text_analysis: accumulated word occurrence stats for 40 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coherence score is highest (0.42) with 10 topics.\n"
     ]
    }
   ],
   "source": [
    "# Calculate coherence score for optimal num of topics\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import numpy as np \n",
    "\n",
    "best_num = float('NaN')\n",
    "best_score = 0\n",
    "\n",
    "# compute the coherence scores for each number of topics\n",
    "for i in range(2,11):\n",
    "    \n",
    "    # create lda model with i topics\n",
    "    lda = LdaModel(corpus=bow_corpus, num_topics=i, id2word=dictionary, random_state=42)\n",
    "    \n",
    "    # obtain the coherence score\n",
    "    coherence_model = CoherenceModel(model=lda, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = np.round(coherence_model.get_coherence(),2)\n",
    "    if coherence_score > best_score:\n",
    "        best_num = i\n",
    "        best_score = coherence_score\n",
    "\n",
    "print(f'The coherence score is highest ({best_score}) with {best_num} topics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a28380b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - gensim.models.ldamodel -  using symmetric alpha at 0.1\n",
      "2022-08-17 10:24:21.296 INFO    gensim.models.ldamodel: using symmetric alpha at 0.1\n",
      "INFO - gensim.models.ldamodel -  using symmetric eta at 0.1\n",
      "2022-08-17 10:24:21.301 INFO    gensim.models.ldamodel: using symmetric eta at 0.1\n",
      "INFO - gensim.models.ldamodel -  using serial LDA version on this node\n",
      "2022-08-17 10:24:21.303 INFO    gensim.models.ldamodel: using serial LDA version on this node\n",
      "INFO - gensim.models.ldamulticore -  running online LDA training, 10 topics, 2 passes over the supplied corpus of 40 documents, updating every 4000 documents, evaluating every ~40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-08-17 10:24:21.307 INFO    gensim.models.ldamulticore: running online LDA training, 10 topics, 2 passes over the supplied corpus of 40 documents, updating every 4000 documents, evaluating every ~40 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING - gensim.models.ldamulticore -  too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-08-17 10:24:21.309 WARNING gensim.models.ldamulticore: too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "INFO - gensim.models.ldamulticore -  training LDA model using 2 processes\n",
      "2022-08-17 10:24:21.314 INFO    gensim.models.ldamulticore: training LDA model using 2 processes\n",
      "INFO - gensim.models.ldamulticore -  PROGRESS: pass 0, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "2022-08-17 10:24:21.559 INFO    gensim.models.ldamulticore: PROGRESS: pass 0, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "INFO - gensim.models.ldamodel -  topic #7 (0.100): 0.039*\"agreement\" + 0.032*\"pari\" + 0.027*\"articl\" + 0.026*\"parti\" + 0.026*\"paragraph\" + 0.026*\"applic\" + 0.023*\"emiss\" + 0.017*\"target\" + 0.016*\"brazil\" + 0.015*\"inform\"\n",
      "2022-08-17 10:24:23.743 INFO    gensim.models.ldamodel: topic #7 (0.100): 0.039*\"agreement\" + 0.032*\"pari\" + 0.027*\"articl\" + 0.026*\"parti\" + 0.026*\"paragraph\" + 0.026*\"applic\" + 0.023*\"emiss\" + 0.017*\"target\" + 0.016*\"brazil\" + 0.015*\"inform\"\n",
      "INFO - gensim.models.ldamodel -  topic #6 (0.100): 0.020*\"emiss\" + 0.018*\"implement\" + 0.018*\"increas\" + 0.017*\"level\" + 0.017*\"target\" + 0.017*\"temperatur\" + 0.016*\"nation\" + 0.014*\"parti\" + 0.013*\"global\" + 0.013*\"contribut\"\n",
      "2022-08-17 10:24:23.744 INFO    gensim.models.ldamodel: topic #6 (0.100): 0.020*\"emiss\" + 0.018*\"implement\" + 0.018*\"increas\" + 0.017*\"level\" + 0.017*\"target\" + 0.017*\"temperatur\" + 0.016*\"nation\" + 0.014*\"parti\" + 0.013*\"global\" + 0.013*\"contribut\"\n",
      "INFO - gensim.models.ldamodel -  topic #1 (0.100): 0.018*\"contribut\" + 0.016*\"increas\" + 0.016*\"relat\" + 0.016*\"plan\" + 0.014*\"individu\" + 0.014*\"temperatur\" + 0.012*\"emiss\" + 0.012*\"climat\" + 0.012*\"includ\" + 0.012*\"brazil\"\n",
      "2022-08-17 10:24:23.745 INFO    gensim.models.ldamodel: topic #1 (0.100): 0.018*\"contribut\" + 0.016*\"increas\" + 0.016*\"relat\" + 0.016*\"plan\" + 0.014*\"individu\" + 0.014*\"temperatur\" + 0.012*\"emiss\" + 0.012*\"climat\" + 0.012*\"includ\" + 0.012*\"brazil\"\n",
      "INFO - gensim.models.ldamodel -  topic #8 (0.100): 0.041*\"climat\" + 0.027*\"chang\" + 0.020*\"global\" + 0.018*\"brazil\" + 0.015*\"temperatur\" + 0.015*\"increas\" + 0.013*\"implement\" + 0.013*\"emiss\" + 0.011*\"contribut\" + 0.011*\"anthropogen\"\n",
      "2022-08-17 10:24:23.748 INFO    gensim.models.ldamodel: topic #8 (0.100): 0.041*\"climat\" + 0.027*\"chang\" + 0.020*\"global\" + 0.018*\"brazil\" + 0.015*\"temperatur\" + 0.015*\"increas\" + 0.013*\"implement\" + 0.013*\"emiss\" + 0.011*\"contribut\" + 0.011*\"anthropogen\"\n",
      "INFO - gensim.models.ldamodel -  topic #9 (0.100): 0.035*\"nation\" + 0.029*\"contribut\" + 0.019*\"determin\" + 0.019*\"brazil\" + 0.016*\"articl\" + 0.016*\"brazilian\" + 0.015*\"agreement\" + 0.015*\"climat\" + 0.014*\"pari\" + 0.012*\"emiss\"\n",
      "2022-08-17 10:24:23.750 INFO    gensim.models.ldamodel: topic #9 (0.100): 0.035*\"nation\" + 0.029*\"contribut\" + 0.019*\"determin\" + 0.019*\"brazil\" + 0.016*\"articl\" + 0.016*\"brazilian\" + 0.015*\"agreement\" + 0.015*\"climat\" + 0.014*\"pari\" + 0.012*\"emiss\"\n",
      "INFO - gensim.models.ldamodel -  topic diff=5.814090, rho=1.000000\n",
      "2022-08-17 10:24:23.751 INFO    gensim.models.ldamodel: topic diff=5.814090, rho=1.000000\n",
      "INFO - gensim.models.ldamodel -  -6.821 per-word bound, 113.1 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "2022-08-17 10:24:23.774 INFO    gensim.models.ldamodel: -6.821 per-word bound, 113.1 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "INFO - gensim.models.ldamulticore -  PROGRESS: pass 1, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "2022-08-17 10:24:23.776 INFO    gensim.models.ldamulticore: PROGRESS: pass 1, dispatched chunk #0 = documents up to #40/40, outstanding queue size 1\n",
      "INFO - gensim.models.ldamodel -  topic #8 (0.100): 0.038*\"climat\" + 0.025*\"chang\" + 0.023*\"global\" + 0.017*\"temperatur\" + 0.017*\"brazil\" + 0.017*\"increas\" + 0.015*\"implement\" + 0.013*\"emiss\" + 0.013*\"anthropogen\" + 0.011*\"contribut\"\n",
      "2022-08-17 10:24:23.791 INFO    gensim.models.ldamodel: topic #8 (0.100): 0.038*\"climat\" + 0.025*\"chang\" + 0.023*\"global\" + 0.017*\"temperatur\" + 0.017*\"brazil\" + 0.017*\"increas\" + 0.015*\"implement\" + 0.013*\"emiss\" + 0.013*\"anthropogen\" + 0.011*\"contribut\"\n",
      "INFO - gensim.models.ldamodel -  topic #2 (0.100): 0.030*\"brazil\" + 0.020*\"climat\" + 0.017*\"commit\" + 0.014*\"brazilian\" + 0.012*\"effort\" + 0.011*\"glasgow\" + 0.011*\"pact\" + 0.010*\"unit\" + 0.009*\"chang\" + 0.009*\"communic\"\n",
      "2022-08-17 10:24:23.793 INFO    gensim.models.ldamodel: topic #2 (0.100): 0.030*\"brazil\" + 0.020*\"climat\" + 0.017*\"commit\" + 0.014*\"brazilian\" + 0.012*\"effort\" + 0.011*\"glasgow\" + 0.011*\"pact\" + 0.010*\"unit\" + 0.009*\"chang\" + 0.009*\"communic\"\n",
      "INFO - gensim.models.ldamodel -  topic #0 (0.100): 0.027*\"plan\" + 0.026*\"adapt\" + 0.021*\"year\" + 0.020*\"refer\" + 0.019*\"climat\" + 0.016*\"brazil\" + 0.015*\"nation\" + 0.015*\"mitig\" + 0.014*\"chang\" + 0.014*\"implement\"\n",
      "2022-08-17 10:24:23.795 INFO    gensim.models.ldamodel: topic #0 (0.100): 0.027*\"plan\" + 0.026*\"adapt\" + 0.021*\"year\" + 0.020*\"refer\" + 0.019*\"climat\" + 0.016*\"brazil\" + 0.015*\"nation\" + 0.015*\"mitig\" + 0.014*\"chang\" + 0.014*\"implement\"\n",
      "INFO - gensim.models.ldamodel -  topic #5 (0.100): 0.029*\"institut\" + 0.027*\"nation\" + 0.026*\"chang\" + 0.025*\"climat\" + 0.016*\"polici\" + 0.015*\"plan\" + 0.012*\"implement\" + 0.012*\"brazilian\" + 0.011*\"includ\" + 0.011*\"develop\"\n",
      "2022-08-17 10:24:23.796 INFO    gensim.models.ldamodel: topic #5 (0.100): 0.029*\"institut\" + 0.027*\"nation\" + 0.026*\"chang\" + 0.025*\"climat\" + 0.016*\"polici\" + 0.015*\"plan\" + 0.012*\"implement\" + 0.012*\"brazilian\" + 0.011*\"includ\" + 0.011*\"develop\"\n",
      "INFO - gensim.models.ldamodel -  topic #9 (0.100): 0.039*\"nation\" + 0.031*\"contribut\" + 0.021*\"determin\" + 0.021*\"brazil\" + 0.017*\"climat\" + 0.016*\"brazilian\" + 0.015*\"agreement\" + 0.015*\"articl\" + 0.015*\"parti\" + 0.013*\"includ\"\n",
      "2022-08-17 10:24:23.797 INFO    gensim.models.ldamodel: topic #9 (0.100): 0.039*\"nation\" + 0.031*\"contribut\" + 0.021*\"determin\" + 0.021*\"brazil\" + 0.017*\"climat\" + 0.016*\"brazilian\" + 0.015*\"agreement\" + 0.015*\"articl\" + 0.015*\"parti\" + 0.013*\"includ\"\n",
      "INFO - gensim.models.ldamodel -  topic diff=0.733632, rho=0.703598\n",
      "2022-08-17 10:24:23.798 INFO    gensim.models.ldamodel: topic diff=0.733632, rho=0.703598\n",
      "INFO - gensim.models.ldamodel -  -6.480 per-word bound, 89.2 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "2022-08-17 10:24:23.824 INFO    gensim.models.ldamodel: -6.480 per-word bound, 89.2 perplexity estimate based on a held-out corpus of 40 documents with 2198 words\n",
      "INFO - gensim.utils -  LdaMulticore lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=10, decay=0.5, chunksize=2000) in 2.54s', 'datetime': '2022-08-17T10:24:23.848432', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-08-17 10:24:23.848 INFO    gensim.utils: LdaMulticore lifecycle event {'msg': 'trained LdaModel(num_terms=631, num_topics=10, decay=0.5, chunksize=2000) in 2.54s', 'datetime': '2022-08-17T10:24:23.848432', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3b2a7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - gensim.models.ldamodel -  topic #0 (0.100): 0.027*\"plan\" + 0.026*\"adapt\" + 0.021*\"year\" + 0.020*\"refer\" + 0.019*\"climat\" + 0.016*\"brazil\" + 0.015*\"nation\" + 0.015*\"mitig\" + 0.014*\"chang\" + 0.014*\"implement\"\n",
      "2022-08-17 10:25:46.085 INFO    gensim.models.ldamodel: topic #0 (0.100): 0.027*\"plan\" + 0.026*\"adapt\" + 0.021*\"year\" + 0.020*\"refer\" + 0.019*\"climat\" + 0.016*\"brazil\" + 0.015*\"nation\" + 0.015*\"mitig\" + 0.014*\"chang\" + 0.014*\"implement\"\n",
      "INFO - gensim.models.ldamodel -  topic #1 (0.100): 0.021*\"plan\" + 0.020*\"increas\" + 0.019*\"individu\" + 0.016*\"temperatur\" + 0.015*\"contribut\" + 0.015*\"relat\" + 0.015*\"sector\" + 0.014*\"includ\" + 0.013*\"carbon\" + 0.012*\"climat\"\n",
      "2022-08-17 10:25:46.087 INFO    gensim.models.ldamodel: topic #1 (0.100): 0.021*\"plan\" + 0.020*\"increas\" + 0.019*\"individu\" + 0.016*\"temperatur\" + 0.015*\"contribut\" + 0.015*\"relat\" + 0.015*\"sector\" + 0.014*\"includ\" + 0.013*\"carbon\" + 0.012*\"climat\"\n",
      "INFO - gensim.models.ldamodel -  topic #2 (0.100): 0.030*\"brazil\" + 0.020*\"climat\" + 0.017*\"commit\" + 0.014*\"brazilian\" + 0.012*\"effort\" + 0.011*\"glasgow\" + 0.011*\"pact\" + 0.010*\"unit\" + 0.009*\"chang\" + 0.009*\"communic\"\n",
      "2022-08-17 10:25:46.089 INFO    gensim.models.ldamodel: topic #2 (0.100): 0.030*\"brazil\" + 0.020*\"climat\" + 0.017*\"commit\" + 0.014*\"brazilian\" + 0.012*\"effort\" + 0.011*\"glasgow\" + 0.011*\"pact\" + 0.010*\"unit\" + 0.009*\"chang\" + 0.009*\"communic\"\n",
      "INFO - gensim.models.ldamodel -  topic #3 (0.100): 0.025*\"account\" + 0.025*\"energi\" + 0.024*\"sourc\" + 0.018*\"renew\" + 0.013*\"solar\" + 0.013*\"biomass\" + 0.012*\"electr\" + 0.012*\"demand\" + 0.012*\"wind\" + 0.012*\"transport\"\n",
      "2022-08-17 10:25:46.090 INFO    gensim.models.ldamodel: topic #3 (0.100): 0.025*\"account\" + 0.025*\"energi\" + 0.024*\"sourc\" + 0.018*\"renew\" + 0.013*\"solar\" + 0.013*\"biomass\" + 0.012*\"electr\" + 0.012*\"demand\" + 0.012*\"wind\" + 0.012*\"transport\"\n",
      "INFO - gensim.models.ldamodel -  topic #4 (0.100): 0.029*\"approach\" + 0.026*\"brazilian\" + 0.021*\"brazil\" + 0.019*\"emiss\" + 0.015*\"adapt\" + 0.014*\"sector\" + 0.013*\"subsequ\" + 0.012*\"consist\" + 0.011*\"govern\" + 0.011*\"product\"\n",
      "2022-08-17 10:25:46.092 INFO    gensim.models.ldamodel: topic #4 (0.100): 0.029*\"approach\" + 0.026*\"brazilian\" + 0.021*\"brazil\" + 0.019*\"emiss\" + 0.015*\"adapt\" + 0.014*\"sector\" + 0.013*\"subsequ\" + 0.012*\"consist\" + 0.011*\"govern\" + 0.011*\"product\"\n",
      "INFO - gensim.models.ldamodel -  topic #5 (0.100): 0.029*\"institut\" + 0.027*\"nation\" + 0.026*\"chang\" + 0.025*\"climat\" + 0.016*\"polici\" + 0.015*\"plan\" + 0.012*\"implement\" + 0.012*\"brazilian\" + 0.011*\"includ\" + 0.011*\"develop\"\n",
      "2022-08-17 10:25:46.093 INFO    gensim.models.ldamodel: topic #5 (0.100): 0.029*\"institut\" + 0.027*\"nation\" + 0.026*\"chang\" + 0.025*\"climat\" + 0.016*\"polici\" + 0.015*\"plan\" + 0.012*\"implement\" + 0.012*\"brazilian\" + 0.011*\"includ\" + 0.011*\"develop\"\n",
      "INFO - gensim.models.ldamodel -  topic #6 (0.100): 0.023*\"emiss\" + 0.021*\"target\" + 0.021*\"temperatur\" + 0.020*\"increas\" + 0.019*\"level\" + 0.019*\"account\" + 0.017*\"relat\" + 0.016*\"implement\" + 0.016*\"nation\" + 0.016*\"contribut\"\n",
      "2022-08-17 10:25:46.095 INFO    gensim.models.ldamodel: topic #6 (0.100): 0.023*\"emiss\" + 0.021*\"target\" + 0.021*\"temperatur\" + 0.020*\"increas\" + 0.019*\"level\" + 0.019*\"account\" + 0.017*\"relat\" + 0.016*\"implement\" + 0.016*\"nation\" + 0.016*\"contribut\"\n",
      "INFO - gensim.models.ldamodel -  topic #7 (0.100): 0.042*\"agreement\" + 0.034*\"pari\" + 0.031*\"articl\" + 0.030*\"applic\" + 0.029*\"paragraph\" + 0.026*\"parti\" + 0.024*\"emiss\" + 0.018*\"target\" + 0.017*\"methodolog\" + 0.016*\"brazil\"\n",
      "2022-08-17 10:25:46.097 INFO    gensim.models.ldamodel: topic #7 (0.100): 0.042*\"agreement\" + 0.034*\"pari\" + 0.031*\"articl\" + 0.030*\"applic\" + 0.029*\"paragraph\" + 0.026*\"parti\" + 0.024*\"emiss\" + 0.018*\"target\" + 0.017*\"methodolog\" + 0.016*\"brazil\"\n",
      "INFO - gensim.models.ldamodel -  topic #8 (0.100): 0.038*\"climat\" + 0.025*\"chang\" + 0.023*\"global\" + 0.017*\"temperatur\" + 0.017*\"brazil\" + 0.017*\"increas\" + 0.015*\"implement\" + 0.013*\"emiss\" + 0.013*\"anthropogen\" + 0.011*\"contribut\"\n",
      "2022-08-17 10:25:46.098 INFO    gensim.models.ldamodel: topic #8 (0.100): 0.038*\"climat\" + 0.025*\"chang\" + 0.023*\"global\" + 0.017*\"temperatur\" + 0.017*\"brazil\" + 0.017*\"increas\" + 0.015*\"implement\" + 0.013*\"emiss\" + 0.013*\"anthropogen\" + 0.011*\"contribut\"\n",
      "INFO - gensim.models.ldamodel -  topic #9 (0.100): 0.039*\"nation\" + 0.031*\"contribut\" + 0.021*\"determin\" + 0.021*\"brazil\" + 0.017*\"climat\" + 0.016*\"brazilian\" + 0.015*\"agreement\" + 0.015*\"articl\" + 0.015*\"parti\" + 0.013*\"includ\"\n",
      "2022-08-17 10:25:46.100 INFO    gensim.models.ldamodel: topic #9 (0.100): 0.039*\"nation\" + 0.031*\"contribut\" + 0.021*\"determin\" + 0.021*\"brazil\" + 0.017*\"climat\" + 0.016*\"brazilian\" + 0.015*\"agreement\" + 0.015*\"articl\" + 0.015*\"parti\" + 0.013*\"includ\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.027*\"plan\" + 0.026*\"adapt\" + 0.021*\"year\" + 0.020*\"refer\" + 0.019*\"climat\" + 0.016*\"brazil\" + 0.015*\"nation\" + 0.015*\"mitig\" + 0.014*\"chang\" + 0.014*\"implement\"')\n",
      "(1, '0.021*\"plan\" + 0.020*\"increas\" + 0.019*\"individu\" + 0.016*\"temperatur\" + 0.015*\"contribut\" + 0.015*\"relat\" + 0.015*\"sector\" + 0.014*\"includ\" + 0.013*\"carbon\" + 0.012*\"climat\"')\n",
      "(2, '0.030*\"brazil\" + 0.020*\"climat\" + 0.017*\"commit\" + 0.014*\"brazilian\" + 0.012*\"effort\" + 0.011*\"glasgow\" + 0.011*\"pact\" + 0.010*\"unit\" + 0.009*\"chang\" + 0.009*\"communic\"')\n",
      "(3, '0.025*\"account\" + 0.025*\"energi\" + 0.024*\"sourc\" + 0.018*\"renew\" + 0.013*\"solar\" + 0.013*\"biomass\" + 0.012*\"electr\" + 0.012*\"demand\" + 0.012*\"wind\" + 0.012*\"transport\"')\n",
      "(4, '0.029*\"approach\" + 0.026*\"brazilian\" + 0.021*\"brazil\" + 0.019*\"emiss\" + 0.015*\"adapt\" + 0.014*\"sector\" + 0.013*\"subsequ\" + 0.012*\"consist\" + 0.011*\"govern\" + 0.011*\"product\"')\n",
      "(5, '0.029*\"institut\" + 0.027*\"nation\" + 0.026*\"chang\" + 0.025*\"climat\" + 0.016*\"polici\" + 0.015*\"plan\" + 0.012*\"implement\" + 0.012*\"brazilian\" + 0.011*\"includ\" + 0.011*\"develop\"')\n",
      "(6, '0.023*\"emiss\" + 0.021*\"target\" + 0.021*\"temperatur\" + 0.020*\"increas\" + 0.019*\"level\" + 0.019*\"account\" + 0.017*\"relat\" + 0.016*\"implement\" + 0.016*\"nation\" + 0.016*\"contribut\"')\n",
      "(7, '0.042*\"agreement\" + 0.034*\"pari\" + 0.031*\"articl\" + 0.030*\"applic\" + 0.029*\"paragraph\" + 0.026*\"parti\" + 0.024*\"emiss\" + 0.018*\"target\" + 0.017*\"methodolog\" + 0.016*\"brazil\"')\n",
      "(8, '0.038*\"climat\" + 0.025*\"chang\" + 0.023*\"global\" + 0.017*\"temperatur\" + 0.017*\"brazil\" + 0.017*\"increas\" + 0.015*\"implement\" + 0.013*\"emiss\" + 0.013*\"anthropogen\" + 0.011*\"contribut\"')\n",
      "(9, '0.039*\"nation\" + 0.031*\"contribut\" + 0.021*\"determin\" + 0.021*\"brazil\" + 0.017*\"climat\" + 0.016*\"brazilian\" + 0.015*\"agreement\" + 0.015*\"articl\" + 0.015*\"parti\" + 0.013*\"includ\"')\n"
     ]
    }
   ],
   "source": [
    "# show the words most strongly associated with each topic\n",
    "for topic in lda_model.print_topics():\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2e85433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9859353303909302\t \n",
      "Topic: 0.039*\"nation\" + 0.031*\"contribut\" + 0.021*\"determin\" + 0.021*\"brazil\" + 0.017*\"climat\" + 0.016*\"brazilian\" + 0.015*\"agreement\" + 0.015*\"articl\" + 0.015*\"parti\" + 0.013*\"includ\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[12]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac3b6c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pickle\n",
    "import re \n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7fa3359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serva\\Downloads\\Anaconda\\envs\\py39\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el374824448358878086625121802\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el374824448358878086625121802_data = {\"mdsDat\": {\"x\": [-0.07379553768974263, 0.007044967878567144, 0.036073361155679357, 0.036352183410080494, -0.08499127142905522, -0.15156883072356309, 0.005098209078030634, 0.07962207802997003, 0.11365437412775475, 0.03251046616227872], \"y\": [0.01835061132033553, 0.004532865502191535, 0.14265437793039043, -0.09582979812217743, 0.010312723075092964, -0.04505522162141886, 0.0006787491882271569, 0.03174710971531347, -0.08174269653286945, 0.014351279544915024], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [27.584760431720895, 15.510337123493825, 11.184531873994882, 9.814348026068686, 9.095155283035556, 8.871864281815158, 5.618651158231967, 5.139272002010428, 4.320794167849238, 2.860285651779363]}, \"tinfo\": {\"Term\": [\"agreement\", \"climat\", \"articl\", \"plan\", \"pari\", \"chang\", \"paragraph\", \"account\", \"brazil\", \"temperatur\", \"approach\", \"applic\", \"increas\", \"target\", \"nation\", \"sourc\", \"energi\", \"brazilian\", \"institut\", \"relat\", \"parti\", \"adapt\", \"global\", \"commit\", \"year\", \"determin\", \"emiss\", \"renew\", \"refer\", \"level\", \"submit\", \"convent\", \"latest\", \"aim\", \"ambiti\", \"rank\", \"unit\", \"educ\", \"health\", \"rat\", \"index\", \"frame\", \"condit\", \"exampl\", \"need\", \"confer\", \"determin\", \"compon\", \"framework\", \"mobil\", \"discuss\", \"awar\", \"citizen\", \"ampl\", \"right\", \"tribal\", \"women\", \"alia\", \"deal\", \"special\", \"nation\", \"popul\", \"contribut\", \"social\", \"improv\", \"peopl\", \"updat\", \"adopt\", \"unfccc\", \"indigen\", \"articl\", \"achiev\", \"level\", \"agreement\", \"brazilian\", \"parti\", \"pari\", \"brazil\", \"develop\", \"consid\", \"refer\", \"includ\", \"andor\", \"result\", \"climat\", \"object\", \"action\", \"applic\", \"inform\", \"chang\", \"emiss\", \"consist\", \"govern\", \"greenhous\", \"implement\", \"paragraph\", \"countri\", \"complement\", \"year\", \"knowledg\", \"system\", \"advantag\", \"avoid\", \"instrument\", \"risk\", \"damag\", \"opportun\", \"emerg\", \"loss\", \"strateg\", \"incorpor\", \"criteria\", \"subnat\", \"support\", \"entiti\", \"mainstream\", \"cobenefit\", \"base\", \"intent\", \"strive\", \"itmo\", \"coordin\", \"voluntari\", \"rule\", \"estat\", \"resourc\", \"tourism\", \"adapt\", \"plan\", \"refer\", \"diversif\", \"mitig\", \"transfer\", \"infrastructur\", \"human\", \"period\", \"cycl\", \"build\", \"goal\", \"quantifi\", \"effort\", \"action\", \"indic\", \"climat\", \"implement\", \"sector\", \"chang\", \"take\", \"brazil\", \"govern\", \"gas\", \"nation\", \"includ\", \"inform\", \"point\", \"feder\", \"polici\", \"measur\", \"econom\", \"emiss\", \"parti\", \"develop\", \"event\", \"precipit\", \"extrem\", \"frequenc\", \"suffer\", \"rainforest\", \"tropic\", \"equatori\", \"subtrop\", \"particular\", \"respect\", \"small\", \"biom\", \"part\", \"south\", \"sixth\", \"especi\", \"studi\", \"publish\", \"lead\", \"greater\", \"variabl\", \"find\", \"carri\", \"ecolog\", \"occur\", \"like\", \"intens\", \"align\", \"august\", \"mean\", \"import\", \"principl\", \"global\", \"climat\", \"temperatur\", \"interfer\", \"chang\", \"increas\", \"histor\", \"anthropogen\", \"communic\", \"establish\", \"implement\", \"respons\", \"unfccc\", \"countri\", \"brazil\", \"emiss\", \"develop\", \"contribut\", \"averag\", \"brazilian\", \"nation\", \"includ\", \"measur\", \"level\", \"report\", \"territori\", \"greenhous\", \"ipcc\", \"spite\", \"food\", \"protect\", \"subsequ\", \"ageclass\", \"harvest\", \"wood\", \"disturb\", \"accur\", \"illeg\", \"landown\", \"voluntarili\", \"preserv\", \"restor\", \"elimin\", \"doubl\", \"choos\", \"have\", \"great\", \"decoupl\", \"ecosystem\", \"advanc\", \"enhanc\", \"deforest\", \"fragil\", \"approach\", \"code\", \"agenda\", \"strengthen\", \"defin\", \"law\", \"environment\", \"view\", \"land\", \"secur\", \"product\", \"brazilian\", \"manag\", \"challeng\", \"forest\", \"ensur\", \"energi\", \"establish\", \"consist\", \"adapt\", \"brazil\", \"potenti\", \"sector\", \"emiss\", \"commit\", \"address\", \"govern\", \"remov\", \"water\", \"area\", \"implement\", \"ipcc\", \"sourc\", \"reduc\", \"contribut\", \"inform\", \"global\", \"singleyear\", \"preindustri\", \"confid\", \"high\", \"evalu\", \"margin\", \"pool\", \"coverag\", \"pfcs\", \"hfcs\", \"multiyear\", \"panel\", \"detail\", \"translat\", \"general\", \"pursu\", \"hold\", \"collect\", \"method\", \"biennial\", \"btrs\", \"averag\", \"guidanc\", \"surfac\", \"government\", \"scope\", \"target\", \"descript\", \"economywid\", \"give\", \"relat\", \"account\", \"temperatur\", \"respons\", \"increas\", \"guidelin\", \"level\", \"measur\", \"compar\", \"assumpt\", \"emiss\", \"appropri\", \"implement\", \"global\", \"consist\", \"polici\", \"methodolog\", \"effort\", \"contribut\", \"nation\", \"applic\", \"estim\", \"parti\", \"accord\", \"greenhous\", \"sector\", \"determin\", \"agreement\", \"joint\", \"agre\", \"tier\", \"warm\", \"join\", \"aspir\", \"acknowledg\", \"stock\", \"prioriti\", \"member\", \"timehorizon\", \"region\", \"fifth\", \"paragraph\", \"depend\", \"identifi\", \"aggreg\", \"stipul\", \"address\", \"calcul\", \"longterm\", \"repres\", \"neutral\", \"reach\", \"organ\", \"integr\", \"agreement\", \"state\", \"economywid\", \"previous\", \"pari\", \"applic\", \"articl\", \"target\", \"ipcc\", \"methodolog\", \"parti\", \"emiss\", \"inform\", \"potenti\", \"accord\", \"reduc\", \"cover\", \"global\", \"brazil\", \"term\", \"includ\", \"determin\", \"valu\", \"gas\", \"contribut\", \"year\", \"nation\", \"individu\", \"actor\", \"capita\", \"allow\", \"reconstruct\", \"carbon\", \"attribut\", \"notil\", \"accumul\", \"fixat\", \"recov\", \"crop\", \"nitrogen\", \"farm\", \"billion\", \"vast\", \"cleanest\", \"plant\", \"channel\", \"cattl\", \"agroforestri\", \"soil\", \"mix\", \"breed\", \"maintain\", \"seri\", \"structur\", \"degrad\", \"organ\", \"continu\", \"forest\", \"relat\", \"land\", \"increas\", \"sustain\", \"plan\", \"term\", \"temperatur\", \"sector\", \"agricultur\", \"estim\", \"econom\", \"includ\", \"approach\", \"contribut\", \"assumpt\", \"global\", \"climat\", \"chang\", \"determin\", \"account\", \"emiss\", \"indic\", \"brazil\", \"growth\", \"implement\", \"methodolog\", \"measur\", \"institut\", \"mcti\", \"research\", \"scienc\", \"decre\", \"adaptabrasil\", \"inp\", \"futur\", \"ministri\", \"space\", \"consolid\", \"tool\", \"teach\", \"innov\", \"network\", \"octob\", \"communiti\", \"engag\", \"green\", \"set\", \"manner\", \"arrang\", \"dialogu\", \"local\", \"civil\", \"particip\", \"undertak\", \"committe\", \"june\", \"process\", \"impact\", \"avail\", \"public\", \"chang\", \"polici\", \"nation\", \"climat\", \"plan\", \"better\", \"develop\", \"implement\", \"includ\", \"brazilian\", \"inform\", \"parti\", \"best\", \"technolog\", \"adapt\", \"brazil\", \"provid\", \"growth\", \"effort\", \"understand\", \"contribut\", \"solar\", \"biomass\", \"wind\", \"demand\", \"issu\", \"intermitt\", \"affect\", \"revolut\", \"reflect\", \"uncondit\", \"instal\", \"incent\", \"equiti\", \"remain\", \"nonetheless\", \"decarbonis\", \"capac\", \"rapid\", \"compens\", \"incentiv\", \"invest\", \"biofuel\", \"use\", \"post\", \"market\", \"fuel\", \"renovabio\", \"transport\", \"electr\", \"renew\", \"energi\", \"sourc\", \"account\", \"sector\", \"consider\", \"place\", \"result\", \"time\", \"take\", \"best\", \"gas\", \"technolog\", \"countri\", \"emiss\", \"brazil\", \"implement\", \"includ\", \"greenhous\", \"nation\", \"current\", \"period\", \"brazilian\", \"monitor\", \"decad\", \"combat\", \"make\", \"embodi\", \"glasgow\", \"conserv\", \"pact\", \"secretariat\", \"better\", \"republ\", \"commit\", \"march\", \"absolut\", \"ambit\", \"pleas\", \"bras\\u00edlia\", \"unit\", \"provid\", \"communic\", \"import\", \"confirm\", \"light\", \"protect\", \"indigen\", \"context\", \"ambiti\", \"land\", \"adopt\", \"cover\", \"world\", \"brazil\", \"effort\", \"climat\", \"current\", \"brazilian\", \"area\", \"chang\", \"countri\", \"mitig\", \"agreement\"], \"Freq\": [21.0, 34.0, 18.0, 18.0, 18.0, 24.0, 12.0, 10.0, 35.0, 12.0, 11.0, 17.0, 15.0, 10.0, 39.0, 9.0, 7.0, 23.0, 4.0, 9.0, 21.0, 17.0, 17.0, 5.0, 10.0, 19.0, 28.0, 4.0, 15.0, 16.0, 2.736878372714449, 4.3912703766925825, 1.8049686998969023, 1.8031013262169375, 2.8780517099851886, 1.7442359989802043, 3.33063403049822, 1.6978139475992695, 1.6884283761513965, 1.6858489497921345, 1.6801888085993473, 1.693451989681426, 1.6616837678646788, 1.6444928624177935, 4.317520127457877, 1.5937922835578464, 12.94467387662787, 2.13257024668521, 2.547492970586667, 0.9912134686549732, 0.9912112805470175, 0.9912097982803377, 0.9912065514104678, 0.9912052103120432, 0.9912049985596604, 0.9912042221342567, 0.9912034457088531, 0.9912016105215353, 0.9912009046802592, 0.9912002694231108, 23.437654948695116, 3.396228142619707, 18.990019193397377, 3.4600757210876925, 2.4773882503745965, 1.8923733074488833, 4.122129427753311, 3.1445079210468085, 3.1970659918088558, 2.1986297905441363, 8.924093550925917, 3.5944707234160975, 7.61438304093438, 9.247541080636312, 9.86302394458, 8.878949072254667, 8.035713250771725, 12.579161030228944, 6.603284047177005, 3.544525959394564, 6.388028997608319, 8.170999307127039, 3.165091099666476, 3.6614172274225307, 10.08647861108451, 3.1139596752916168, 4.458324168572978, 6.030961400909287, 5.6144523693239945, 6.974716925526568, 7.560730069184896, 4.429677741552023, 4.534950579839403, 4.3241770577007275, 4.887234266705759, 4.058816029963054, 3.7271787650947013, 1.6577294360501849, 7.11978166850772, 1.5716609560732737, 1.5135053548914357, 1.5076615369264732, 1.5011687409972947, 1.4987488850509765, 1.4732320494099926, 1.4690551269010652, 1.4655338499381785, 1.467448557185344, 1.461717135599703, 0.8961630026553603, 0.8961625263995158, 0.8961591926086037, 0.8961565732014585, 0.8961565732014585, 0.8961483181001524, 0.8961476830923597, 2.293152047666053, 4.008990888081152, 0.8507664543018068, 0.8409356605339311, 0.837076003793469, 0.8352399581366335, 0.8320123722779053, 0.8312213906960295, 0.8164469025094504, 2.4317409109197667, 0.8136286585491398, 9.007452188880265, 9.205910539348517, 6.8958677606504875, 2.3335428295891596, 4.9489316454743335, 1.6167398417784915, 1.5428874829670423, 2.1895524312981514, 2.983058327902037, 1.7832633328441807, 1.4823663190051681, 1.7484790347234869, 1.5377151857429396, 3.8114799692397203, 3.1920397100082636, 2.359010452126203, 6.439769603442916, 4.777602097929025, 4.037957086052491, 4.880154268942744, 2.2519851274682274, 5.505631864764011, 3.263935927314069, 2.5415913852478, 5.155628269542155, 3.8790317807312538, 3.2928068741164918, 2.251548400858746, 2.469267807697457, 2.522303341046148, 2.4584045706345026, 2.2499410373832838, 2.762208332644944, 2.5503167098244277, 2.4302468963353148, 1.5931147768638234, 1.5929729407106306, 1.5928810162303935, 1.5928724305068347, 1.5760360555604889, 1.5623965461622156, 1.5581467274768814, 1.5515425889153869, 1.5469791051293682, 1.5199094635113441, 1.5181333634977963, 1.5113291203392225, 1.8411175230095322, 0.834516360477827, 0.8345092629463516, 0.8344915763558203, 0.8344828761559473, 0.8344697686179807, 0.8344626138483483, 0.8344598091786525, 0.83445751965237, 0.8344523109800777, 0.834446873355157, 0.834437200106614, 0.8344367422013576, 0.8344213451371086, 0.8344215168515798, 0.8343924971059508, 0.8343890628165272, 0.8343739519430636, 1.5069953905156397, 1.8071591547131152, 1.5165269173817717, 5.634183041495022, 9.445268505538527, 4.24292583750838, 1.718877883172804, 6.137563326894579, 4.173199230389333, 1.5685197697280984, 3.101677348119745, 1.739699522042556, 1.591079387998797, 3.605500427902313, 1.5566654039721886, 1.6709923265007338, 2.3104427076272427, 4.179271054090177, 3.2239964345184715, 2.3908936848055364, 2.6009732899916487, 1.6488600483106395, 1.8043832185720563, 1.8599766944263514, 1.7734135978846444, 1.7103005163848495, 1.692911907699196, 1.592861211828051, 1.5932300545121407, 1.5967885507365134, 1.593033155251857, 1.5882510134166703, 1.5255770020806574, 2.3388752601183196, 2.830709930476935, 0.8728800505264266, 0.8701005392538615, 0.8625183097502664, 0.8583392989818801, 0.8577420104373672, 0.8554902748144609, 0.8488957914020523, 0.8385865368795935, 0.845068564098665, 0.8353229968731343, 0.8404137114474403, 0.8316086777978049, 0.8390099929608908, 0.8301699015073478, 0.8284585985062847, 0.8282645751588701, 0.8335230950667801, 0.8330166655011626, 0.8155809329259083, 0.8255807947949699, 0.822740208609007, 6.252036372986674, 0.8197010285023408, 0.7965844751377215, 0.7958312848405876, 1.6511729406840416, 1.59776805197776, 1.5693689204128642, 1.5195412335832472, 2.324828833654087, 1.5227857379053498, 2.3521500130879422, 5.563839427115601, 1.5806269958144346, 1.569987404363178, 1.6348962753591847, 1.5152727199401281, 2.227937300730428, 1.6060499307771057, 2.5310840397110796, 3.2624820443080984, 4.613196747626918, 1.5629947285877608, 3.093673796336826, 4.009399706750753, 1.5967626263063794, 1.621779131828906, 2.4193344268688213, 1.8576119741941888, 1.4654710502200012, 1.5502207296367045, 2.188329817583258, 1.7449070613084867, 1.6018776503034524, 1.5814735061683884, 1.6449062326703459, 1.6159348251488255, 1.6052475189214768, 1.6264963790440454, 2.3163623381217677, 0.8719326033582405, 0.8701005714287344, 0.8689201768725283, 0.8679252196945526, 0.862736696746232, 0.8608830676923537, 0.8604056967708849, 0.8562596074377374, 0.8552429600443362, 0.8514462414343309, 0.8508696354500138, 0.8507421007069537, 0.8502058031487278, 1.2564731264478575, 1.2424000864609124, 1.2395538275053917, 0.782213401072294, 0.7789750426001534, 0.7597328891495067, 2.997150988589422, 1.2449407274883555, 0.9062908355028523, 0.8589147504607747, 0.8926479692733384, 4.187860405868585, 0.8809004368895941, 0.8603854029212592, 0.866859699498154, 3.339751013240816, 3.7156977426513538, 4.160054480603557, 1.6853003217927371, 4.042136788080696, 1.7703823794392282, 3.829854928983954, 3.0834823281715824, 1.7332582259181182, 2.2642799417876116, 4.504826133347, 1.8549269293438, 3.258920051635627, 2.806819999867554, 2.1731277889177782, 2.348170992497817, 2.1243063721817217, 2.1457122875304107, 3.1537807818210712, 3.2010658238129936, 2.2067137376839763, 1.3941211884505467, 2.303345974681155, 1.5449415414081737, 1.7157967646810668, 1.832719500025952, 1.8822180610839208, 1.5954767644360093, 1.56992887574338, 1.4561996526259426, 1.309460408242501, 1.2968862819818763, 0.8296589627644819, 0.8286620078908575, 0.8274687312723769, 0.8272229204660282, 0.8268148400213549, 0.8265717533835288, 1.2646815249311285, 0.8249360717969911, 0.7286374409708904, 5.714626334226186, 0.7070082239442217, 0.6841582161969948, 0.6826854852909124, 0.675725688743964, 2.4258486414537086, 0.6546714528867815, 1.3105819484232222, 0.8879407321914236, 1.2767804653958086, 1.5864914571378246, 0.8307243850736391, 0.8268752257569374, 8.19585278146183, 0.8265805615284183, 0.8361022569595609, 0.8353660050135414, 6.6285035116980415, 5.889673049366443, 5.983105854906854, 3.4281503314429416, 2.945550438447356, 3.2245096538229183, 5.12165257648235, 4.695709577195641, 2.7445113417663385, 1.3471479176672876, 1.6624779610150857, 1.6497255833274707, 1.4988385199516419, 2.3411319039067138, 3.194707976631502, 1.441387712729686, 2.309562967789122, 2.2098620320896303, 1.2892205625651256, 1.3889791598316774, 1.5472981181594072, 1.3742970719683274, 1.3280164453561076, 2.397509244018241, 1.2393804960900305, 0.6476408512529442, 0.6412496756673541, 0.6407662040954095, 1.6669348743346595, 0.6325155578535503, 0.5970613976378684, 0.5951231982338899, 0.5903218372797269, 0.5875198069631542, 0.5832241157523131, 0.5815906523849392, 0.5783740453391948, 0.5755316442549875, 0.574647397925712, 0.571542701868311, 0.5715034812649964, 0.5684304147263975, 0.5682006694034621, 0.5668789005668292, 0.5544267615719431, 0.5494412018019197, 0.5463646847703606, 0.6451811673462426, 0.6522841221213127, 0.632392145222006, 0.6187703466218173, 0.5806461949535077, 0.5858232570828241, 1.1196038790107858, 1.8096326560829987, 1.1303558451077333, 2.4802614965520338, 1.1565361153941993, 2.573880731614782, 1.2313440679527856, 1.9306927415270176, 1.802491745885366, 1.0986716935004013, 1.0145089944608974, 1.2570672629384527, 1.6924232057661668, 1.3254951389971377, 1.8803326817559964, 1.0864406160878342, 1.3473629831819054, 1.5123985662561956, 1.2306763975649806, 1.1295804043231372, 0.8943163054388648, 1.0559756386597838, 0.7952745631808955, 0.9664971101657462, 0.7525936905093032, 0.8880727534437566, 0.8192727417193105, 0.7874587365602416, 3.254635195435256, 1.191328443097316, 1.1513182546843221, 1.1514848967355962, 1.108189734805537, 0.6377157750897586, 0.6342462749578355, 0.6304653730129254, 0.623305919202081, 0.6207461121366771, 0.6169421706657385, 0.6116680128649045, 0.6106186097958018, 0.6086057547661137, 0.6066778514134481, 0.5845758973300772, 0.5841277838089902, 0.5826799757852318, 0.5830893744863258, 0.581815099330987, 0.581631519545966, 0.5810364895952047, 0.5779594504306285, 0.5784973023795796, 0.5779267848012595, 0.5781925809771078, 0.5770610667204931, 0.5765233199748572, 0.5597164065503872, 1.1364173623229565, 1.1980689247053833, 1.2199455332875995, 1.1340658578216452, 2.8952886547998613, 1.831324605247312, 3.087409686575131, 2.8667524659589647, 1.694118125955803, 0.6613104064108201, 1.273194086071881, 1.350374183794146, 1.2902686893318729, 1.3155344227132009, 1.147655075249119, 1.1106999911094824, 0.6911836767862284, 0.6795716504645907, 0.8498602590500277, 0.9288761546225024, 0.6700250282285827, 0.705210382199954, 0.7075431605111602, 0.6733904296801172, 0.6852691990074401, 1.214351498741236, 1.2109346374383203, 1.1822754932439998, 1.183036859558501, 0.6443004944819398, 0.6372291544732378, 0.6364703089463717, 0.6350826374653992, 0.6331532619889385, 0.6317173417481425, 0.6301497656338412, 0.6341510958733537, 0.6288930424368625, 0.6231551990871497, 0.6228779566716288, 0.6263705300522878, 0.6198560187648849, 0.6185265465212431, 0.6167990551773159, 0.6216280440236995, 0.6151126482494071, 0.6206023488022643, 0.6195946971133753, 0.6104667924134992, 0.6172677890044186, 0.6056653111093798, 0.5916211629314686, 1.1788525289815464, 1.183176077794912, 1.7533112852060908, 2.3296043787908167, 2.311151505712079, 2.334618888762278, 1.171877111576013, 0.6891414589931147, 0.6484935372547564, 0.7047520776767154, 0.6809201533549996, 0.678872654654443, 0.6445551824817779, 0.6769134719698053, 0.6411322182193244, 0.6752858834200498, 0.6939547039728649, 0.6954511673412486, 0.6688600419433216, 0.659052674414914, 0.6468429520458734, 0.6464482497714238, 0.6423109738969915, 0.6410878169774703, 0.6391609622886447, 0.4721270468715131, 0.47149618489128753, 0.4642477859611277, 0.462350574460431, 0.46105975045782743, 0.6832452764266016, 0.44433720923259035, 0.6667484800957689, 0.34896755911426225, 0.4710698722013231, 0.4875777640210651, 1.0769213615704378, 0.2953236514291809, 0.45408496218557226, 0.44177804496216516, 0.21594950989341868, 0.19943709497859363, 0.6119738864670117, 0.3725771200741557, 0.5465361474124112, 0.44508069481659923, 0.1795879532988058, 0.4304960405915918, 0.3751783827959042, 0.3567852239595683, 0.19267033980446285, 0.33897228014880615, 0.4239210119527293, 0.4492487342545623, 0.4819510630134359, 0.3357261616639862, 1.8988871244519192, 0.7437005847227178, 1.2706933311899684, 0.46189410780324613, 0.8602734213896629, 0.4061585979938336, 0.5645306298161186, 0.41841630277170916, 0.3974405591078837, 0.4062319921645341], \"Total\": [21.0, 34.0, 18.0, 18.0, 18.0, 24.0, 12.0, 10.0, 35.0, 12.0, 11.0, 17.0, 15.0, 10.0, 39.0, 9.0, 7.0, 23.0, 4.0, 9.0, 21.0, 17.0, 17.0, 5.0, 10.0, 19.0, 28.0, 4.0, 15.0, 16.0, 3.420341604190129, 5.968228564753268, 2.4946160046896426, 2.4934674746742016, 4.0587730067513395, 2.469672299559111, 4.730850286496086, 2.4807891682094247, 2.482599071400347, 2.482342594521707, 2.4795888122395753, 2.507552833530335, 2.4885668061709145, 2.480864430912973, 6.58917218579557, 2.453302831902989, 19.98400098991777, 3.303070877692599, 4.03025690358675, 1.6282466881508022, 1.6282445254672562, 1.6282430448661627, 1.6282399207061578, 1.6282385794468481, 1.6282384274905368, 1.6282376115211392, 1.6282369034624762, 1.6282350818385727, 1.6282343986408234, 1.6282337051343516, 39.81349763991342, 5.658181905797415, 33.128600737825124, 5.859962072188618, 4.153900563260553, 3.189792244957354, 7.341299846863406, 5.578430710380973, 5.702367852246423, 3.831166204089136, 18.19338869270337, 6.700934884325801, 16.25292626844756, 21.880025038239676, 23.980520511751028, 21.10122495325466, 18.78749163600252, 35.437267867308044, 15.255003618026343, 6.658609359585247, 15.059790456054861, 22.170904000032824, 5.858463865478647, 7.276982370340775, 34.81676049056799, 5.736853282974311, 9.966943044002635, 17.803698544162874, 16.131662165712434, 24.763081828418446, 28.841081455424675, 10.826325256350371, 13.837349708421947, 12.154689775550448, 22.018073587093557, 12.068142715809254, 10.814099645121903, 2.3621950210397413, 10.374106666718914, 2.3211495665910986, 2.3112064225548736, 2.3095898187477557, 2.3040786957393395, 2.3087957437213995, 2.3051673155602694, 2.304610318153236, 2.2998432863137626, 2.303277427462485, 2.297082747253782, 1.541840534382317, 1.541840110342693, 1.5418370155575742, 1.5418344092172414, 1.541834474885968, 1.541826807992083, 1.5418262151969138, 4.026740009986174, 7.109695383771022, 1.5466249657946158, 1.5476611434284009, 1.5480710161791322, 1.5482661299365368, 1.5486023917146945, 1.5486799987663167, 1.524927246955016, 4.55002452974227, 1.5245236466442993, 17.405325103699276, 18.42299872889887, 15.059790456054861, 4.819532228208558, 11.18315435042186, 3.261352910245547, 3.114671327514838, 4.718199336269619, 7.160040370540556, 3.932388008239161, 3.059933227210642, 3.8464207924792295, 3.2531644625676783, 12.329129056523207, 9.966943044002635, 6.412958317288182, 34.81676049056799, 22.018073587093557, 17.034157244860182, 24.763081828418446, 6.1120115063708935, 35.437267867308044, 13.837349708421947, 7.866915909473612, 39.81349763991342, 22.170904000032824, 16.131662165712434, 6.3523591237441694, 8.865957795549079, 13.193690116621076, 12.799188007886178, 9.397035043477207, 28.841081455424675, 21.10122495325466, 15.255003618026343, 2.2448243276966653, 2.244808925546517, 2.244783903410615, 2.244780709452057, 2.2457939297274034, 2.2465701029996112, 2.2467363147110513, 2.247224451426828, 2.247535376965181, 2.251445512596212, 2.253019552482067, 2.2542517589524915, 3.0615866251042956, 1.4859760083994962, 1.4859739653117447, 1.48597013144963, 1.4859654568215126, 1.4859674626816193, 1.4859665450910373, 1.4859628138277656, 1.4859625211365777, 1.48596328903719, 1.4859626843293314, 1.485957939772497, 1.485957450507948, 1.4859563943138736, 1.4859571078025238, 1.4859521919202916, 1.4859500098600236, 1.485944955628446, 2.8908100561100243, 3.661202177761418, 3.0565025497085356, 17.030145366265156, 34.81676049056799, 12.933619748136831, 3.992294087858871, 24.763081828418446, 15.644525680847414, 3.7229978096834806, 10.277137521524976, 4.428896912066506, 4.799423508210419, 22.018073587093557, 4.758405728759578, 5.702367852246423, 10.814099645121903, 35.437267867308044, 28.841081455424675, 15.255003618026343, 33.128600737825124, 6.771801753959943, 23.980520511751028, 39.81349763991342, 22.170904000032824, 12.799188007886178, 16.25292626844756, 5.5243005385810235, 6.252163488888107, 12.154689775550448, 9.43262998893911, 2.3550615394058827, 2.335488277118251, 3.8339770844292285, 4.791920796113339, 1.5463971564423171, 1.5462478161989275, 1.545775768795948, 1.545608415141311, 1.5454675246446996, 1.5524625547962925, 1.5531115285648869, 1.540134824526069, 1.5534909020485896, 1.539824828352781, 1.5539464626152877, 1.5394133901069837, 1.5540786522892578, 1.5395246129680233, 1.5383758265564493, 1.5394921478217014, 1.554614763928689, 1.55466146023013, 1.53361897007553, 1.5553854294004652, 1.5556603056601386, 11.860692908569481, 1.5559604732431, 1.5279871470015678, 1.5303603403212902, 3.186601362816958, 3.2494635107752123, 3.2168847728013565, 3.1161035300131035, 5.086849780033577, 3.209318580612953, 6.264727530890593, 23.980520511751028, 3.919862589108923, 4.038700358127725, 4.442965184851839, 4.0747987786530535, 7.937691148047022, 4.799423508210419, 10.826325256350371, 17.405325103699276, 35.437267867308044, 4.77868760786753, 17.034157244860182, 28.841081455424675, 5.086460547186594, 5.413333086924299, 13.837349708421947, 8.136034350872952, 4.8925806456485414, 5.648948890047302, 22.018073587093557, 9.43262998893911, 9.256974671405072, 7.224223023793926, 33.128600737825124, 16.131662165712434, 17.030145366265156, 2.3302096328838497, 3.981056811694446, 1.5318914858562123, 1.531473633862938, 1.5312061081504884, 1.530983081835653, 1.5304855513191433, 1.5301110361534653, 1.530018030607143, 1.5291826801970707, 1.5289803689355077, 1.5282188485634733, 1.5281002700568178, 1.5280699900070491, 1.5279645005412312, 2.3522753924486333, 2.353822257913988, 2.3574252979008317, 1.5151304456957182, 1.515373135054434, 1.5095551004714183, 6.771801753959943, 3.1515138644345795, 2.2956180955501795, 2.1879851018395544, 2.293515062068539, 10.941848380044572, 2.3283737011768895, 2.2927267097696062, 2.357640617316381, 9.22411847869618, 10.470295431002246, 12.933619748136831, 4.758405728759578, 15.644525680847414, 5.612215387595549, 16.25292626844756, 12.799188007886178, 5.54621593165694, 8.602151611802329, 28.841081455424675, 6.318770457365087, 22.018073587093557, 17.030145366265156, 10.826325256350371, 13.193690116621076, 11.144286554409966, 12.329129056523207, 33.128600737825124, 39.81349763991342, 17.803698544162874, 5.309436375922105, 21.10122495325466, 7.20223173341901, 12.154689775550448, 17.034157244860182, 19.98400098991777, 21.880025038239676, 2.259624566853124, 2.270223871905497, 2.284798335860573, 2.2831561068184394, 1.4921961935557904, 1.4923679595346893, 1.4925786729224042, 1.4926287447057582, 1.492703471087043, 1.4927486110797104, 2.288673621980326, 1.4930403719755398, 1.5029569176472521, 12.068142715809254, 1.504699432417615, 1.5061991884891845, 1.5070101676343794, 1.5061016388661053, 5.413333086924299, 1.5082835307655862, 3.0928301257373603, 2.1417160956612142, 3.129729023602693, 3.9029248651748016, 2.1505330455565175, 2.158164077953106, 21.880025038239676, 2.2515408917853095, 2.2927267097696062, 2.292285364501691, 18.78749163600252, 17.803698544162874, 18.19338869270337, 10.941848380044572, 9.43262998893911, 11.144286554409966, 21.10122495325466, 28.841081455424675, 16.131662165712434, 4.77868760786753, 7.20223173341901, 7.224223023793926, 6.086991176745776, 17.030145366265156, 35.437267867308044, 5.8705933246014865, 22.170904000032824, 19.98400098991777, 4.891331336065468, 7.866915909473612, 33.128600737825124, 10.374106666718914, 39.81349763991342, 3.2647170460984536, 1.9939671963195011, 1.361047284165168, 1.3626509699364884, 1.3625657939893148, 3.54603132154291, 1.3641147477660016, 1.3807446181839527, 1.3813258960136103, 1.3827751400414792, 1.3836093523094117, 1.384904725822643, 1.3853981959277295, 1.386370316738341, 1.387220794240656, 1.3874904656254299, 1.3884159957414504, 1.3884318775852753, 1.389358036398213, 1.389423513864911, 1.3898184527822197, 1.3935643701198577, 1.3950602803049799, 1.3959892270418173, 2.028998988556156, 2.2030174008200594, 2.1827417598248418, 2.1960921423839923, 2.1505330455565175, 2.2026904818376902, 4.442965184851839, 9.22411847869618, 5.086849780033577, 15.644525680847414, 5.288182070406012, 18.42299872889887, 5.8705933246014865, 12.933619748136831, 17.034157244860182, 6.035094009593433, 5.309436375922105, 9.397035043477207, 22.170904000032824, 11.860692908569481, 33.128600737825124, 8.602151611802329, 17.030145366265156, 34.81676049056799, 24.763081828418446, 19.98400098991777, 10.470295431002246, 28.841081455424675, 6.412958317288182, 35.437267867308044, 5.198350134427608, 22.018073587093557, 11.144286554409966, 12.799188007886178, 4.680884602378126, 2.0618161239127617, 2.072439034961201, 2.0727611528262258, 2.043099027376484, 1.3919125665813947, 1.392929624360436, 1.393926163263504, 1.3954037976570381, 1.3962114591718036, 1.397293836864349, 1.398553013702219, 1.3990512813820757, 1.39946193623928, 1.3999353578959828, 1.3848705253813514, 1.3844281944607288, 1.3834296622580042, 1.385208197120438, 1.3849646803402471, 1.385769763068383, 1.3863825791337048, 1.3850614535150345, 1.386442609095883, 1.3855551089169105, 1.386240939780382, 1.3867507242697013, 1.3867548538767882, 1.3875210003572658, 2.929957329431892, 4.517853993892633, 5.000817229700375, 4.573627652122357, 24.763081828418446, 13.193690116621076, 39.81349763991342, 34.81676049056799, 18.42299872889887, 1.9423173345762759, 15.255003618026343, 22.018073587093557, 22.170904000032824, 23.980520511751028, 16.131662165712434, 21.10122495325466, 2.9206250795176203, 2.6679417801077405, 17.405325103699276, 35.437267867308044, 2.9191066162496417, 5.198350134427608, 12.329129056523207, 4.639026570269101, 33.128600737825124, 1.9986259928405599, 2.0004409645531305, 2.000810793692347, 2.026906291913008, 1.3629168523620898, 1.3628554741663812, 1.3629496475777076, 1.3630124100764605, 1.3624674197977844, 1.3635482040423585, 1.3631462726517332, 1.3742625131224886, 1.3633489137339458, 1.3635907275537884, 1.3641138192814484, 1.376170481070195, 1.3638047026642592, 1.3637806037521265, 1.3637423602742544, 1.3775387303509419, 1.3643172715747502, 1.3776078105546177, 1.3781731824958012, 1.3637306777167562, 1.3789517651207668, 1.3815347670292428, 1.3856067064603432, 2.822135771012219, 2.9085395787378907, 4.368927820990069, 7.937691148047022, 9.256974671405072, 10.470295431002246, 17.034157244860182, 2.9267267752604877, 2.0175665093337782, 7.276982370340775, 4.857642920438752, 6.1120115063708935, 2.9206250795176203, 7.866915909473612, 2.6679417801077405, 10.814099645121903, 28.841081455424675, 35.437267867308044, 22.018073587093557, 22.170904000032824, 12.154689775550448, 39.81349763991342, 6.919463898763871, 7.160040370540556, 23.980520511751028, 1.269525757194496, 1.2765080590442794, 1.2797754743949177, 1.2781999707611047, 1.2838307501306248, 1.985991782821039, 1.294875051717469, 2.0002040191818926, 1.3701787962164842, 1.9423173345762759, 2.1405874949753434, 5.086460547186594, 1.4121628879577734, 2.852843450773083, 2.875213755017843, 1.4751363879223458, 1.4919784184201186, 4.730850286496086, 2.9191066162496417, 4.428896912066506, 3.661202177761418, 1.5073013417946979, 3.905736761835341, 3.8339770844292285, 3.831166204089136, 2.300800004273924, 4.0587730067513395, 5.086849780033577, 5.578430710380973, 6.086991176745776, 4.424840744218522, 35.437267867308044, 12.329129056523207, 34.81676049056799, 6.919463898763871, 23.980520511751028, 5.648948890047302, 24.763081828418446, 10.814099645121903, 11.18315435042186, 21.880025038239676], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.4006, -4.9278, -5.8169, -5.8179, -5.3503, -5.8511, -5.2042, -5.8781, -5.8836, -5.8851, -5.8885, -5.8806, -5.8996, -5.91, -4.9447, -5.9413, -3.8467, -5.6501, -5.4723, -6.4162, -6.4162, -6.4162, -6.4162, -6.4162, -6.4162, -6.4162, -6.4162, -6.4162, -6.4162, -6.4162, -3.2531, -5.1847, -3.4635, -5.1661, -5.5002, -5.7696, -4.991, -5.2617, -5.2452, -5.6196, -4.2186, -5.128, -4.3774, -4.183, -4.1186, -4.2237, -4.3235, -3.8754, -4.5198, -5.142, -4.553, -4.3068, -5.2552, -5.1095, -4.0962, -5.2715, -4.9126, -4.6105, -4.6821, -4.4651, -4.3844, -4.9191, -4.8956, -4.9432, -4.8208, -5.0065, -5.0917, -5.3262, -3.8688, -5.3795, -5.4172, -5.4211, -5.4254, -5.427, -5.4442, -5.447, -5.4494, -5.4481, -5.452, -5.9413, -5.9413, -5.9413, -5.9413, -5.9413, -5.9413, -5.9413, -5.0017, -4.4431, -5.9933, -6.0049, -6.0095, -6.0117, -6.0155, -6.0165, -6.0344, -4.943, -6.0379, -3.6336, -3.6118, -3.9007, -4.9843, -4.2325, -5.3512, -5.398, -5.0479, -4.7387, -5.2532, -5.438, -5.2729, -5.4013, -4.4936, -4.671, -4.9734, -3.9691, -4.2677, -4.4359, -4.2465, -5.0198, -4.1259, -4.6487, -4.8988, -4.1916, -4.4761, -4.6399, -5.02, -4.9277, -4.9065, -4.9321, -5.0207, -4.8156, -4.8954, -4.9436, -5.039, -5.0391, -5.0391, -5.0391, -5.0498, -5.0584, -5.0612, -5.0654, -5.0684, -5.086, -5.0872, -5.0917, -4.8943, -5.6856, -5.6856, -5.6856, -5.6856, -5.6856, -5.6856, -5.6856, -5.6856, -5.6856, -5.6857, -5.6857, -5.6857, -5.6857, -5.6857, -5.6857, -5.6857, -5.6857, -5.0945, -4.9129, -5.0882, -3.7758, -3.2592, -4.0594, -4.963, -3.6902, -4.076, -5.0545, -4.3727, -4.951, -5.0403, -4.2222, -5.0621, -4.9912, -4.6672, -4.0745, -4.334, -4.633, -4.5488, -5.0046, -4.9144, -4.8841, -4.9318, -4.968, -4.9782, -5.0391, -5.0389, -5.0367, -5.039, -4.9113, -4.9516, -4.5243, -4.3335, -5.5099, -5.5131, -5.5219, -5.5267, -5.5274, -5.5301, -5.5378, -5.55, -5.5423, -5.5539, -5.5478, -5.5584, -5.5495, -5.5601, -5.5622, -5.5624, -5.5561, -5.5567, -5.5778, -5.5656, -5.5691, -3.5411, -5.5728, -5.6014, -5.6023, -4.8725, -4.9054, -4.9233, -4.9556, -4.5303, -4.9534, -4.5186, -3.6577, -4.9162, -4.9229, -4.8824, -4.9584, -4.5729, -4.9002, -4.4453, -4.1915, -3.8451, -4.9274, -4.2446, -3.9853, -4.906, -4.8905, -4.4905, -4.7547, -4.9918, -4.9356, -4.5908, -4.8173, -4.9028, -4.9156, -4.8763, -4.8941, -4.9007, -4.8114, -4.4579, -5.4349, -5.437, -5.4384, -5.4395, -5.4455, -5.4477, -5.4482, -5.4531, -5.4542, -5.4587, -5.4594, -5.4595, -5.4602, -5.0696, -5.0808, -5.0831, -5.5435, -5.5477, -5.5727, -4.2002, -5.0788, -5.3963, -5.45, -5.4114, -3.8657, -5.4247, -5.4482, -5.4408, -4.092, -3.9853, -3.8723, -4.7759, -3.9011, -4.7267, -3.955, -4.1718, -4.7479, -4.4806, -3.7927, -4.68, -4.1165, -4.2658, -4.5217, -4.4442, -4.5444, -4.5344, -4.1493, -4.1344, -4.5064, -4.9656, -4.4635, -4.8629, -4.758, -4.6921, -4.6654, -4.8307, -4.822, -4.8972, -5.0034, -5.0131, -5.4598, -5.461, -5.4624, -5.4627, -5.4632, -5.4635, -5.0382, -5.4655, -5.5896, -3.53, -5.6197, -5.6526, -5.6547, -5.665, -4.3868, -5.6966, -5.0025, -5.3919, -5.0287, -4.8115, -5.4585, -5.4631, -3.1694, -5.4635, -5.452, -5.4529, -3.3816, -3.4998, -3.4841, -4.041, -4.1927, -4.1022, -3.6395, -3.7264, -4.2634, -4.975, -4.7647, -4.7724, -4.8683, -4.4224, -4.1115, -4.9074, -4.436, -4.4801, -5.019, -4.9444, -4.8365, -4.9551, -4.9893, -3.9418, -4.6016, -5.2506, -5.2606, -5.2613, -4.3052, -5.2743, -5.332, -5.3352, -5.3433, -5.3481, -5.3554, -5.3582, -5.3638, -5.3687, -5.3702, -5.3756, -5.3757, -5.3811, -5.3815, -5.3838, -5.406, -5.4151, -5.4207, -5.2544, -5.2435, -5.2745, -5.2962, -5.3598, -5.351, -4.7032, -4.2231, -4.6937, -3.9079, -4.6708, -3.8708, -4.6081, -4.1583, -4.2271, -4.7221, -4.8018, -4.5874, -4.2901, -4.5344, -4.1848, -4.7333, -4.5181, -4.4025, -4.6087, -4.6944, -4.9279, -4.7618, -5.0453, -4.8503, -5.1005, -4.9349, -5.0156, -5.0552, -3.547, -4.552, -4.5861, -4.586, -4.6243, -5.1769, -5.1824, -5.1883, -5.1998, -5.2039, -5.21, -5.2186, -5.2203, -5.2236, -5.2268, -5.2639, -5.2647, -5.2672, -5.2665, -5.2686, -5.269, -5.27, -5.2753, -5.2744, -5.2754, -5.2749, -5.2769, -5.2778, -5.3074, -4.5992, -4.5463, -4.5282, -4.6012, -3.664, -4.122, -3.5997, -3.6739, -4.1999, -5.1406, -4.4855, -4.4267, -4.4722, -4.4528, -4.5893, -4.6221, -5.0964, -5.1133, -4.8897, -4.8008, -5.1275, -5.0763, -5.073, -5.1225, -5.105, -4.3594, -4.3622, -4.3861, -4.3855, -4.9932, -5.0042, -5.0054, -5.0076, -5.0106, -5.0129, -5.0154, -5.009, -5.0174, -5.0265, -5.027, -5.0214, -5.0318, -5.034, -5.0368, -5.029, -5.0395, -5.0306, -5.0323, -5.0471, -5.036, -5.055, -5.0785, -4.389, -4.3854, -3.9921, -3.7079, -3.7158, -3.7057, -4.395, -4.9259, -4.9867, -4.9035, -4.9379, -4.9409, -4.9928, -4.9438, -4.9981, -4.9462, -4.9189, -4.9168, -4.9558, -4.9705, -4.9892, -4.9898, -4.9963, -4.9982, -5.0012, -4.8916, -4.8929, -4.9084, -4.9125, -4.9153, -4.522, -4.9522, -4.5464, -5.1938, -4.8938, -4.8594, -4.0669, -5.3607, -4.9305, -4.958, -5.6738, -5.7533, -4.6321, -5.1284, -4.7452, -4.9506, -5.8581, -4.9839, -5.1214, -5.1717, -5.7878, -5.2229, -4.9993, -4.9412, -4.871, -5.2325, -3.4998, -4.4372, -3.9015, -4.9135, -4.2916, -5.0421, -4.7128, -5.0123, -5.0638, -5.0419], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.065, 0.9811, 0.9643, 0.9637, 0.9441, 0.9401, 0.937, 0.9087, 0.9024, 0.901, 0.8987, 0.8954, 0.884, 0.8767, 0.8652, 0.8566, 0.8537, 0.8504, 0.8292, 0.7916, 0.7916, 0.7916, 0.7916, 0.7916, 0.7916, 0.7916, 0.7916, 0.7916, 0.7916, 0.7916, 0.758, 0.7775, 0.7314, 0.7611, 0.7711, 0.7658, 0.7108, 0.7147, 0.7093, 0.7326, 0.5756, 0.6651, 0.5297, 0.4267, 0.3995, 0.4223, 0.4386, 0.2522, 0.4506, 0.6574, 0.4303, 0.2897, 0.6722, 0.601, 0.049, 0.6769, 0.4834, 0.2054, 0.2325, 0.0208, -0.0509, 0.3943, 0.1723, 0.2544, -0.2173, 0.1982, 0.2227, 1.5095, 1.4872, 1.4737, 1.4403, 1.4372, 1.4352, 1.4316, 1.416, 1.4134, 1.413, 1.4129, 1.4116, 1.3211, 1.3211, 1.3211, 1.3211, 1.3211, 1.321, 1.321, 1.3006, 1.2907, 1.266, 1.2537, 1.2488, 1.2465, 1.2424, 1.2414, 1.2389, 1.2371, 1.2357, 1.2049, 1.1699, 1.0826, 1.1384, 1.0484, 1.1619, 1.1612, 1.0959, 0.9881, 1.0729, 1.1389, 1.0753, 1.1143, 0.6897, 0.725, 0.8636, 0.1761, 0.3357, 0.4242, 0.2395, 0.8652, 0.0017, 0.4192, 0.7338, -0.1805, 0.1205, 0.2746, 0.8265, 0.5854, 0.2091, 0.2138, 0.4342, -0.4821, -0.2495, 0.0267, 1.8477, 1.8476, 1.8476, 1.8476, 1.8365, 1.8275, 1.8247, 1.8202, 1.8171, 1.7977, 1.7958, 1.7908, 1.6821, 1.6137, 1.6137, 1.6136, 1.6136, 1.6136, 1.6136, 1.6136, 1.6136, 1.6136, 1.6136, 1.6136, 1.6136, 1.6136, 1.6136, 1.6135, 1.6135, 1.6135, 1.5392, 1.4846, 1.4898, 1.0845, 0.8861, 1.0761, 1.3479, 0.7957, 0.8692, 1.3262, 0.9927, 1.2562, 1.0866, 0.3812, 1.0733, 0.9632, 0.6472, 0.053, -0.0005, 0.3374, -0.3539, 0.778, -0.3964, -0.873, -0.3352, 0.1779, -0.0712, 0.947, 0.8235, 0.1609, 0.4121, 1.9274, 1.8955, 1.8271, 1.7949, 1.7494, 1.7463, 1.7379, 1.7332, 1.7325, 1.7254, 1.7172, 1.7134, 1.7125, 1.7097, 1.7067, 1.7055, 1.7049, 1.7037, 1.7024, 1.7014, 1.698, 1.6974, 1.6898, 1.6879, 1.6843, 1.681, 1.6804, 1.67, 1.6675, 1.6639, 1.6114, 1.6036, 1.6031, 1.5383, 1.5758, 1.3417, 0.8604, 1.4131, 1.3765, 1.3216, 1.3321, 1.0508, 1.2266, 0.868, 0.647, 0.2825, 1.2038, 0.6155, 0.3482, 1.1627, 1.116, 0.5774, 0.8443, 1.1158, 1.0283, 0.0126, 0.6339, 0.5671, 0.8022, -0.6814, 0.0205, -0.0404, 2.0379, 1.8559, 1.8339, 1.8321, 1.8309, 1.8299, 1.8242, 1.8223, 1.8218, 1.8175, 1.8165, 1.8125, 1.8119, 1.8118, 1.8112, 1.7704, 1.7584, 1.7546, 1.7363, 1.732, 1.7108, 1.5823, 1.4686, 1.468, 1.4624, 1.4538, 1.437, 1.4254, 1.4173, 1.3969, 1.3815, 1.3615, 1.2631, 1.3595, 1.0441, 1.2437, 0.952, 0.9741, 1.2343, 1.0627, 0.5408, 1.1717, 0.487, 0.5945, 0.7916, 0.6713, 0.7399, 0.6489, 0.0456, -0.1233, 0.3095, 1.0602, 0.1825, 0.858, 0.4396, 0.168, 0.0349, -0.221, 2.0581, 1.9782, 1.8656, 1.8567, 1.8353, 1.834, 1.8324, 1.8321, 1.8315, 1.8312, 1.8291, 1.829, 1.6983, 1.6747, 1.667, 1.6331, 1.6304, 1.6208, 1.6196, 1.5877, 1.5637, 1.5418, 1.5257, 1.5221, 1.4711, 1.4629, 1.4403, 1.4202, 1.4135, 1.4129, 1.3805, 1.3161, 1.3102, 1.2617, 1.2584, 1.1821, 1.0064, 0.6071, 0.6511, 1.1561, 0.9562, 0.9455, 1.0208, 0.4379, 0.016, 1.0179, 0.1606, 0.2203, 1.0889, 0.6882, -0.6416, 0.4009, -0.9782, 2.5703, 2.4036, 2.1364, 2.1253, 2.1246, 2.1242, 2.1105, 2.0407, 2.037, 2.0279, 2.0225, 2.0143, 2.0111, 2.0049, 1.9993, 1.9976, 1.9915, 1.9914, 1.9854, 1.9849, 1.9823, 1.9574, 1.9473, 1.941, 1.7333, 1.662, 1.6403, 1.6124, 1.5697, 1.5547, 1.5007, 1.2504, 1.375, 1.0373, 1.359, 0.9109, 1.3172, 0.9771, 0.633, 1.1756, 1.224, 0.8675, 0.3065, 0.6876, 0.0101, 0.81, 0.3422, -0.2573, -0.1227, 0.006, 0.4188, -0.4283, 0.7917, -0.7228, 0.9465, -0.3315, 0.2688, 0.0908, 2.6049, 2.4197, 2.3804, 2.3804, 2.3565, 2.1877, 2.1815, 2.1748, 2.1624, 2.1577, 2.1507, 2.1413, 2.1392, 2.1356, 2.1321, 2.1058, 2.1053, 2.1036, 2.103, 2.101, 2.1001, 2.0986, 2.0943, 2.0942, 2.0938, 2.0938, 2.0915, 2.0906, 2.0604, 2.0212, 1.6409, 1.5575, 1.5738, 0.822, 0.9936, 0.4114, 0.4713, 0.5818, 1.8908, 0.4849, 0.1768, 0.1243, 0.0653, 0.3252, 0.0239, 1.5271, 1.6007, -0.0512, -0.6733, 1.4965, 0.9707, 0.1103, 1.0383, -0.9101, 2.6435, 2.6398, 2.6156, 2.6033, 2.3925, 2.3815, 2.3803, 2.378, 2.3754, 2.3723, 2.3701, 2.3683, 2.368, 2.3586, 2.3578, 2.3546, 2.3532, 2.3511, 2.3483, 2.346, 2.3451, 2.3443, 2.3423, 2.338, 2.338, 2.3171, 2.2907, 2.2688, 2.2423, 2.2287, 1.9158, 1.7541, 1.641, 0.4651, 1.6955, 2.0067, 0.8071, 1.1769, 0.9442, 1.6307, 0.6889, 1.7159, 0.3683, -0.5854, -0.7892, -0.3523, -0.374, 0.2084, -0.9787, 0.7647, 0.7286, -0.4831, 2.5651, 2.5583, 2.5402, 2.5374, 2.5302, 2.4872, 2.4847, 2.4557, 2.1865, 2.1376, 2.0749, 2.0018, 1.9894, 1.7165, 1.6812, 1.6328, 1.5419, 1.5091, 1.4957, 1.4619, 1.447, 1.4268, 1.349, 1.23, 1.1805, 1.0742, 1.0715, 1.0694, 1.0352, 1.0182, 0.9756, 0.6278, 0.7462, 0.2437, 0.8475, 0.2265, 0.9218, -0.2269, 0.3021, 0.2171, -0.4322]}, \"token.table\": {\"Topic\": [5, 6, 1, 2, 3, 5, 6, 1, 4, 5, 7, 9, 7, 4, 1, 2, 4, 6, 1, 2, 3, 4, 7, 1, 2, 3, 4, 7, 8, 8, 3, 4, 6, 1, 6, 4, 2, 9, 4, 4, 6, 6, 1, 2, 3, 5, 6, 1, 2, 3, 4, 7, 7, 1, 1, 3, 7, 3, 4, 1, 1, 1, 2, 1, 2, 3, 5, 6, 7, 1, 2, 4, 5, 6, 7, 1, 2, 4, 5, 6, 7, 1, 2, 4, 5, 8, 1, 4, 8, 1, 2, 5, 6, 6, 1, 2, 3, 4, 5, 6, 7, 7, 3, 1, 6, 7, 8, 9, 3, 5, 7, 9, 2, 1, 1, 2, 4, 6, 8, 1, 8, 9, 8, 5, 7, 9, 3, 9, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 7, 5, 2, 3, 6, 9, 7, 1, 7, 3, 7, 1, 2, 4, 1, 2, 3, 4, 5, 7, 8, 10, 7, 4, 1, 8, 7, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 4, 5, 1, 4, 10, 8, 1, 2, 3, 10, 8, 1, 5, 6, 9, 2, 1, 1, 1, 5, 1, 1, 2, 3, 2, 3, 9, 1, 4, 5, 6, 8, 1, 4, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 5, 2, 1, 2, 3, 5, 6, 7, 9, 1, 2, 5, 6, 5, 2, 7, 1, 3, 4, 6, 9, 2, 4, 2, 1, 9, 4, 8, 2, 4, 4, 4, 7, 9, 6, 2, 5, 5, 1, 2, 5, 6, 7, 8, 1, 2, 3, 4, 6, 8, 8, 1, 4, 1, 2, 4, 4, 3, 1, 2, 3, 4, 6, 7, 5, 6, 4, 1, 1, 2, 4, 5, 6, 7, 8, 10, 1, 9, 4, 2, 1, 2, 3, 4, 5, 6, 7, 9, 2, 4, 7, 9, 8, 4, 1, 4, 2, 1, 4, 3, 9, 3, 1, 3, 4, 2, 1, 5, 6, 7, 5, 3, 1, 3, 7, 1, 2, 3, 5, 6, 3, 7, 4, 3, 4, 7, 4, 1, 1, 8, 3, 9, 8, 1, 2, 4, 5, 6, 9, 5, 4, 5, 1, 10, 1, 2, 3, 4, 5, 6, 7, 1, 2, 7, 1, 2, 3, 4, 5, 8, 5, 8, 4, 3, 8, 1, 2, 3, 4, 5, 6, 9, 1, 4, 7, 8, 9, 4, 5, 1, 2, 4, 5, 6, 4, 4, 1, 5, 5, 3, 5, 7, 5, 1, 2, 3, 6, 4, 1, 2, 3, 8, 1, 2, 3, 4, 5, 7, 8, 9, 1, 3, 1, 2, 9, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 1, 3, 4, 5, 6, 7, 9, 1, 1, 2, 7, 1, 8, 7, 1, 2, 4, 5, 6, 8, 2, 4, 8, 8, 9, 3, 8, 2, 6, 7, 3, 2, 1, 3, 9, 9, 1, 2, 3, 4, 5, 6, 9, 2, 6, 6, 8, 2, 4, 7, 4, 1, 1, 4, 3, 1, 3, 4, 5, 7, 8, 1, 2, 3, 8, 1, 6, 2, 2, 7, 8, 2, 4, 8, 5, 9, 8, 3, 9, 1, 2, 3, 4, 5, 7, 6, 5, 1, 2, 4, 5, 6, 7, 8, 1, 2, 3, 4, 7, 1, 5, 1, 2, 3, 5, 6, 8, 9, 1, 2, 7, 8, 1, 6, 7, 9, 7, 1, 3, 6, 3, 8, 2, 6, 7, 1, 10, 5, 1, 2, 5, 6, 1, 2, 3, 5, 6, 3, 1, 2, 5, 6, 8, 8, 3, 1, 8, 1, 2, 4, 9, 5, 8, 9, 1, 2, 3, 4, 7, 8, 7, 1, 1, 2, 6, 7, 1, 2, 3, 4, 5, 7, 8, 5, 1, 4, 7, 9, 1, 4, 6, 3, 1, 5, 4, 2, 6, 2, 3, 6, 1, 8, 1, 2, 4, 9, 1, 4, 1, 8, 1, 2, 8, 3, 5, 1, 2, 3, 1, 9, 1, 1, 2, 6, 7, 7, 1, 4, 6, 1, 2, 6, 9, 6, 1, 5, 7, 9, 1, 2, 4, 5, 6, 1, 4, 9, 9, 1, 2, 3, 5, 6, 6, 9, 1, 8, 2, 4, 7, 3, 1, 3, 5, 4, 1, 2, 3, 9, 9, 1, 2, 2, 8, 3, 5, 1, 2, 3, 4, 5, 6, 7, 9, 1, 4, 7, 8, 5, 3, 3, 1, 4, 7, 9, 1, 2, 4, 9, 3, 8, 1, 4, 3, 6, 6, 6, 2, 4, 2, 4, 7, 3, 1, 2, 4, 6, 3, 3, 2, 3, 5, 1, 2, 3, 7, 2, 1, 2, 4, 8, 9, 1, 2, 5, 6, 8, 7, 8, 9, 1, 3, 4, 5, 7, 1, 4, 6, 7, 1, 2, 3, 4, 6, 1, 2, 9, 6, 8, 2, 1, 2, 5, 2, 9, 1, 3, 9, 1, 2, 8, 8, 1, 3, 1, 10, 1, 3, 4, 5, 9, 1, 2, 6, 3, 7, 2, 4, 2, 4, 6, 1, 2, 4, 9, 1, 4, 1, 4, 7, 9, 1, 2, 3, 6], \"Freq\": [0.3505274710145813, 0.3505274710145813, 0.2776917036312256, 0.1388458518156128, 0.1388458518156128, 0.2776917036312256, 0.2776917036312256, 0.09550828881475766, 0.09550828881475766, 0.38203315525903064, 0.09550828881475766, 0.19101657762951532, 0.7239421217584607, 0.6470533893812478, 0.5969316325333089, 0.14923290813332724, 0.14923290813332724, 0.6699814342396059, 0.4013266637865361, 0.3009949978399021, 0.10033166594663402, 0.10033166594663402, 0.5015127640243116, 0.11490736243558737, 0.5170831309601431, 0.057453681217793685, 0.17236104365338106, 0.057453681217793685, 0.057453681217793685, 0.7184359305384022, 0.18472907244807496, 0.3694581448961499, 0.3694581448961499, 0.5377856525881485, 0.1792618841960495, 0.6432268539364024, 0.8659546313225379, 0.7337028200397885, 0.6466644068983074, 0.6544557668317703, 0.6635655296007353, 0.4404851928372407, 0.41133408139482097, 0.045703786821646775, 0.045703786821646775, 0.09140757364329355, 0.3656302945731742, 0.16569750171420564, 0.33139500342841127, 0.16569750171420564, 0.16569750171420564, 0.16569750171420564, 0.7195184363814868, 0.8020958846721358, 0.6141619297815514, 0.6729701493081857, 0.733863639378328, 0.3478002281586171, 0.3478002281586171, 0.7391396353059946, 0.6141606105044656, 0.5120796285315817, 0.3413864190210545, 0.29191007648935735, 0.09730335882978577, 0.29191007648935735, 0.19460671765957155, 0.09730335882978577, 0.09730335882978577, 0.33700862689382943, 0.1123362089646098, 0.0561681044823049, 0.1123362089646098, 0.33700862689382943, 0.0561681044823049, 0.08431210619048142, 0.08431210619048142, 0.5058726371428885, 0.08431210619048142, 0.08431210619048142, 0.08431210619048142, 0.15825863698441703, 0.15825863698441703, 0.15825863698441703, 0.31651727396883406, 0.15825863698441703, 0.5310722505005492, 0.3540481670003661, 0.7213016198060279, 0.49468519317731807, 0.05496502146414645, 0.05496502146414645, 0.3297901287848787, 0.6700760315919632, 0.2324999709672588, 0.1162499854836294, 0.1162499854836294, 0.1162499854836294, 0.2324999709672588, 0.1162499854836294, 0.1162499854836294, 0.7330761591997235, 0.6729724383209559, 0.19996731615402694, 0.19996731615402694, 0.19996731615402694, 0.19996731615402694, 0.19996731615402694, 0.29534237307382205, 0.4430135596107331, 0.14767118653691103, 0.14767118653691103, 0.8680259071438678, 0.6141589261830364, 0.1406530021360204, 0.5626120085440816, 0.1406530021360204, 0.1406530021360204, 0.1406530021360204, 0.3423924580436607, 0.3423924580436607, 0.3423924580436607, 0.514848929265286, 0.6599034764886992, 0.7208657800919032, 0.7258960005441645, 0.6532560547529398, 0.4998897831625766, 0.6702509819538255, 0.3668454365239848, 0.1693132783956853, 0.11287551893045687, 0.14109439866307108, 0.028218879732614218, 0.08465663919784265, 0.028218879732614218, 0.028218879732614218, 0.028218879732614218, 0.056437759465228436, 0.4170051269362465, 0.0834010253872493, 0.0834010253872493, 0.2502030761617479, 0.04170051269362465, 0.04170051269362465, 0.04170051269362465, 0.04170051269362465, 0.04170051269362465, 0.7163379062165532, 0.6624468359503475, 0.3268045168788127, 0.3268045168788127, 0.6630053167075373, 0.7332428155192976, 0.7347283313623999, 0.2820054052892266, 0.5640108105784531, 0.6729665579586337, 0.7197229570545663, 0.24760440521108218, 0.24760440521108218, 0.49520881042216436, 0.2826788704452249, 0.20191347888944633, 0.2422961746673356, 0.04038269577788926, 0.04038269577788926, 0.04038269577788926, 0.1211480873336678, 0.04038269577788926, 0.7197568760550815, 0.6434680757804219, 0.6141601045909169, 0.7217323898301676, 0.7202452313047387, 0.2872179909646977, 0.1723307945788186, 0.2584961918682279, 0.02872179909646977, 0.02872179909646977, 0.02872179909646977, 0.05744359819293954, 0.0861653972894093, 0.02872179909646977, 0.2483398474994748, 0.4966796949989496, 0.6426898479726111, 0.4241915961835353, 0.3932007299469242, 0.3932007299469242, 0.1966003649734621, 0.7211079861768048, 0.22578985689992137, 0.22578985689992137, 0.45157971379984274, 0.22578985689992137, 0.7223198747332116, 0.3606062267760457, 0.3606062267760457, 0.18030311338802285, 0.7332763351274765, 0.8466701445842867, 0.6054971491853438, 0.80367543079036, 0.8152275267414218, 0.6527877524177733, 0.6634373447908767, 0.6007260351205155, 0.30036301756025774, 0.15018150878012887, 0.3416786317236589, 0.3416786317236589, 0.3416786317236589, 0.3694697790142348, 0.27710233426067604, 0.1847348895071174, 0.0923674447535587, 0.715669083779893, 0.43463143173783825, 0.43463143173783825, 0.45399024885498507, 0.45399024885498507, 0.573522562886468, 0.060370796093312425, 0.09055619413996863, 0.060370796093312425, 0.09055619413996863, 0.060370796093312425, 0.060370796093312425, 0.030185398046656212, 0.670215618688418, 0.1675539046721045, 0.6458837926274276, 0.36988747387808163, 0.09247186846952041, 0.18494373693904081, 0.09247186846952041, 0.09247186846952041, 0.09247186846952041, 0.09247186846952041, 0.16428477895948249, 0.32856955791896497, 0.16428477895948249, 0.16428477895948249, 0.6535473415797931, 0.6485769831115192, 0.722071331951007, 0.4335595999765149, 0.1445198666588383, 0.1445198666588383, 0.1445198666588383, 0.1445198666588383, 0.5085968108461294, 0.2542984054230647, 0.4339128364231809, 0.6141621874803498, 0.726654156411158, 0.6495648590445532, 0.48945253587834486, 0.31381396232003095, 0.6276279246400619, 0.6429274577848253, 0.455354299894921, 0.455354299894921, 0.49336271932739095, 0.6645845532042837, 0.4294843218228004, 0.4294843218228004, 0.654407318416885, 0.650520384109203, 0.050040029546861764, 0.10008005909372353, 0.10008005909372353, 0.050040029546861764, 0.050040029546861764, 0.4588658367624592, 0.13110452478927404, 0.13110452478927404, 0.06555226239463702, 0.06555226239463702, 0.06555226239463702, 0.7219896254149457, 0.6141583677138609, 0.6469944069944602, 0.20748901608065487, 0.41497803216130974, 0.20748901608065487, 0.6495980913421207, 0.6729667795387868, 0.3192496341792829, 0.21283308945285526, 0.10641654472642763, 0.10641654472642763, 0.10641654472642763, 0.10641654472642763, 0.4361618834634194, 0.4361618834634194, 0.6432461746811704, 0.8061950711609858, 0.162217460035575, 0.32443492007115, 0.0811087300177875, 0.162217460035575, 0.0811087300177875, 0.0811087300177875, 0.0811087300177875, 0.0811087300177875, 0.3438151597833619, 0.3438151597833619, 0.643522813724871, 0.43416393877558096, 0.2773821090018555, 0.1040182908756958, 0.1040182908756958, 0.13869105450092775, 0.17336381812615967, 0.17336381812615967, 0.03467276362523194, 0.03467276362523194, 0.251962436267387, 0.251962436267387, 0.1259812181336935, 0.251962436267387, 0.7228412309504926, 0.6520524455632878, 0.4908217825325624, 0.4908217825325624, 0.6485812769738369, 0.3108597511651532, 0.6217195023303064, 0.8899867562094841, 0.7334879500957651, 0.6729631536247181, 0.20835835768385322, 0.41671671536770644, 0.41671671536770644, 0.6557689896333128, 0.18834390869338313, 0.18834390869338313, 0.18834390869338313, 0.18834390869338313, 0.6530799444157644, 0.8909383132229902, 0.806170613387362, 0.8909543573264659, 0.7213079996927955, 0.3383729168557594, 0.22558194457050623, 0.11279097228525312, 0.11279097228525312, 0.6653550665746378, 0.6729644092316733, 0.7231833803216935, 0.8563519755568166, 0.2250749124502418, 0.4501498249004836, 0.2250749124502418, 0.6428138561880022, 0.7975903730747076, 0.7443694215448482, 0.24812314051494938, 0.8909556250098892, 0.7238326706394304, 0.7173981135835548, 0.12711461664357762, 0.3813438499307329, 0.12711461664357762, 0.12711461664357762, 0.12711461664357762, 0.12711461664357762, 0.6544654667341963, 0.42415285546711723, 0.42415285546711723, 0.5035267560772742, 0.5035267560772742, 0.11743880965113662, 0.05871940482556831, 0.35231642895340987, 0.11743880965113662, 0.17615821447670493, 0.11743880965113662, 0.05871940482556831, 0.2599819556807889, 0.5199639113615778, 0.2599819556807889, 0.3613408712910397, 0.2168045227746238, 0.07226817425820793, 0.14453634851641586, 0.07226817425820793, 0.07226817425820793, 0.45704150323475573, 0.45704150323475573, 0.6500362152975535, 0.6729644831385946, 0.721913140623044, 0.32909108120933944, 0.16454554060466972, 0.16454554060466972, 0.08227277030233486, 0.16454554060466972, 0.08227277030233486, 0.08227277030233486, 0.3847374548232928, 0.1923687274116464, 0.1923687274116464, 0.1923687274116464, 0.1923687274116464, 0.3173078218963864, 0.3173078218963864, 0.178182755104207, 0.178182755104207, 0.178182755104207, 0.356365510208414, 0.178182755104207, 0.6467268632645546, 0.6495511611679381, 0.8056073262252008, 0.6539441055342889, 0.6529658610430226, 0.5372014978891526, 0.2686007489445763, 0.2686007489445763, 0.4248409142354798, 0.21194526316699383, 0.42389052633398766, 0.21194526316699383, 0.6639228115658892, 0.6441379194045783, 0.2213440277954598, 0.2213440277954598, 0.2213440277954598, 0.2213440277954598, 0.22708616992409703, 0.22708616992409703, 0.18166893593927763, 0.09083446796963882, 0.1362517019544582, 0.04541723398481941, 0.04541723398481941, 0.04541723398481941, 0.2731343289573354, 0.5462686579146708, 0.48147517484870284, 0.24073758742435142, 0.7276630123075107, 0.7259324024561109, 0.3608332795085016, 0.1804166397542508, 0.0902083198771254, 0.0451041599385627, 0.0451041599385627, 0.0902083198771254, 0.0902083198771254, 0.0451041599385627, 0.0451041599385627, 0.6485756812862636, 0.12784024525898355, 0.2556804905179671, 0.06392012262949177, 0.2556804905179671, 0.06392012262949177, 0.12784024525898355, 0.06392012262949177, 0.8065853459766144, 0.3118685481875595, 0.3118685481875595, 0.15593427409377975, 0.5220342562704096, 0.2610171281352048, 0.6126105177752321, 0.37193935369864706, 0.18596967684932353, 0.12397978456621568, 0.06198989228310784, 0.18596967684932353, 0.06198989228310784, 0.6421223267868132, 0.3210611633934066, 0.7145603421606889, 0.7179113592757066, 0.7335969881315059, 0.21363483293135435, 0.6409044987940631, 0.43312623159472924, 0.4633567995202859, 0.4633567995202859, 0.6729691610789328, 0.6465691567872925, 0.5009650982582375, 0.5009650982582375, 0.7337535189574453, 0.7329673389282535, 0.10601497155858121, 0.10601497155858121, 0.21202994311716242, 0.21202994311716242, 0.10601497155858121, 0.31804491467574364, 0.7337204747794308, 0.6459651976872144, 0.6701531637184222, 0.8851027862497125, 0.7207098124947406, 0.8616420194486876, 0.393170643224066, 0.196585321612033, 0.6438687638382444, 0.8017265968951489, 0.30774310795736054, 0.6154862159147211, 0.6729643505842856, 0.492219054456102, 0.1230547636140255, 0.06152738180701275, 0.246109527228051, 0.06152738180701275, 0.06152738180701275, 0.5120672799925671, 0.25603363999628354, 0.6729669347447241, 0.7212703890081053, 0.32332845948388145, 0.32332845948388145, 0.4353347745942214, 0.6485815263377691, 0.49285386815870424, 0.49285386815870424, 0.25511098342539695, 0.5102219668507939, 0.7216205943083877, 0.6531750819878409, 0.7251885274699376, 0.48500930243104035, 0.6918476002159998, 0.3459238001079999, 0.23438986896290295, 0.15625991264193528, 0.15625991264193528, 0.07812995632096764, 0.23438986896290295, 0.07812995632096764, 0.6699051619124914, 0.6600091779825727, 0.2691962365964875, 0.08973207886549585, 0.08973207886549585, 0.1794641577309917, 0.2691962365964875, 0.08973207886549585, 0.7166384394818593, 0.2682606271893968, 0.44710104531566136, 0.08942020906313228, 0.08942020906313228, 0.7168149033541302, 0.6141575519712549, 0.6540306339552355, 0.5776935301695844, 0.12558555003686617, 0.050234220014746464, 0.0753513300221197, 0.025117110007373232, 0.0753513300221197, 0.025117110007373232, 0.6070565295930332, 0.1517641323982583, 0.1517641323982583, 0.7143186964739136, 0.3195164796883534, 0.3195164796883534, 0.7218141346938537, 0.7330766581682703, 0.7242468931838145, 0.5229347609260506, 0.1743115869753502, 0.1743115869753502, 0.6729672578728265, 0.7220891640571455, 0.4348122352296539, 0.46500099222665925, 0.46500099222665925, 0.4999490004069745, 0.4999490004069745, 0.6543565412375333, 0.3314511681039374, 0.08286279202598434, 0.08286279202598434, 0.497176752155906, 0.4258152261619416, 0.0532269032702427, 0.0532269032702427, 0.1064538065404854, 0.3725883228916989, 0.6729583750662788, 0.42651552314795055, 0.14217184104931685, 0.09478122736621124, 0.23695306841552807, 0.04739061368310562, 0.7213753188954489, 0.8883181888304894, 0.6270000822660909, 0.31350004113304547, 0.2793280339910999, 0.4189920509866499, 0.13966401699554995, 0.13966401699554995, 0.6535870689074031, 0.495646609603076, 0.495646609603076, 0.16283993958562834, 0.48851981875688505, 0.05427997986187611, 0.05427997986187611, 0.16283993958562834, 0.10855995972375222, 0.7202369926417809, 0.6779034184143806, 0.3148436606054432, 0.3148436606054432, 0.1574218303027216, 0.1574218303027216, 0.2273814204731606, 0.2273814204731606, 0.07579380682438687, 0.07579380682438687, 0.15158761364877374, 0.07579380682438687, 0.15158761364877374, 0.6533874162602112, 0.5302056473168842, 0.17673521577229476, 0.17673521577229476, 0.733282616824506, 0.20926247582152496, 0.4185249516430499, 0.20926247582152496, 0.8909444261555952, 0.2511895828922805, 0.502379165784561, 0.6437115265247445, 0.4362458599116804, 0.4362458599116804, 0.32717132858121084, 0.6543426571624217, 0.6699254201316771, 0.34130189882113277, 0.34130189882113277, 0.15962386154371824, 0.3192477230874365, 0.3192477230874365, 0.15962386154371824, 0.26082576342494546, 0.5216515268498909, 0.34257056403262254, 0.34257056403262254, 0.43728964229781914, 0.21864482114890957, 0.21864482114890957, 0.6729626607702229, 0.4251202912763698, 0.3073930050283144, 0.6147860100566288, 0.8902459786719356, 0.8098240403623762, 0.7332557724085029, 0.8056905619771457, 0.2562181016915919, 0.2562181016915919, 0.5124362033831839, 0.7339095142497332, 0.7227473551916073, 0.41526957156764216, 0.2768463810450948, 0.2768463810450948, 0.3984119179817453, 0.4648139043120362, 0.06640198633029089, 0.733962504694915, 0.6697742531079949, 0.32523433073076125, 0.32523433073076125, 0.21682288715384085, 0.7333578762257709, 0.24582000440858645, 0.12291000220429323, 0.24582000440858645, 0.12291000220429323, 0.12291000220429323, 0.22888910986251634, 0.22888910986251634, 0.4577782197250327, 0.7217055137922865, 0.18101839192421287, 0.18101839192421287, 0.36203678384842575, 0.18101839192421287, 0.18101839192421287, 0.46691529378046204, 0.46691529378046204, 0.46716146961865657, 0.48252324103648303, 0.43955806983600754, 0.21977903491800377, 0.21977903491800377, 0.8876975780333, 0.21015442082965888, 0.42030884165931776, 0.42030884165931776, 0.6494245199759147, 0.5496783964054984, 0.1374195991013746, 0.2748391982027492, 0.1374195991013746, 0.733669035298001, 0.6141606678213667, 0.4338079900967842, 0.645711186814967, 0.4824482544148863, 0.43601196108914686, 0.43601196108914686, 0.17611672575731377, 0.23482230100975168, 0.05870557525243792, 0.17611672575731377, 0.11741115050487584, 0.05870557525243792, 0.11741115050487584, 0.05870557525243792, 0.3115926246901323, 0.6231852493802646, 0.4539228785155107, 0.7220400737976422, 0.8582918771667831, 0.6729610365885722, 0.8872123497551855, 0.51194870598873, 0.34129913732582, 0.7175843624030026, 0.5003437379390546, 0.32407996202766365, 0.10802665400922122, 0.21605330801844244, 0.21605330801844244, 0.6729593003267782, 0.7162238881731955, 0.6141624490677684, 0.8492347085352789, 0.4441402790633183, 0.4441402790633183, 0.6639658135906866, 0.6699589590157129, 0.6485755029138691, 0.6534408751013868, 0.6461362710087726, 0.4581393999078695, 0.4581393999078695, 0.6729622452132105, 0.8771053734296057, 0.6485780794759147, 0.6260537533160521, 0.208684584438684, 0.8898636348499106, 0.8905536583415566, 0.6485780518521346, 0.4356125271613765, 0.4356125271613765, 0.3782018042064966, 0.1891009021032483, 0.1891009021032483, 0.1891009021032483, 0.8653489279374461, 0.16361225743074007, 0.32722451486148013, 0.16361225743074007, 0.16361225743074007, 0.16361225743074007, 0.1827844739328999, 0.09139223696644995, 0.3655689478657998, 0.27417671089934986, 0.7147700826320917, 0.3748207728729435, 0.3748207728729435, 0.3748207728729435, 0.0773178753878284, 0.3092715015513136, 0.0773178753878284, 0.3092715015513136, 0.1546357507756568, 0.17034053369177687, 0.17034053369177687, 0.17034053369177687, 0.17034053369177687, 0.15994463384991253, 0.31988926769982506, 0.31988926769982506, 0.15994463384991253, 0.4376753888099049, 0.6175834760058967, 0.20586115866863222, 0.20586115866863222, 0.43693429696398894, 0.7150247364258447, 0.6559425970211397, 0.3066212174887599, 0.6132424349775198, 0.6544202860730135, 0.35434156296503366, 0.35434156296503366, 0.6141609755997318, 0.890180119003959, 0.7333807466691769, 0.4311249288412642, 0.2155624644206321, 0.2155624644206321, 0.7211101335653716, 0.5260972420111696, 0.3507314946741131, 0.6341354763568213, 0.21137849211894044, 0.5448626378759087, 0.13621565946897718, 0.13621565946897718, 0.13621565946897718, 0.7255982141439228, 0.40888663281779997, 0.20444331640889998, 0.20444331640889998, 0.672964135371027, 0.7207256732746171, 0.3209135994258172, 0.6418271988516344, 0.6457435461485677, 0.6492938047211032, 0.4379902000627948, 0.4087822245257825, 0.20439111226289125, 0.20439111226289125, 0.4997973837169154, 0.6141612426751177, 0.646924360044103, 0.22599683419264202, 0.22599683419264202, 0.22599683419264202, 0.22599683419264202, 0.09639384210383066, 0.6747568947268147, 0.09639384210383066, 0.09639384210383066], \"Term\": [\"absolut\", \"absolut\", \"accord\", \"accord\", \"accord\", \"accord\", \"accord\", \"account\", \"account\", \"account\", \"account\", \"account\", \"accumul\", \"accur\", \"achiev\", \"achiev\", \"achiev\", \"acknowledg\", \"action\", \"action\", \"action\", \"action\", \"actor\", \"adapt\", \"adapt\", \"adapt\", \"adapt\", \"adapt\", \"adapt\", \"adaptabrasil\", \"address\", \"address\", \"address\", \"adopt\", \"adopt\", \"advanc\", \"advantag\", \"affect\", \"ageclass\", \"agenda\", \"aggreg\", \"agre\", \"agreement\", \"agreement\", \"agreement\", \"agreement\", \"agreement\", \"agricultur\", \"agricultur\", \"agricultur\", \"agricultur\", \"agricultur\", \"agroforestri\", \"aim\", \"alia\", \"align\", \"allow\", \"ambit\", \"ambit\", \"ambiti\", \"ampl\", \"andor\", \"andor\", \"anthropogen\", \"anthropogen\", \"anthropogen\", \"anthropogen\", \"anthropogen\", \"anthropogen\", \"applic\", \"applic\", \"applic\", \"applic\", \"applic\", \"applic\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"appropri\", \"appropri\", \"appropri\", \"appropri\", \"appropri\", \"area\", \"area\", \"arrang\", \"articl\", \"articl\", \"articl\", \"articl\", \"aspir\", \"assumpt\", \"assumpt\", \"assumpt\", \"assumpt\", \"assumpt\", \"assumpt\", \"assumpt\", \"attribut\", \"august\", \"avail\", \"avail\", \"avail\", \"avail\", \"avail\", \"averag\", \"averag\", \"averag\", \"averag\", \"avoid\", \"awar\", \"base\", \"base\", \"base\", \"base\", \"base\", \"best\", \"best\", \"best\", \"better\", \"biennial\", \"billion\", \"biofuel\", \"biom\", \"biomass\", \"bras\\u00edlia\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazil\", \"brazilian\", \"brazilian\", \"brazilian\", \"brazilian\", \"brazilian\", \"brazilian\", \"brazilian\", \"brazilian\", \"brazilian\", \"breed\", \"btrs\", \"build\", \"build\", \"calcul\", \"capac\", \"capita\", \"carbon\", \"carbon\", \"carri\", \"cattl\", \"challeng\", \"challeng\", \"challeng\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"channel\", \"choos\", \"citizen\", \"civil\", \"cleanest\", \"climat\", \"climat\", \"climat\", \"climat\", \"climat\", \"climat\", \"climat\", \"climat\", \"climat\", \"cobenefit\", \"cobenefit\", \"code\", \"collect\", \"commit\", \"commit\", \"commit\", \"committe\", \"communic\", \"communic\", \"communic\", \"communic\", \"communiti\", \"compar\", \"compar\", \"compar\", \"compens\", \"complement\", \"compon\", \"condit\", \"confer\", \"confid\", \"confirm\", \"consid\", \"consid\", \"consid\", \"consider\", \"consider\", \"consider\", \"consist\", \"consist\", \"consist\", \"consist\", \"consolid\", \"context\", \"context\", \"continu\", \"continu\", \"contribut\", \"contribut\", \"contribut\", \"contribut\", \"contribut\", \"contribut\", \"contribut\", \"contribut\", \"convent\", \"convent\", \"coordin\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"cover\", \"cover\", \"cover\", \"cover\", \"coverag\", \"criteria\", \"crop\", \"current\", \"current\", \"current\", \"current\", \"current\", \"cycl\", \"cycl\", \"damag\", \"deal\", \"decarbonis\", \"decoupl\", \"decre\", \"defin\", \"defin\", \"deforest\", \"degrad\", \"degrad\", \"demand\", \"depend\", \"descript\", \"descript\", \"detail\", \"determin\", \"determin\", \"determin\", \"determin\", \"determin\", \"determin\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"dialogu\", \"discuss\", \"disturb\", \"diversif\", \"diversif\", \"diversif\", \"doubl\", \"ecolog\", \"econom\", \"econom\", \"econom\", \"econom\", \"econom\", \"econom\", \"economywid\", \"economywid\", \"ecosystem\", \"educ\", \"effort\", \"effort\", \"effort\", \"effort\", \"effort\", \"effort\", \"effort\", \"effort\", \"electr\", \"electr\", \"elimin\", \"emerg\", \"emiss\", \"emiss\", \"emiss\", \"emiss\", \"emiss\", \"emiss\", \"emiss\", \"emiss\", \"energi\", \"energi\", \"energi\", \"energi\", \"engag\", \"enhanc\", \"ensur\", \"ensur\", \"entiti\", \"environment\", \"environment\", \"equatori\", \"equiti\", \"especi\", \"establish\", \"establish\", \"establish\", \"estat\", \"estim\", \"estim\", \"estim\", \"estim\", \"evalu\", \"event\", \"exampl\", \"extrem\", \"farm\", \"feder\", \"feder\", \"feder\", \"feder\", \"fifth\", \"find\", \"fixat\", \"food\", \"forest\", \"forest\", \"forest\", \"fragil\", \"frame\", \"framework\", \"framework\", \"frequenc\", \"fuel\", \"futur\", \"gas\", \"gas\", \"gas\", \"gas\", \"gas\", \"gas\", \"general\", \"give\", \"give\", \"glasgow\", \"glasgow\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"goal\", \"goal\", \"goal\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"govern\", \"government\", \"government\", \"great\", \"greater\", \"green\", \"greenhous\", \"greenhous\", \"greenhous\", \"greenhous\", \"greenhous\", \"greenhous\", \"greenhous\", \"growth\", \"growth\", \"growth\", \"growth\", \"growth\", \"guidanc\", \"guidanc\", \"guidelin\", \"guidelin\", \"guidelin\", \"guidelin\", \"guidelin\", \"harvest\", \"have\", \"health\", \"hfcs\", \"high\", \"histor\", \"histor\", \"histor\", \"hold\", \"human\", \"human\", \"human\", \"identifi\", \"illeg\", \"impact\", \"impact\", \"impact\", \"impact\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"import\", \"import\", \"improv\", \"improv\", \"incent\", \"incentiv\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"includ\", \"incorpor\", \"increas\", \"increas\", \"increas\", \"increas\", \"increas\", \"increas\", \"increas\", \"index\", \"indic\", \"indic\", \"indic\", \"indigen\", \"indigen\", \"individu\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"infrastructur\", \"infrastructur\", \"innov\", \"inp\", \"instal\", \"institut\", \"institut\", \"instrument\", \"integr\", \"integr\", \"intens\", \"intent\", \"interfer\", \"interfer\", \"intermitt\", \"invest\", \"ipcc\", \"ipcc\", \"ipcc\", \"ipcc\", \"ipcc\", \"ipcc\", \"issu\", \"itmo\", \"join\", \"joint\", \"june\", \"knowledg\", \"land\", \"land\", \"landown\", \"latest\", \"law\", \"law\", \"lead\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"light\", \"light\", \"like\", \"local\", \"longterm\", \"longterm\", \"loss\", \"mainstream\", \"maintain\", \"maintain\", \"manag\", \"manag\", \"manner\", \"margin\", \"market\", \"mcti\", \"mean\", \"mean\", \"measur\", \"measur\", \"measur\", \"measur\", \"measur\", \"measur\", \"member\", \"method\", \"methodolog\", \"methodolog\", \"methodolog\", \"methodolog\", \"methodolog\", \"methodolog\", \"ministri\", \"mitig\", \"mitig\", \"mitig\", \"mitig\", \"mix\", \"mobil\", \"multiyear\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"need\", \"need\", \"need\", \"network\", \"neutral\", \"neutral\", \"nitrogen\", \"nonetheless\", \"notil\", \"object\", \"object\", \"object\", \"occur\", \"octob\", \"opportun\", \"organ\", \"organ\", \"pact\", \"pact\", \"panel\", \"paragraph\", \"paragraph\", \"paragraph\", \"paragraph\", \"pari\", \"pari\", \"pari\", \"pari\", \"pari\", \"part\", \"parti\", \"parti\", \"parti\", \"parti\", \"parti\", \"particip\", \"particular\", \"peopl\", \"peopl\", \"period\", \"period\", \"period\", \"period\", \"pfcs\", \"place\", \"place\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"plant\", \"pleas\", \"point\", \"point\", \"point\", \"point\", \"polici\", \"polici\", \"polici\", \"polici\", \"polici\", \"polici\", \"polici\", \"pool\", \"popul\", \"popul\", \"popul\", \"post\", \"potenti\", \"potenti\", \"potenti\", \"precipit\", \"preindustri\", \"preindustri\", \"preserv\", \"previous\", \"previous\", \"principl\", \"principl\", \"prioriti\", \"process\", \"process\", \"product\", \"product\", \"product\", \"product\", \"protect\", \"protect\", \"provid\", \"provid\", \"public\", \"public\", \"public\", \"publish\", \"pursu\", \"quantifi\", \"quantifi\", \"rainforest\", \"rank\", \"rapid\", \"rat\", \"reach\", \"reach\", \"reach\", \"reconstruct\", \"recov\", \"reduc\", \"reduc\", \"reduc\", \"refer\", \"refer\", \"refer\", \"reflect\", \"region\", \"relat\", \"relat\", \"relat\", \"remain\", \"remov\", \"remov\", \"remov\", \"remov\", \"remov\", \"renew\", \"renew\", \"renew\", \"renovabio\", \"report\", \"report\", \"report\", \"report\", \"report\", \"repres\", \"repres\", \"republ\", \"research\", \"resourc\", \"resourc\", \"resourc\", \"respect\", \"respons\", \"respons\", \"respons\", \"restor\", \"result\", \"result\", \"result\", \"result\", \"revolut\", \"right\", \"risk\", \"rule\", \"scienc\", \"scope\", \"scope\", \"sector\", \"sector\", \"sector\", \"sector\", \"sector\", \"sector\", \"sector\", \"sector\", \"secur\", \"secur\", \"seri\", \"set\", \"singleyear\", \"sixth\", \"small\", \"social\", \"social\", \"soil\", \"solar\", \"sourc\", \"sourc\", \"sourc\", \"sourc\", \"south\", \"space\", \"special\", \"spite\", \"state\", \"state\", \"stipul\", \"stock\", \"strateg\", \"strengthen\", \"strive\", \"structur\", \"structur\", \"studi\", \"submit\", \"subnat\", \"subsequ\", \"subsequ\", \"subtrop\", \"suffer\", \"support\", \"surfac\", \"surfac\", \"sustain\", \"sustain\", \"sustain\", \"sustain\", \"system\", \"take\", \"take\", \"take\", \"take\", \"take\", \"target\", \"target\", \"target\", \"target\", \"teach\", \"technolog\", \"technolog\", \"technolog\", \"temperatur\", \"temperatur\", \"temperatur\", \"temperatur\", \"temperatur\", \"term\", \"term\", \"term\", \"term\", \"territori\", \"territori\", \"territori\", \"territori\", \"tier\", \"time\", \"time\", \"time\", \"timehorizon\", \"tool\", \"tourism\", \"transfer\", \"transfer\", \"translat\", \"transport\", \"transport\", \"tribal\", \"tropic\", \"uncondit\", \"understand\", \"understand\", \"understand\", \"undertak\", \"unfccc\", \"unfccc\", \"unit\", \"unit\", \"updat\", \"updat\", \"updat\", \"updat\", \"use\", \"valu\", \"valu\", \"valu\", \"variabl\", \"vast\", \"view\", \"view\", \"voluntari\", \"voluntarili\", \"warm\", \"water\", \"water\", \"water\", \"wind\", \"women\", \"wood\", \"world\", \"world\", \"world\", \"world\", \"year\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [10, 1, 9, 5, 7, 8, 2, 6, 4, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el374824448358878086625121802\", ldavis_el374824448358878086625121802_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el374824448358878086625121802\", ldavis_el374824448358878086625121802_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el374824448358878086625121802\", ldavis_el374824448358878086625121802_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "9     -0.073796  0.018351       1        1  27.584760\n",
       "0      0.007045  0.004533       2        1  15.510337\n",
       "8      0.036073  0.142654       3        1  11.184532\n",
       "4      0.036352 -0.095830       4        1   9.814348\n",
       "6     -0.084991  0.010313       5        1   9.095155\n",
       "7     -0.151569 -0.045055       6        1   8.871864\n",
       "1      0.005098  0.000679       7        1   5.618651\n",
       "5      0.079622  0.031747       8        1   5.139272\n",
       "3      0.113654 -0.081743       9        1   4.320794\n",
       "2      0.032510  0.014351      10        1   2.860286, topic_info=          Term       Freq      Total Category  logprob  loglift\n",
       "3    agreement  21.000000  21.000000  Default  30.0000  30.0000\n",
       "7       climat  34.000000  34.000000  Default  29.0000  29.0000\n",
       "104     articl  18.000000  18.000000  Default  28.0000  28.0000\n",
       "115       plan  18.000000  18.000000  Default  27.0000  27.0000\n",
       "30        pari  18.000000  18.000000  Default  26.0000  26.0000\n",
       "..         ...        ...        ...      ...      ...      ...\n",
       "344       area   0.406159   5.648949  Topic10  -5.0421   0.9218\n",
       "6        chang   0.564531  24.763082  Topic10  -4.7128  -0.2269\n",
       "48     countri   0.418416  10.814100  Topic10  -5.0123   0.3021\n",
       "62       mitig   0.397441  11.183154  Topic10  -5.0638   0.2171\n",
       "3    agreement   0.406232  21.880025  Topic10  -5.0419  -0.4322\n",
       "\n",
       "[601 rows x 6 columns], token_table=      Topic      Freq     Term\n",
       "term                          \n",
       "136       5  0.350527  absolut\n",
       "136       6  0.350527  absolut\n",
       "158       1  0.277692   accord\n",
       "158       2  0.138846   accord\n",
       "158       3  0.138846   accord\n",
       "...     ...       ...      ...\n",
       "532       9  0.225997    world\n",
       "103       1  0.096394     year\n",
       "103       2  0.674757     year\n",
       "103       3  0.096394     year\n",
       "103       6  0.096394     year\n",
       "\n",
       "[851 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[10, 1, 9, 5, 7, 8, 2, 6, 4, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Topic Distance Visualization \n",
    "pyLDAvis.enable_notebook()\n",
    "p = pyLDAvis.gensim_models.prepare(lda_model, bow_corpus, dictionary)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baea64d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serva\\Downloads\\Anaconda\\envs\\py39\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "# Save the visualization in a html file\n",
    "p = pyLDAvis.gensim_models.prepare(lda_model, bow_corpus, dictionary)\n",
    "pyLDAvis.save_html(p, 'lda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52be34d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.39343810081481934\t Topic: 0.029*\"institut\" + 0.027*\"nation\" + 0.026*\"chang\" + 0.025*\"climat\" + 0.016*\"polici\"\n",
      "Score: 0.33987119793891907\t Topic: 0.039*\"nation\" + 0.031*\"contribut\" + 0.021*\"determin\" + 0.021*\"brazil\" + 0.017*\"climat\"\n",
      "Score: 0.03334071487188339\t Topic: 0.042*\"agreement\" + 0.034*\"pari\" + 0.031*\"articl\" + 0.030*\"applic\" + 0.029*\"paragraph\"\n",
      "Score: 0.03333934769034386\t Topic: 0.023*\"emiss\" + 0.021*\"target\" + 0.021*\"temperatur\" + 0.020*\"increas\" + 0.019*\"level\"\n",
      "Score: 0.0333390049636364\t Topic: 0.021*\"plan\" + 0.020*\"increas\" + 0.019*\"individu\" + 0.016*\"temperatur\" + 0.015*\"contribut\"\n",
      "Score: 0.033334605395793915\t Topic: 0.027*\"plan\" + 0.026*\"adapt\" + 0.021*\"year\" + 0.020*\"refer\" + 0.019*\"climat\"\n",
      "Score: 0.03333446756005287\t Topic: 0.038*\"climat\" + 0.025*\"chang\" + 0.023*\"global\" + 0.017*\"temperatur\" + 0.017*\"brazil\"\n",
      "Score: 0.033334311097860336\t Topic: 0.030*\"brazil\" + 0.020*\"climat\" + 0.017*\"commit\" + 0.014*\"brazilian\" + 0.012*\"effort\"\n",
      "Score: 0.03333412855863571\t Topic: 0.025*\"account\" + 0.025*\"energi\" + 0.024*\"sourc\" + 0.018*\"renew\" + 0.013*\"solar\"\n",
      "Score: 0.03333412855863571\t Topic: 0.029*\"approach\" + 0.026*\"brazilian\" + 0.021*\"brazil\" + 0.019*\"emiss\" + 0.015*\"adapt\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = 'Determining this huge process was quiet nice'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b663482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
